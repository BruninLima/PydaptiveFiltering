window.pdocSearch = (function(){
/** elasticlunr - http://weixsong.github.io * Copyright (C) 2017 Oliver Nightingale * Copyright (C) 2017 Wei Song * MIT Licensed */!function(){function e(e){if(null===e||"object"!=typeof e)return e;var t=e.constructor();for(var n in e)e.hasOwnProperty(n)&&(t[n]=e[n]);return t}var t=function(e){var n=new t.Index;return n.pipeline.add(t.trimmer,t.stopWordFilter,t.stemmer),e&&e.call(n,n),n};t.version="0.9.5",lunr=t,t.utils={},t.utils.warn=function(e){return function(t){e.console&&console.warn&&console.warn(t)}}(this),t.utils.toString=function(e){return void 0===e||null===e?"":e.toString()},t.EventEmitter=function(){this.events={}},t.EventEmitter.prototype.addListener=function(){var e=Array.prototype.slice.call(arguments),t=e.pop(),n=e;if("function"!=typeof t)throw new TypeError("last argument must be a function");n.forEach(function(e){this.hasHandler(e)||(this.events[e]=[]),this.events[e].push(t)},this)},t.EventEmitter.prototype.removeListener=function(e,t){if(this.hasHandler(e)){var n=this.events[e].indexOf(t);-1!==n&&(this.events[e].splice(n,1),0==this.events[e].length&&delete this.events[e])}},t.EventEmitter.prototype.emit=function(e){if(this.hasHandler(e)){var t=Array.prototype.slice.call(arguments,1);this.events[e].forEach(function(e){e.apply(void 0,t)},this)}},t.EventEmitter.prototype.hasHandler=function(e){return e in this.events},t.tokenizer=function(e){if(!arguments.length||null===e||void 0===e)return[];if(Array.isArray(e)){var n=e.filter(function(e){return null===e||void 0===e?!1:!0});n=n.map(function(e){return t.utils.toString(e).toLowerCase()});var i=[];return n.forEach(function(e){var n=e.split(t.tokenizer.seperator);i=i.concat(n)},this),i}return e.toString().trim().toLowerCase().split(t.tokenizer.seperator)},t.tokenizer.defaultSeperator=/[\s\-]+/,t.tokenizer.seperator=t.tokenizer.defaultSeperator,t.tokenizer.setSeperator=function(e){null!==e&&void 0!==e&&"object"==typeof e&&(t.tokenizer.seperator=e)},t.tokenizer.resetSeperator=function(){t.tokenizer.seperator=t.tokenizer.defaultSeperator},t.tokenizer.getSeperator=function(){return t.tokenizer.seperator},t.Pipeline=function(){this._queue=[]},t.Pipeline.registeredFunctions={},t.Pipeline.registerFunction=function(e,n){n in t.Pipeline.registeredFunctions&&t.utils.warn("Overwriting existing registered function: "+n),e.label=n,t.Pipeline.registeredFunctions[n]=e},t.Pipeline.getRegisteredFunction=function(e){return e in t.Pipeline.registeredFunctions!=!0?null:t.Pipeline.registeredFunctions[e]},t.Pipeline.warnIfFunctionNotRegistered=function(e){var n=e.label&&e.label in this.registeredFunctions;n||t.utils.warn("Function is not registered with pipeline. This may cause problems when serialising the index.\n",e)},t.Pipeline.load=function(e){var n=new t.Pipeline;return e.forEach(function(e){var i=t.Pipeline.getRegisteredFunction(e);if(!i)throw new Error("Cannot load un-registered function: "+e);n.add(i)}),n},t.Pipeline.prototype.add=function(){var e=Array.prototype.slice.call(arguments);e.forEach(function(e){t.Pipeline.warnIfFunctionNotRegistered(e),this._queue.push(e)},this)},t.Pipeline.prototype.after=function(e,n){t.Pipeline.warnIfFunctionNotRegistered(n);var i=this._queue.indexOf(e);if(-1===i)throw new Error("Cannot find existingFn");this._queue.splice(i+1,0,n)},t.Pipeline.prototype.before=function(e,n){t.Pipeline.warnIfFunctionNotRegistered(n);var i=this._queue.indexOf(e);if(-1===i)throw new Error("Cannot find existingFn");this._queue.splice(i,0,n)},t.Pipeline.prototype.remove=function(e){var t=this._queue.indexOf(e);-1!==t&&this._queue.splice(t,1)},t.Pipeline.prototype.run=function(e){for(var t=[],n=e.length,i=this._queue.length,o=0;n>o;o++){for(var r=e[o],s=0;i>s&&(r=this._queue[s](r,o,e),void 0!==r&&null!==r);s++);void 0!==r&&null!==r&&t.push(r)}return t},t.Pipeline.prototype.reset=function(){this._queue=[]},t.Pipeline.prototype.get=function(){return this._queue},t.Pipeline.prototype.toJSON=function(){return this._queue.map(function(e){return t.Pipeline.warnIfFunctionNotRegistered(e),e.label})},t.Index=function(){this._fields=[],this._ref="id",this.pipeline=new t.Pipeline,this.documentStore=new t.DocumentStore,this.index={},this.eventEmitter=new t.EventEmitter,this._idfCache={},this.on("add","remove","update",function(){this._idfCache={}}.bind(this))},t.Index.prototype.on=function(){var e=Array.prototype.slice.call(arguments);return this.eventEmitter.addListener.apply(this.eventEmitter,e)},t.Index.prototype.off=function(e,t){return this.eventEmitter.removeListener(e,t)},t.Index.load=function(e){e.version!==t.version&&t.utils.warn("version mismatch: current "+t.version+" importing "+e.version);var n=new this;n._fields=e.fields,n._ref=e.ref,n.documentStore=t.DocumentStore.load(e.documentStore),n.pipeline=t.Pipeline.load(e.pipeline),n.index={};for(var i in e.index)n.index[i]=t.InvertedIndex.load(e.index[i]);return n},t.Index.prototype.addField=function(e){return this._fields.push(e),this.index[e]=new t.InvertedIndex,this},t.Index.prototype.setRef=function(e){return this._ref=e,this},t.Index.prototype.saveDocument=function(e){return this.documentStore=new t.DocumentStore(e),this},t.Index.prototype.addDoc=function(e,n){if(e){var n=void 0===n?!0:n,i=e[this._ref];this.documentStore.addDoc(i,e),this._fields.forEach(function(n){var o=this.pipeline.run(t.tokenizer(e[n]));this.documentStore.addFieldLength(i,n,o.length);var r={};o.forEach(function(e){e in r?r[e]+=1:r[e]=1},this);for(var s in r){var u=r[s];u=Math.sqrt(u),this.index[n].addToken(s,{ref:i,tf:u})}},this),n&&this.eventEmitter.emit("add",e,this)}},t.Index.prototype.removeDocByRef=function(e){if(e&&this.documentStore.isDocStored()!==!1&&this.documentStore.hasDoc(e)){var t=this.documentStore.getDoc(e);this.removeDoc(t,!1)}},t.Index.prototype.removeDoc=function(e,n){if(e){var n=void 0===n?!0:n,i=e[this._ref];this.documentStore.hasDoc(i)&&(this.documentStore.removeDoc(i),this._fields.forEach(function(n){var o=this.pipeline.run(t.tokenizer(e[n]));o.forEach(function(e){this.index[n].removeToken(e,i)},this)},this),n&&this.eventEmitter.emit("remove",e,this))}},t.Index.prototype.updateDoc=function(e,t){var t=void 0===t?!0:t;this.removeDocByRef(e[this._ref],!1),this.addDoc(e,!1),t&&this.eventEmitter.emit("update",e,this)},t.Index.prototype.idf=function(e,t){var n="@"+t+"/"+e;if(Object.prototype.hasOwnProperty.call(this._idfCache,n))return this._idfCache[n];var i=this.index[t].getDocFreq(e),o=1+Math.log(this.documentStore.length/(i+1));return this._idfCache[n]=o,o},t.Index.prototype.getFields=function(){return this._fields.slice()},t.Index.prototype.search=function(e,n){if(!e)return[];e="string"==typeof e?{any:e}:JSON.parse(JSON.stringify(e));var i=null;null!=n&&(i=JSON.stringify(n));for(var o=new t.Configuration(i,this.getFields()).get(),r={},s=Object.keys(e),u=0;u<s.length;u++){var a=s[u];r[a]=this.pipeline.run(t.tokenizer(e[a]))}var l={};for(var c in o){var d=r[c]||r.any;if(d){var f=this.fieldSearch(d,c,o),h=o[c].boost;for(var p in f)f[p]=f[p]*h;for(var p in f)p in l?l[p]+=f[p]:l[p]=f[p]}}var v,g=[];for(var p in l)v={ref:p,score:l[p]},this.documentStore.hasDoc(p)&&(v.doc=this.documentStore.getDoc(p)),g.push(v);return g.sort(function(e,t){return t.score-e.score}),g},t.Index.prototype.fieldSearch=function(e,t,n){var i=n[t].bool,o=n[t].expand,r=n[t].boost,s=null,u={};return 0!==r?(e.forEach(function(e){var n=[e];1==o&&(n=this.index[t].expandToken(e));var r={};n.forEach(function(n){var o=this.index[t].getDocs(n),a=this.idf(n,t);if(s&&"AND"==i){var l={};for(var c in s)c in o&&(l[c]=o[c]);o=l}n==e&&this.fieldSearchStats(u,n,o);for(var c in o){var d=this.index[t].getTermFrequency(n,c),f=this.documentStore.getFieldLength(c,t),h=1;0!=f&&(h=1/Math.sqrt(f));var p=1;n!=e&&(p=.15*(1-(n.length-e.length)/n.length));var v=d*a*h*p;c in r?r[c]+=v:r[c]=v}},this),s=this.mergeScores(s,r,i)},this),s=this.coordNorm(s,u,e.length)):void 0},t.Index.prototype.mergeScores=function(e,t,n){if(!e)return t;if("AND"==n){var i={};for(var o in t)o in e&&(i[o]=e[o]+t[o]);return i}for(var o in t)o in e?e[o]+=t[o]:e[o]=t[o];return e},t.Index.prototype.fieldSearchStats=function(e,t,n){for(var i in n)i in e?e[i].push(t):e[i]=[t]},t.Index.prototype.coordNorm=function(e,t,n){for(var i in e)if(i in t){var o=t[i].length;e[i]=e[i]*o/n}return e},t.Index.prototype.toJSON=function(){var e={};return this._fields.forEach(function(t){e[t]=this.index[t].toJSON()},this),{version:t.version,fields:this._fields,ref:this._ref,documentStore:this.documentStore.toJSON(),index:e,pipeline:this.pipeline.toJSON()}},t.Index.prototype.use=function(e){var t=Array.prototype.slice.call(arguments,1);t.unshift(this),e.apply(this,t)},t.DocumentStore=function(e){this._save=null===e||void 0===e?!0:e,this.docs={},this.docInfo={},this.length=0},t.DocumentStore.load=function(e){var t=new this;return t.length=e.length,t.docs=e.docs,t.docInfo=e.docInfo,t._save=e.save,t},t.DocumentStore.prototype.isDocStored=function(){return this._save},t.DocumentStore.prototype.addDoc=function(t,n){this.hasDoc(t)||this.length++,this.docs[t]=this._save===!0?e(n):null},t.DocumentStore.prototype.getDoc=function(e){return this.hasDoc(e)===!1?null:this.docs[e]},t.DocumentStore.prototype.hasDoc=function(e){return e in this.docs},t.DocumentStore.prototype.removeDoc=function(e){this.hasDoc(e)&&(delete this.docs[e],delete this.docInfo[e],this.length--)},t.DocumentStore.prototype.addFieldLength=function(e,t,n){null!==e&&void 0!==e&&0!=this.hasDoc(e)&&(this.docInfo[e]||(this.docInfo[e]={}),this.docInfo[e][t]=n)},t.DocumentStore.prototype.updateFieldLength=function(e,t,n){null!==e&&void 0!==e&&0!=this.hasDoc(e)&&this.addFieldLength(e,t,n)},t.DocumentStore.prototype.getFieldLength=function(e,t){return null===e||void 0===e?0:e in this.docs&&t in this.docInfo[e]?this.docInfo[e][t]:0},t.DocumentStore.prototype.toJSON=function(){return{docs:this.docs,docInfo:this.docInfo,length:this.length,save:this._save}},t.stemmer=function(){var e={ational:"ate",tional:"tion",enci:"ence",anci:"ance",izer:"ize",bli:"ble",alli:"al",entli:"ent",eli:"e",ousli:"ous",ization:"ize",ation:"ate",ator:"ate",alism:"al",iveness:"ive",fulness:"ful",ousness:"ous",aliti:"al",iviti:"ive",biliti:"ble",logi:"log"},t={icate:"ic",ative:"",alize:"al",iciti:"ic",ical:"ic",ful:"",ness:""},n="[^aeiou]",i="[aeiouy]",o=n+"[^aeiouy]*",r=i+"[aeiou]*",s="^("+o+")?"+r+o,u="^("+o+")?"+r+o+"("+r+")?$",a="^("+o+")?"+r+o+r+o,l="^("+o+")?"+i,c=new RegExp(s),d=new RegExp(a),f=new RegExp(u),h=new RegExp(l),p=/^(.+?)(ss|i)es$/,v=/^(.+?)([^s])s$/,g=/^(.+?)eed$/,m=/^(.+?)(ed|ing)$/,y=/.$/,S=/(at|bl|iz)$/,x=new RegExp("([^aeiouylsz])\\1$"),w=new RegExp("^"+o+i+"[^aeiouwxy]$"),I=/^(.+?[^aeiou])y$/,b=/^(.+?)(ational|tional|enci|anci|izer|bli|alli|entli|eli|ousli|ization|ation|ator|alism|iveness|fulness|ousness|aliti|iviti|biliti|logi)$/,E=/^(.+?)(icate|ative|alize|iciti|ical|ful|ness)$/,D=/^(.+?)(al|ance|ence|er|ic|able|ible|ant|ement|ment|ent|ou|ism|ate|iti|ous|ive|ize)$/,F=/^(.+?)(s|t)(ion)$/,_=/^(.+?)e$/,P=/ll$/,k=new RegExp("^"+o+i+"[^aeiouwxy]$"),z=function(n){var i,o,r,s,u,a,l;if(n.length<3)return n;if(r=n.substr(0,1),"y"==r&&(n=r.toUpperCase()+n.substr(1)),s=p,u=v,s.test(n)?n=n.replace(s,"$1$2"):u.test(n)&&(n=n.replace(u,"$1$2")),s=g,u=m,s.test(n)){var z=s.exec(n);s=c,s.test(z[1])&&(s=y,n=n.replace(s,""))}else if(u.test(n)){var z=u.exec(n);i=z[1],u=h,u.test(i)&&(n=i,u=S,a=x,l=w,u.test(n)?n+="e":a.test(n)?(s=y,n=n.replace(s,"")):l.test(n)&&(n+="e"))}if(s=I,s.test(n)){var z=s.exec(n);i=z[1],n=i+"i"}if(s=b,s.test(n)){var z=s.exec(n);i=z[1],o=z[2],s=c,s.test(i)&&(n=i+e[o])}if(s=E,s.test(n)){var z=s.exec(n);i=z[1],o=z[2],s=c,s.test(i)&&(n=i+t[o])}if(s=D,u=F,s.test(n)){var z=s.exec(n);i=z[1],s=d,s.test(i)&&(n=i)}else if(u.test(n)){var z=u.exec(n);i=z[1]+z[2],u=d,u.test(i)&&(n=i)}if(s=_,s.test(n)){var z=s.exec(n);i=z[1],s=d,u=f,a=k,(s.test(i)||u.test(i)&&!a.test(i))&&(n=i)}return s=P,u=d,s.test(n)&&u.test(n)&&(s=y,n=n.replace(s,"")),"y"==r&&(n=r.toLowerCase()+n.substr(1)),n};return z}(),t.Pipeline.registerFunction(t.stemmer,"stemmer"),t.stopWordFilter=function(e){return e&&t.stopWordFilter.stopWords[e]!==!0?e:void 0},t.clearStopWords=function(){t.stopWordFilter.stopWords={}},t.addStopWords=function(e){null!=e&&Array.isArray(e)!==!1&&e.forEach(function(e){t.stopWordFilter.stopWords[e]=!0},this)},t.resetStopWords=function(){t.stopWordFilter.stopWords=t.defaultStopWords},t.defaultStopWords={"":!0,a:!0,able:!0,about:!0,across:!0,after:!0,all:!0,almost:!0,also:!0,am:!0,among:!0,an:!0,and:!0,any:!0,are:!0,as:!0,at:!0,be:!0,because:!0,been:!0,but:!0,by:!0,can:!0,cannot:!0,could:!0,dear:!0,did:!0,"do":!0,does:!0,either:!0,"else":!0,ever:!0,every:!0,"for":!0,from:!0,get:!0,got:!0,had:!0,has:!0,have:!0,he:!0,her:!0,hers:!0,him:!0,his:!0,how:!0,however:!0,i:!0,"if":!0,"in":!0,into:!0,is:!0,it:!0,its:!0,just:!0,least:!0,let:!0,like:!0,likely:!0,may:!0,me:!0,might:!0,most:!0,must:!0,my:!0,neither:!0,no:!0,nor:!0,not:!0,of:!0,off:!0,often:!0,on:!0,only:!0,or:!0,other:!0,our:!0,own:!0,rather:!0,said:!0,say:!0,says:!0,she:!0,should:!0,since:!0,so:!0,some:!0,than:!0,that:!0,the:!0,their:!0,them:!0,then:!0,there:!0,these:!0,they:!0,"this":!0,tis:!0,to:!0,too:!0,twas:!0,us:!0,wants:!0,was:!0,we:!0,were:!0,what:!0,when:!0,where:!0,which:!0,"while":!0,who:!0,whom:!0,why:!0,will:!0,"with":!0,would:!0,yet:!0,you:!0,your:!0},t.stopWordFilter.stopWords=t.defaultStopWords,t.Pipeline.registerFunction(t.stopWordFilter,"stopWordFilter"),t.trimmer=function(e){if(null===e||void 0===e)throw new Error("token should not be undefined");return e.replace(/^\W+/,"").replace(/\W+$/,"")},t.Pipeline.registerFunction(t.trimmer,"trimmer"),t.InvertedIndex=function(){this.root={docs:{},df:0}},t.InvertedIndex.load=function(e){var t=new this;return t.root=e.root,t},t.InvertedIndex.prototype.addToken=function(e,t,n){for(var n=n||this.root,i=0;i<=e.length-1;){var o=e[i];o in n||(n[o]={docs:{},df:0}),i+=1,n=n[o]}var r=t.ref;n.docs[r]?n.docs[r]={tf:t.tf}:(n.docs[r]={tf:t.tf},n.df+=1)},t.InvertedIndex.prototype.hasToken=function(e){if(!e)return!1;for(var t=this.root,n=0;n<e.length;n++){if(!t[e[n]])return!1;t=t[e[n]]}return!0},t.InvertedIndex.prototype.getNode=function(e){if(!e)return null;for(var t=this.root,n=0;n<e.length;n++){if(!t[e[n]])return null;t=t[e[n]]}return t},t.InvertedIndex.prototype.getDocs=function(e){var t=this.getNode(e);return null==t?{}:t.docs},t.InvertedIndex.prototype.getTermFrequency=function(e,t){var n=this.getNode(e);return null==n?0:t in n.docs?n.docs[t].tf:0},t.InvertedIndex.prototype.getDocFreq=function(e){var t=this.getNode(e);return null==t?0:t.df},t.InvertedIndex.prototype.removeToken=function(e,t){if(e){var n=this.getNode(e);null!=n&&t in n.docs&&(delete n.docs[t],n.df-=1)}},t.InvertedIndex.prototype.expandToken=function(e,t,n){if(null==e||""==e)return[];var t=t||[];if(void 0==n&&(n=this.getNode(e),null==n))return t;n.df>0&&t.push(e);for(var i in n)"docs"!==i&&"df"!==i&&this.expandToken(e+i,t,n[i]);return t},t.InvertedIndex.prototype.toJSON=function(){return{root:this.root}},t.Configuration=function(e,n){var e=e||"";if(void 0==n||null==n)throw new Error("fields should not be null");this.config={};var i;try{i=JSON.parse(e),this.buildUserConfig(i,n)}catch(o){t.utils.warn("user configuration parse failed, will use default configuration"),this.buildDefaultConfig(n)}},t.Configuration.prototype.buildDefaultConfig=function(e){this.reset(),e.forEach(function(e){this.config[e]={boost:1,bool:"OR",expand:!1}},this)},t.Configuration.prototype.buildUserConfig=function(e,n){var i="OR",o=!1;if(this.reset(),"bool"in e&&(i=e.bool||i),"expand"in e&&(o=e.expand||o),"fields"in e)for(var r in e.fields)if(n.indexOf(r)>-1){var s=e.fields[r],u=o;void 0!=s.expand&&(u=s.expand),this.config[r]={boost:s.boost||0===s.boost?s.boost:1,bool:s.bool||i,expand:u}}else t.utils.warn("field name in user configuration not found in index instance fields");else this.addAllFields2UserConfig(i,o,n)},t.Configuration.prototype.addAllFields2UserConfig=function(e,t,n){n.forEach(function(n){this.config[n]={boost:1,bool:e,expand:t}},this)},t.Configuration.prototype.get=function(){return this.config},t.Configuration.prototype.reset=function(){this.config={}},lunr.SortedSet=function(){this.length=0,this.elements=[]},lunr.SortedSet.load=function(e){var t=new this;return t.elements=e,t.length=e.length,t},lunr.SortedSet.prototype.add=function(){var e,t;for(e=0;e<arguments.length;e++)t=arguments[e],~this.indexOf(t)||this.elements.splice(this.locationFor(t),0,t);this.length=this.elements.length},lunr.SortedSet.prototype.toArray=function(){return this.elements.slice()},lunr.SortedSet.prototype.map=function(e,t){return this.elements.map(e,t)},lunr.SortedSet.prototype.forEach=function(e,t){return this.elements.forEach(e,t)},lunr.SortedSet.prototype.indexOf=function(e){for(var t=0,n=this.elements.length,i=n-t,o=t+Math.floor(i/2),r=this.elements[o];i>1;){if(r===e)return o;e>r&&(t=o),r>e&&(n=o),i=n-t,o=t+Math.floor(i/2),r=this.elements[o]}return r===e?o:-1},lunr.SortedSet.prototype.locationFor=function(e){for(var t=0,n=this.elements.length,i=n-t,o=t+Math.floor(i/2),r=this.elements[o];i>1;)e>r&&(t=o),r>e&&(n=o),i=n-t,o=t+Math.floor(i/2),r=this.elements[o];return r>e?o:e>r?o+1:void 0},lunr.SortedSet.prototype.intersect=function(e){for(var t=new lunr.SortedSet,n=0,i=0,o=this.length,r=e.length,s=this.elements,u=e.elements;;){if(n>o-1||i>r-1)break;s[n]!==u[i]?s[n]<u[i]?n++:s[n]>u[i]&&i++:(t.add(s[n]),n++,i++)}return t},lunr.SortedSet.prototype.clone=function(){var e=new lunr.SortedSet;return e.elements=this.toArray(),e.length=e.elements.length,e},lunr.SortedSet.prototype.union=function(e){var t,n,i;this.length>=e.length?(t=this,n=e):(t=e,n=this),i=t.clone();for(var o=0,r=n.toArray();o<r.length;o++)i.add(r[o]);return i},lunr.SortedSet.prototype.toJSON=function(){return this.toArray()},function(e,t){"function"==typeof define&&define.amd?define(t):"object"==typeof exports?module.exports=t():e.elasticlunr=t()}(this,function(){return t})}();
    /** pdoc search index */const docs = [{"fullname": "pydaptivefiltering", "modulename": "pydaptivefiltering", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "pydaptivefiltering.AdaptiveFilter", "modulename": "pydaptivefiltering", "qualname": "AdaptiveFilter", "kind": "class", "doc": "<p>Abstract base class for all adaptive filters.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>filter_order:\n    Order in the FIR sense (number of taps - 1). For non-FIR structures, it can be used\n    as a generic size indicator for base allocation.\nw_init:\n    Initial coefficient vector. If None, initialized to zeros.</p>\n\n<h2 id=\"notes\">Notes</h2>\n\n<ul>\n<li>Subclasses should set <code>supports_complex = True</code> if they support complex-valued data.</li>\n<li>Subclasses are expected to call <code>_record_history()</code> every iteration (or use helper methods)\nif they want coefficient trajectories.</li>\n</ul>\n", "bases": "abc.ABC"}, {"fullname": "pydaptivefiltering.AdaptiveFilter.supports_complex", "modulename": "pydaptivefiltering", "qualname": "AdaptiveFilter.supports_complex", "kind": "variable", "doc": "<p></p>\n", "annotation": ": bool", "default_value": "False"}, {"fullname": "pydaptivefiltering.AdaptiveFilter.filter_order", "modulename": "pydaptivefiltering", "qualname": "AdaptiveFilter.filter_order", "kind": "variable", "doc": "<p></p>\n", "annotation": ": int"}, {"fullname": "pydaptivefiltering.AdaptiveFilter.regressor", "modulename": "pydaptivefiltering", "qualname": "AdaptiveFilter.regressor", "kind": "variable", "doc": "<p></p>\n", "annotation": ": numpy.ndarray"}, {"fullname": "pydaptivefiltering.AdaptiveFilter.w_history", "modulename": "pydaptivefiltering", "qualname": "AdaptiveFilter.w_history", "kind": "variable", "doc": "<p></p>\n", "annotation": ": List[numpy.ndarray]"}, {"fullname": "pydaptivefiltering.AdaptiveFilter.filter_signal", "modulename": "pydaptivefiltering", "qualname": "AdaptiveFilter.filter_signal", "kind": "function", "doc": "<p>Filter an input signal using current coefficients.</p>\n\n<p>Default implementation assumes an FIR structure with taps <code>self.w</code> and\nregressor convention:\n    x_k = [x[k], x[k-1], ..., x[k-m]]\nand output:\n    y[k] = w^H x_k   (Hermitian for complex)</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">input_signal</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span><span class=\"p\">,</span> <span class=\"n\">Sequence</span><span class=\"p\">[</span><span class=\"nb\">float</span><span class=\"p\">],</span> <span class=\"n\">Sequence</span><span class=\"p\">[</span><span class=\"nb\">complex</span><span class=\"p\">]]</span></span><span class=\"return-annotation\">) -> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span>:</span></span>", "funcdef": "def"}, {"fullname": "pydaptivefiltering.AdaptiveFilter.default_test_init_kwargs", "modulename": "pydaptivefiltering", "qualname": "AdaptiveFilter.default_test_init_kwargs", "kind": "function", "doc": "<p>Override in subclasses to provide init kwargs for standardized tests.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">cls</span>, </span><span class=\"param\"><span class=\"n\">order</span><span class=\"p\">:</span> <span class=\"nb\">int</span></span><span class=\"return-annotation\">) -> <span class=\"nb\">dict</span>:</span></span>", "funcdef": "def"}, {"fullname": "pydaptivefiltering.AdaptiveFilter.optimize", "modulename": "pydaptivefiltering", "qualname": "AdaptiveFilter.optimize", "kind": "function", "doc": "<p>Run the adaptation procedure.</p>\n\n<p>Subclasses should return either:</p>\n\n<ul>\n<li>OptimizationResult (recommended), or</li>\n<li>dict-like with standardized keys, if you are migrating older code.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">input_signal</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span><span class=\"p\">,</span> <span class=\"n\">Sequence</span><span class=\"p\">[</span><span class=\"nb\">float</span><span class=\"p\">],</span> <span class=\"n\">Sequence</span><span class=\"p\">[</span><span class=\"nb\">complex</span><span class=\"p\">]]</span>,</span><span class=\"param\">\t<span class=\"n\">desired_signal</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span><span class=\"p\">,</span> <span class=\"n\">Sequence</span><span class=\"p\">[</span><span class=\"nb\">float</span><span class=\"p\">],</span> <span class=\"n\">Sequence</span><span class=\"p\">[</span><span class=\"nb\">complex</span><span class=\"p\">]]</span>,</span><span class=\"param\">\t<span class=\"o\">**</span><span class=\"n\">kwargs</span><span class=\"p\">:</span> <span class=\"n\">Any</span></span><span class=\"return-annotation\">) -> <span class=\"n\">Any</span>:</span></span>", "funcdef": "def"}, {"fullname": "pydaptivefiltering.AdaptiveFilter.reset_filter", "modulename": "pydaptivefiltering", "qualname": "AdaptiveFilter.reset_filter", "kind": "function", "doc": "<p>Reset coefficients and history.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">w_new</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span><span class=\"p\">,</span> <span class=\"n\">Sequence</span><span class=\"p\">[</span><span class=\"nb\">float</span><span class=\"p\">],</span> <span class=\"n\">Sequence</span><span class=\"p\">[</span><span class=\"nb\">complex</span><span class=\"p\">],</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span><span class=\"return-annotation\">) -> <span class=\"kc\">None</span>:</span></span>", "funcdef": "def"}, {"fullname": "pydaptivefiltering.LMS", "modulename": "pydaptivefiltering", "qualname": "LMS", "kind": "class", "doc": "<p>Complex LMS (Least-Mean Squares).</p>\n\n<p>Implements the complex LMS recursion (Algorithm 3.2 - Diniz) for adaptive FIR\nfiltering.</p>\n\n<h2 id=\"notes\">Notes</h2>\n\n<ul>\n<li>Complex-valued implementation (supports_complex = True).</li>\n<li>Uses the unified base API via <code>@validate_input</code>:\n<ul>\n<li>optimize(input_signal=..., desired_signal=...)</li>\n<li>optimize(x=..., d=...)</li>\n<li>optimize(x, d)</li>\n</ul></li>\n<li>This implementation returns the a priori error: e[k] = d[k] - y[k] where\ny[k] = w[k]^H x_k, and then updates:\n    w[k+1] = w[k] + mu * conj(e[k]) * x_k</li>\n</ul>\n", "bases": "pydaptivefiltering.base.AdaptiveFilter"}, {"fullname": "pydaptivefiltering.LMS.__init__", "modulename": "pydaptivefiltering", "qualname": "LMS.__init__", "kind": "function", "doc": "<h2 id=\"parameters\">Parameters</h2>\n\n<p>filter_order:\n    FIR order M (number of taps is M+1).\nstep_size:\n    Step-size (mu).\nw_init:\n    Optional initial coefficients (length M+1). If None, zeros.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">filter_order</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">step_size</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">0.01</span>,</span><span class=\"param\">\t<span class=\"n\">w_init</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span><span class=\"p\">,</span> <span class=\"nb\">list</span><span class=\"p\">,</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span>)</span>"}, {"fullname": "pydaptivefiltering.LMS.supports_complex", "modulename": "pydaptivefiltering", "qualname": "LMS.supports_complex", "kind": "variable", "doc": "<p></p>\n", "annotation": ": bool", "default_value": "True"}, {"fullname": "pydaptivefiltering.LMS.step_size", "modulename": "pydaptivefiltering", "qualname": "LMS.step_size", "kind": "variable", "doc": "<p></p>\n", "annotation": ": float"}, {"fullname": "pydaptivefiltering.LMS.optimize", "modulename": "pydaptivefiltering", "qualname": "LMS.optimize", "kind": "function", "doc": "<p>Run LMS adaptation.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>input_signal:\n    Input signal x[k].\ndesired_signal:\n    Desired signal d[k].\nverbose:\n    If True, prints runtime.</p>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>OptimizationResult\n    outputs:\n        Filter output y[k].\n    errors:\n        A priori error e[k] = d[k] - y[k].\n    coefficients:\n        History of coefficients stored in the base class.\n    error_type:\n        \"a_priori\".</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">input_signal</span><span class=\"p\">:</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span>,</span><span class=\"param\">\t<span class=\"n\">desired_signal</span><span class=\"p\">:</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span>,</span><span class=\"param\">\t<span class=\"n\">verbose</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span></span><span class=\"return-annotation\">) -> <span class=\"n\">pydaptivefiltering</span><span class=\"o\">.</span><span class=\"n\">base</span><span class=\"o\">.</span><span class=\"n\">OptimizationResult</span>:</span></span>", "funcdef": "def"}, {"fullname": "pydaptivefiltering.NLMS", "modulename": "pydaptivefiltering", "qualname": "NLMS", "kind": "class", "doc": "<p>Complex NLMS (Normalized Least-Mean Squares).</p>\n\n<p>Implements the normalized LMS recursion (Algorithm 4.3 - Diniz) for adaptive\nFIR filtering. The update uses a step normalized by the regressor energy:</p>\n\n<pre><code>y[k] = w[k]^H x_k\ne[k] = d[k] - y[k]\nmu_k = mu / (||x_k||^2 + gamma)\nw[k+1] = w[k] + mu_k * conj(e[k]) * x_k\n</code></pre>\n\n<h2 id=\"notes\">Notes</h2>\n\n<ul>\n<li>Complex-valued implementation (supports_complex = True).</li>\n<li>Uses the unified base API via <code>@validate_input</code>.</li>\n<li><code>gamma</code> is a regularization constant to avoid division by zero.</li>\n</ul>\n", "bases": "pydaptivefiltering.base.AdaptiveFilter"}, {"fullname": "pydaptivefiltering.NLMS.__init__", "modulename": "pydaptivefiltering", "qualname": "NLMS.__init__", "kind": "function", "doc": "<h2 id=\"parameters\">Parameters</h2>\n\n<p>filter_order:\n    FIR order M (number of taps is M+1).\nstep_size:\n    Base step-size (mu).\ngamma:\n    Regularization to avoid division by (near) zero.\nw_init:\n    Optional initial coefficients (length M+1). If None, zeros.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">filter_order</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">step_size</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">0.01</span>,</span><span class=\"param\">\t<span class=\"n\">gamma</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">1e-06</span>,</span><span class=\"param\">\t<span class=\"n\">w_init</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span><span class=\"p\">,</span> <span class=\"nb\">list</span><span class=\"p\">,</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span>)</span>"}, {"fullname": "pydaptivefiltering.NLMS.supports_complex", "modulename": "pydaptivefiltering", "qualname": "NLMS.supports_complex", "kind": "variable", "doc": "<p></p>\n", "annotation": ": bool", "default_value": "True"}, {"fullname": "pydaptivefiltering.NLMS.step_size", "modulename": "pydaptivefiltering", "qualname": "NLMS.step_size", "kind": "variable", "doc": "<p></p>\n", "annotation": ": float"}, {"fullname": "pydaptivefiltering.NLMS.gamma", "modulename": "pydaptivefiltering", "qualname": "NLMS.gamma", "kind": "variable", "doc": "<p></p>\n", "annotation": ": float"}, {"fullname": "pydaptivefiltering.NLMS.optimize", "modulename": "pydaptivefiltering", "qualname": "NLMS.optimize", "kind": "function", "doc": "<p>Run NLMS adaptation.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>input_signal:\n    Input signal x[k].\ndesired_signal:\n    Desired signal d[k].\nverbose:\n    If True, prints runtime.</p>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>OptimizationResult\n    outputs:\n        Filter output y[k].\n    errors:\n        A priori error e[k] = d[k] - y[k].\n    coefficients:\n        History of coefficients stored in the base class.\n    error_type:\n        \"a_priori\".</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">input_signal</span><span class=\"p\">:</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span>,</span><span class=\"param\">\t<span class=\"n\">desired_signal</span><span class=\"p\">:</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span>,</span><span class=\"param\">\t<span class=\"n\">verbose</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span></span><span class=\"return-annotation\">) -> <span class=\"n\">pydaptivefiltering</span><span class=\"o\">.</span><span class=\"n\">base</span><span class=\"o\">.</span><span class=\"n\">OptimizationResult</span>:</span></span>", "funcdef": "def"}, {"fullname": "pydaptivefiltering.AffineProjection", "modulename": "pydaptivefiltering", "qualname": "AffineProjection", "kind": "class", "doc": "<p>Complex Affine Projection Algorithm (APA).</p>\n\n<p>Implements Algorithm 4.6 (Diniz) using an affine-projection update with data reuse.</p>\n\n<h2 id=\"notes\">Notes</h2>\n\n<ul>\n<li>This implementation supports complex-valued data (supports_complex=True).</li>\n<li>The base decorator <code>@validate_input</code> allows calling optimize with:\n<ul>\n<li>optimize(input_signal=..., desired_signal=...)</li>\n<li>optimize(x=..., d=...)</li>\n<li>optimize(x, d)</li>\n</ul></li>\n</ul>\n", "bases": "pydaptivefiltering.base.AdaptiveFilter"}, {"fullname": "pydaptivefiltering.AffineProjection.__init__", "modulename": "pydaptivefiltering", "qualname": "AffineProjection.__init__", "kind": "function", "doc": "<h2 id=\"parameters\">Parameters</h2>\n\n<p>filter_order:\n    FIR order M (number of taps is M+1).\nstep_size:\n    Step-size / relaxation factor (mu).\ngamma:\n    Diagonal loading regularization to ensure invertibility.\nL:\n    Data reuse factor (projection order). Uses L+1 past regressors.\nw_init:\n    Optional initial weights (length M+1). If None, initializes to zeros.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">filter_order</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">step_size</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">0.01</span>,</span><span class=\"param\">\t<span class=\"n\">gamma</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">1e-06</span>,</span><span class=\"param\">\t<span class=\"n\">L</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">2</span>,</span><span class=\"param\">\t<span class=\"n\">w_init</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span><span class=\"p\">,</span> <span class=\"nb\">list</span><span class=\"p\">,</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span>)</span>"}, {"fullname": "pydaptivefiltering.AffineProjection.supports_complex", "modulename": "pydaptivefiltering", "qualname": "AffineProjection.supports_complex", "kind": "variable", "doc": "<p></p>\n", "annotation": ": bool", "default_value": "True"}, {"fullname": "pydaptivefiltering.AffineProjection.step_size", "modulename": "pydaptivefiltering", "qualname": "AffineProjection.step_size", "kind": "variable", "doc": "<p></p>\n", "annotation": ": float"}, {"fullname": "pydaptivefiltering.AffineProjection.gamma", "modulename": "pydaptivefiltering", "qualname": "AffineProjection.gamma", "kind": "variable", "doc": "<p></p>\n", "annotation": ": float"}, {"fullname": "pydaptivefiltering.AffineProjection.memory_length", "modulename": "pydaptivefiltering", "qualname": "AffineProjection.memory_length", "kind": "variable", "doc": "<p></p>\n", "annotation": ": int"}, {"fullname": "pydaptivefiltering.AffineProjection.optimize", "modulename": "pydaptivefiltering", "qualname": "AffineProjection.optimize", "kind": "function", "doc": "<p>Run APA adaptation.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>input_signal:\n    Input signal x[k].\ndesired_signal:\n    Desired signal d[k].\nverbose:\n    If True, prints runtime.\nreturn_internal_states:\n    If True, returns the last regressor matrix and last correlation matrix in result.extra.</p>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>OptimizationResult\n    outputs:\n        Filter output y[k] (a priori).\n    errors:\n        Error e[k] = d[k] - y[k] (a priori).\n    coefficients:\n        Coefficient history (self.w_history) as a 2D array.\n    error_type:\n        \"a_priori\".\n    extra (optional):\n        last_regressor_matrix, last_correlation_matrix.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">input_signal</span><span class=\"p\">:</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span>,</span><span class=\"param\">\t<span class=\"n\">desired_signal</span><span class=\"p\">:</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span>,</span><span class=\"param\">\t<span class=\"n\">verbose</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">return_internal_states</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span></span><span class=\"return-annotation\">) -> <span class=\"n\">pydaptivefiltering</span><span class=\"o\">.</span><span class=\"n\">base</span><span class=\"o\">.</span><span class=\"n\">OptimizationResult</span>:</span></span>", "funcdef": "def"}, {"fullname": "pydaptivefiltering.SignData", "modulename": "pydaptivefiltering", "qualname": "SignData", "kind": "class", "doc": "<p>Sign-Data LMS (complex-valued).</p>\n\n<p>This is a low-complexity LMS variant where the input regressor is replaced by\nits elementwise sign:</p>\n\n<pre><code>y[k] = w^H x_k\ne[k] = d[k] - y[k]\nw &lt;- w + 2 * mu * conj(e[k]) * sign(x_k)\n</code></pre>\n\n<h2 id=\"notes\">Notes</h2>\n\n<ul>\n<li>Complex-valued implementation (supports_complex=True).</li>\n<li>Uses the unified base API via <code>@validate_input</code>.</li>\n<li>Returns a priori error by default (e[k] computed before update).</li>\n</ul>\n", "bases": "pydaptivefiltering.base.AdaptiveFilter"}, {"fullname": "pydaptivefiltering.SignData.__init__", "modulename": "pydaptivefiltering", "qualname": "SignData.__init__", "kind": "function", "doc": "<h2 id=\"parameters\">Parameters</h2>\n\n<p>filter_order:\n    FIR order M (number of taps is M+1).\nstep_size:\n    Step-size (mu).\nw_init:\n    Optional initial coefficients (length M+1). If None, zeros.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">filter_order</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">step_size</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">0.01</span>,</span><span class=\"param\">\t<span class=\"n\">w_init</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span><span class=\"p\">,</span> <span class=\"nb\">list</span><span class=\"p\">,</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span>)</span>"}, {"fullname": "pydaptivefiltering.SignData.supports_complex", "modulename": "pydaptivefiltering", "qualname": "SignData.supports_complex", "kind": "variable", "doc": "<p></p>\n", "annotation": ": bool", "default_value": "True"}, {"fullname": "pydaptivefiltering.SignData.step_size", "modulename": "pydaptivefiltering", "qualname": "SignData.step_size", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pydaptivefiltering.SignData.optimize", "modulename": "pydaptivefiltering", "qualname": "SignData.optimize", "kind": "function", "doc": "<p>Run Sign-Data LMS adaptation.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>input_signal:\n    Input signal x[k].\ndesired_signal:\n    Desired signal d[k].\nverbose:\n    If True, prints runtime.\nreturn_internal_states:\n    If True, returns the last regressor sign vector in result.extra.</p>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>OptimizationResult\n    outputs:\n        Filter output y[k].\n    errors:\n        A priori error e[k] = d[k] - y[k].\n    coefficients:\n        Coefficient history stored in the base class.\n    error_type:\n        \"a_priori\".</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">input_signal</span><span class=\"p\">:</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span>,</span><span class=\"param\">\t<span class=\"n\">desired_signal</span><span class=\"p\">:</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span>,</span><span class=\"param\">\t<span class=\"n\">verbose</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">return_internal_states</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span></span><span class=\"return-annotation\">) -> <span class=\"n\">pydaptivefiltering</span><span class=\"o\">.</span><span class=\"n\">base</span><span class=\"o\">.</span><span class=\"n\">OptimizationResult</span>:</span></span>", "funcdef": "def"}, {"fullname": "pydaptivefiltering.SignError", "modulename": "pydaptivefiltering", "qualname": "SignError", "kind": "class", "doc": "<p>Sign-Error LMS (real-valued).</p>\n\n<p>This is a sign-error LMS variant that replaces the error term by its sign:</p>\n\n<pre><code>y[k] = w^T x_k\ne[k] = d[k] - y[k]\nw &lt;- w + mu * sign(e[k]) * x_k\n</code></pre>\n\n<h2 id=\"notes\">Notes</h2>\n\n<ul>\n<li>Real-valued only: enforced by <code>ensure_real_signals</code>.</li>\n<li>Uses the unified base API via <code>validate_input</code>.</li>\n<li>Returns a priori error (computed before update).</li>\n</ul>\n", "bases": "pydaptivefiltering.base.AdaptiveFilter"}, {"fullname": "pydaptivefiltering.SignError.__init__", "modulename": "pydaptivefiltering", "qualname": "SignError.__init__", "kind": "function", "doc": "<h2 id=\"parameters\">Parameters</h2>\n\n<p>filter_order:\n    FIR order M (number of taps is M+1).\nstep_size:\n    Step-size (mu).\nw_init:\n    Optional initial coefficients (length M+1). If None, zeros.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">filter_order</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">step_size</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">0.01</span>,</span><span class=\"param\">\t<span class=\"n\">w_init</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span><span class=\"p\">,</span> <span class=\"nb\">list</span><span class=\"p\">,</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span>)</span>"}, {"fullname": "pydaptivefiltering.SignError.supports_complex", "modulename": "pydaptivefiltering", "qualname": "SignError.supports_complex", "kind": "variable", "doc": "<p></p>\n", "annotation": ": bool", "default_value": "False"}, {"fullname": "pydaptivefiltering.SignError.step_size", "modulename": "pydaptivefiltering", "qualname": "SignError.step_size", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pydaptivefiltering.SignError.optimize", "modulename": "pydaptivefiltering", "qualname": "SignError.optimize", "kind": "function", "doc": "<p>Run Sign-Error LMS adaptation.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>input_signal:\n    Input signal x[k] (real).\ndesired_signal:\n    Desired signal d[k] (real).\nverbose:\n    If True, prints runtime.\nreturn_internal_states:\n    If True, returns the last sign(e[k]) value in result.extra.</p>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>OptimizationResult\n    outputs:\n        Filter output y[k].\n    errors:\n        A priori error e[k] = d[k] - y[k].\n    coefficients:\n        Coefficient history stored in the base class.\n    error_type:\n        \"a_priori\".</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">input_signal</span><span class=\"p\">:</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span>,</span><span class=\"param\">\t<span class=\"n\">desired_signal</span><span class=\"p\">:</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span>,</span><span class=\"param\">\t<span class=\"n\">verbose</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">return_internal_states</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span></span><span class=\"return-annotation\">) -> <span class=\"n\">pydaptivefiltering</span><span class=\"o\">.</span><span class=\"n\">base</span><span class=\"o\">.</span><span class=\"n\">OptimizationResult</span>:</span></span>", "funcdef": "def"}, {"fullname": "pydaptivefiltering.DualSign", "modulename": "pydaptivefiltering", "qualname": "DualSign", "kind": "class", "doc": "<p>DualSign LMS (real-valued).</p>\n\n<p>This is a sign-error LMS variant that switches between two effective gains\ndepending on the error magnitude, controlled by a threshold <code>rho</code>.</p>\n\n<h2 id=\"notes\">Notes</h2>\n\n<ul>\n<li>Real-valued only: enforced by <code>@ensure_real_signals</code>.</li>\n<li>Uses the unified base API via <code>@validate_input</code>:\n<ul>\n<li>optimize(input_signal=..., desired_signal=...)</li>\n<li>optimize(x=..., d=...)</li>\n<li>optimize(x, d)</li>\n</ul></li>\n</ul>\n\n<h2 id=\"update-rule-one-common-form\">Update rule (one common form)</h2>\n\n<pre><code>e[k] = d[k] - y[k]\nu[k] = sign(e[k])              if |e[k]| &lt;= rho\n     = gamma * sign(e[k])      if |e[k]| &gt;  rho\nw &lt;- w + 2 * mu * u[k] * x_k\n</code></pre>\n", "bases": "pydaptivefiltering.base.AdaptiveFilter"}, {"fullname": "pydaptivefiltering.DualSign.__init__", "modulename": "pydaptivefiltering", "qualname": "DualSign.__init__", "kind": "function", "doc": "<h2 id=\"parameters\">Parameters</h2>\n\n<p>filter_order:\n    FIR order M (number of taps is M+1).\nrho:\n    Threshold on |e[k]| that selects which sign gain is used.\ngamma:\n    Gain multiplier used when |e[k]| &gt; rho. Typically an integer &gt; 1.\nstep:\n    Step-size (mu).\nw_init:\n    Optional initial coefficients (length M+1). If None, zeros.\nsafe_eps:\n    Small epsilon for internal safety checks (kept for consistency across the library).</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">filter_order</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">rho</span><span class=\"p\">:</span> <span class=\"nb\">float</span>,</span><span class=\"param\">\t<span class=\"n\">gamma</span><span class=\"p\">:</span> <span class=\"nb\">float</span>,</span><span class=\"param\">\t<span class=\"n\">step</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">0.01</span>,</span><span class=\"param\">\t<span class=\"n\">w_init</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span><span class=\"p\">,</span> <span class=\"nb\">list</span><span class=\"p\">,</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"o\">*</span>,</span><span class=\"param\">\t<span class=\"n\">safe_eps</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">1e-12</span></span>)</span>"}, {"fullname": "pydaptivefiltering.DualSign.supports_complex", "modulename": "pydaptivefiltering", "qualname": "DualSign.supports_complex", "kind": "variable", "doc": "<p></p>\n", "annotation": ": bool", "default_value": "False"}, {"fullname": "pydaptivefiltering.DualSign.rho", "modulename": "pydaptivefiltering", "qualname": "DualSign.rho", "kind": "variable", "doc": "<p></p>\n", "annotation": ": float"}, {"fullname": "pydaptivefiltering.DualSign.gamma", "modulename": "pydaptivefiltering", "qualname": "DualSign.gamma", "kind": "variable", "doc": "<p></p>\n", "annotation": ": float"}, {"fullname": "pydaptivefiltering.DualSign.step_size", "modulename": "pydaptivefiltering", "qualname": "DualSign.step_size", "kind": "variable", "doc": "<p></p>\n", "annotation": ": float"}, {"fullname": "pydaptivefiltering.DualSign.optimize", "modulename": "pydaptivefiltering", "qualname": "DualSign.optimize", "kind": "function", "doc": "<p>Run DualSign LMS adaptation.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>input_signal:\n    Input signal x[k] (real).\ndesired_signal:\n    Desired signal d[k] (real).\nverbose:\n    If True, prints runtime.</p>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>OptimizationResult\n    outputs:\n        Filter output y[k].\n    errors:\n        A priori error e[k] = d[k] - y[k].\n    coefficients:\n        Coefficient history stored in the base class.\n    error_type:\n        \"a_priori\".</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">input_signal</span><span class=\"p\">:</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span>,</span><span class=\"param\">\t<span class=\"n\">desired_signal</span><span class=\"p\">:</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span>,</span><span class=\"param\">\t<span class=\"n\">verbose</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span></span><span class=\"return-annotation\">) -> <span class=\"n\">pydaptivefiltering</span><span class=\"o\">.</span><span class=\"n\">base</span><span class=\"o\">.</span><span class=\"n\">OptimizationResult</span>:</span></span>", "funcdef": "def"}, {"fullname": "pydaptivefiltering.LMSNewton", "modulename": "pydaptivefiltering", "qualname": "LMSNewton", "kind": "class", "doc": "<p>LMS-Newton (complex-valued).</p>\n\n<p>This algorithm approximates a Newton step by maintaining a recursive estimate of\nthe inverse input correlation matrix, which tends to accelerate convergence in\ncorrelated-input scenarios.</p>\n\n<h2 id=\"notes\">Notes</h2>\n\n<ul>\n<li>Complex-valued implementation (supports_complex = True).</li>\n<li>Uses the unified base API via <code>@validate_input</code>:\n<ul>\n<li>optimize(input_signal=..., desired_signal=...)</li>\n<li>optimize(x=..., d=...)</li>\n<li>optimize(x, d)</li>\n</ul></li>\n</ul>\n\n<h2 id=\"recursion-one-common-form\">Recursion (one common form)</h2>\n\n<p>Let P[k] approximate R_x^{-1}. With forgetting factor alpha (0 &lt; alpha &lt; 1),\nand regressor x_k (shape (M+1,)), define:</p>\n\n<pre><code>phi = x_k^H P x_k\ndenom = (1-alpha)/alpha + phi\nP &lt;- (P - (P x_k x_k^H P)/denom) / (1-alpha)\nw &lt;- w + mu * conj(e[k]) * (P x_k)\n</code></pre>\n\n<p>where e[k] = d[k] - w^H x_k.</p>\n", "bases": "pydaptivefiltering.base.AdaptiveFilter"}, {"fullname": "pydaptivefiltering.LMSNewton.__init__", "modulename": "pydaptivefiltering", "qualname": "LMSNewton.__init__", "kind": "function", "doc": "<h2 id=\"parameters\">Parameters</h2>\n\n<p>filter_order:\n    FIR order M (number of taps is M+1).\nalpha:\n    Forgetting factor (0 &lt; alpha &lt; 1).\ninitial_inv_rx:\n    Initial inverse correlation matrix P[0], shape (M+1, M+1).\nstep:\n    Step-size mu.\nw_init:\n    Optional initial coefficients (length M+1). If None, zeros.\nsafe_eps:\n    Small epsilon used to guard denominators.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">filter_order</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">alpha</span><span class=\"p\">:</span> <span class=\"nb\">float</span>,</span><span class=\"param\">\t<span class=\"n\">initial_inv_rx</span><span class=\"p\">:</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span>,</span><span class=\"param\">\t<span class=\"n\">step</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">0.01</span>,</span><span class=\"param\">\t<span class=\"n\">w_init</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span><span class=\"p\">,</span> <span class=\"nb\">list</span><span class=\"p\">,</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"o\">*</span>,</span><span class=\"param\">\t<span class=\"n\">safe_eps</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">1e-12</span></span>)</span>"}, {"fullname": "pydaptivefiltering.LMSNewton.supports_complex", "modulename": "pydaptivefiltering", "qualname": "LMSNewton.supports_complex", "kind": "variable", "doc": "<p></p>\n", "annotation": ": bool", "default_value": "True"}, {"fullname": "pydaptivefiltering.LMSNewton.alpha", "modulename": "pydaptivefiltering", "qualname": "LMSNewton.alpha", "kind": "variable", "doc": "<p></p>\n", "annotation": ": float"}, {"fullname": "pydaptivefiltering.LMSNewton.step_size", "modulename": "pydaptivefiltering", "qualname": "LMSNewton.step_size", "kind": "variable", "doc": "<p></p>\n", "annotation": ": float"}, {"fullname": "pydaptivefiltering.LMSNewton.inv_rx", "modulename": "pydaptivefiltering", "qualname": "LMSNewton.inv_rx", "kind": "variable", "doc": "<p></p>\n", "annotation": ": numpy.ndarray"}, {"fullname": "pydaptivefiltering.LMSNewton.optimize", "modulename": "pydaptivefiltering", "qualname": "LMSNewton.optimize", "kind": "function", "doc": "<p>Run LMS-Newton adaptation.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>input_signal:\n    Input signal x[k].\ndesired_signal:\n    Desired signal d[k].\nverbose:\n    If True, prints runtime.</p>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>OptimizationResult\n    outputs:\n        Filter output y[k].\n    errors:\n        A priori error e[k] = d[k] - y[k].\n    coefficients:\n        History of coefficients stored in the base class.\n    error_type:\n        \"a_priori\".</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">input_signal</span><span class=\"p\">:</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span>,</span><span class=\"param\">\t<span class=\"n\">desired_signal</span><span class=\"p\">:</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span>,</span><span class=\"param\">\t<span class=\"n\">verbose</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span></span><span class=\"return-annotation\">) -> <span class=\"n\">pydaptivefiltering</span><span class=\"o\">.</span><span class=\"n\">base</span><span class=\"o\">.</span><span class=\"n\">OptimizationResult</span>:</span></span>", "funcdef": "def"}, {"fullname": "pydaptivefiltering.Power2ErrorLMS", "modulename": "pydaptivefiltering", "qualname": "Power2ErrorLMS", "kind": "class", "doc": "<p>Power-of-Two Error LMS (real-valued).</p>\n\n<p>This is an LMS variant where the instantaneous error is quantized to the nearest\npower-of-two (or special cases), aiming at reducing computational complexity.</p>\n\n<h2 id=\"quantization-rule-as-implemented-here\">Quantization rule (as implemented here)</h2>\n\n<p>Let e be the a priori error.</p>\n\n<ul>\n<li>If |e| &gt;= 1:\nq(e) = sign(e)</li>\n<li>Else if |e| &lt; 2^(-bd+1):\nq(e) = tau * sign(e)</li>\n<li>Else:\nq(e) = 2^{floor(log2(|e|))} * sign(e)</li>\n</ul>\n\n<p>Update:\n    w &lt;- w + 2 * mu * q(e) * x_k</p>\n\n<h2 id=\"notes\">Notes</h2>\n\n<ul>\n<li>Real-valued only: enforced by <code>ensure_real_signals</code>.</li>\n<li>Uses the unified base API via <code>validate_input</code>.</li>\n</ul>\n", "bases": "pydaptivefiltering.base.AdaptiveFilter"}, {"fullname": "pydaptivefiltering.Power2ErrorLMS.__init__", "modulename": "pydaptivefiltering", "qualname": "Power2ErrorLMS.__init__", "kind": "function", "doc": "<h2 id=\"parameters\">Parameters</h2>\n\n<p>filter_order:\n    FIR order M (number of taps is M+1).\nbd:\n    Word length (signal bits) used in the small-error threshold 2^(-bd+1).\ntau:\n    Gain factor used when |e| is very small (&lt; 2^(-bd+1)).\nstep_size:\n    Step-size (mu).\nw_init:\n    Optional initial coefficients (length M+1). If None, zeros.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">filter_order</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">bd</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">tau</span><span class=\"p\">:</span> <span class=\"nb\">float</span>,</span><span class=\"param\">\t<span class=\"n\">step_size</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">0.01</span>,</span><span class=\"param\">\t<span class=\"n\">w_init</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span><span class=\"p\">,</span> <span class=\"nb\">list</span><span class=\"p\">,</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span>)</span>"}, {"fullname": "pydaptivefiltering.Power2ErrorLMS.supports_complex", "modulename": "pydaptivefiltering", "qualname": "Power2ErrorLMS.supports_complex", "kind": "variable", "doc": "<p></p>\n", "annotation": ": bool", "default_value": "False"}, {"fullname": "pydaptivefiltering.Power2ErrorLMS.bd", "modulename": "pydaptivefiltering", "qualname": "Power2ErrorLMS.bd", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pydaptivefiltering.Power2ErrorLMS.tau", "modulename": "pydaptivefiltering", "qualname": "Power2ErrorLMS.tau", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pydaptivefiltering.Power2ErrorLMS.step_size", "modulename": "pydaptivefiltering", "qualname": "Power2ErrorLMS.step_size", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pydaptivefiltering.Power2ErrorLMS.optimize", "modulename": "pydaptivefiltering", "qualname": "Power2ErrorLMS.optimize", "kind": "function", "doc": "<p>Run Power-of-Two Error LMS adaptation.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>input_signal:\n    Input signal x[k] (real).\ndesired_signal:\n    Desired signal d[k] (real).\nverbose:\n    If True, prints runtime.\nreturn_internal_states:\n    If True, returns the last quantized error value in result.extra.</p>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>OptimizationResult\n    outputs:\n        Filter output outputs[k].\n    errors:\n        A priori error errors[k] = d[k] - outputs[k].\n    coefficients:\n        History of coefficients stored in the base class.\n    error_type:\n        \"a_priori\".</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">input_signal</span><span class=\"p\">:</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span>,</span><span class=\"param\">\t<span class=\"n\">desired_signal</span><span class=\"p\">:</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span>,</span><span class=\"param\">\t<span class=\"n\">verbose</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">return_internal_states</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span></span><span class=\"return-annotation\">) -> <span class=\"n\">pydaptivefiltering</span><span class=\"o\">.</span><span class=\"n\">base</span><span class=\"o\">.</span><span class=\"n\">OptimizationResult</span>:</span></span>", "funcdef": "def"}, {"fullname": "pydaptivefiltering.TDomainLMS", "modulename": "pydaptivefiltering", "qualname": "TDomainLMS", "kind": "class", "doc": "<p>Generic Transform-Domain LMS using a user-provided unitary transform matrix T.</p>\n\n<p>This is a transform-domain LMS variant (Algorithm 4.4 - Diniz). Given a transform\nz_k = T x_k and transform-domain weights w_T, the recursion is:</p>\n\n<pre><code>y[k] = w_T^H z_k\ne[k] = d[k] - y[k]\nP_z[k] = alpha * |z_k|^2 + (1-alpha) * P_z[k-1]\nw_T &lt;- w_T + mu * conj(e[k]) * z_k / (gamma + P_z[k])\n</code></pre>\n\n<p>For library consistency, this implementation also exposes time-domain weights:</p>\n\n<pre><code>w_time = T^H w_T\n</code></pre>\n\n<h2 id=\"notes\">Notes</h2>\n\n<ul>\n<li>Complex-valued implementation (<code>supports_complex=True</code>).</li>\n<li><code>OptimizationResult.coefficients</code> stores time-domain coefficient history (self.w_history).</li>\n<li>Transform-domain coefficient history is returned in <code>result.extra[\"coefficients_transform\"]</code>\nwhen requested.</li>\n<li><code>transform_matrix</code> is expected to be unitary (T^H T = I). If it is not, the mapping\nback to time domain is not the true inverse transform.</li>\n</ul>\n", "bases": "pydaptivefiltering.base.AdaptiveFilter"}, {"fullname": "pydaptivefiltering.TDomainLMS.__init__", "modulename": "pydaptivefiltering", "qualname": "TDomainLMS.__init__", "kind": "function", "doc": "<h2 id=\"parameters\">Parameters</h2>\n\n<p>filter_order:\n    FIR order M (number of taps is M+1). Transform size must be (M+1, M+1).\ngamma:\n    Small positive constant to avoid division by (near) zero in each bin.\nalpha:\n    Smoothing factor for power estimation (typically close to 1).\ninitial_power:\n    Initial power estimate for all transform bins.\ntransform_matrix:\n    Transform matrix T of shape (M+1, M+1). Typically unitary.\nstep_size:\n    Step-size (mu).\nw_init:\n    Optional initial coefficients in time domain (length M+1). If None, zeros.\nassume_unitary:\n    If True, uses w_time = T^H w_T. If False, uses a least-squares mapping\n    w_time = pinv(T)^H w_T (slower, but works for non-unitary transforms).</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">filter_order</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">gamma</span><span class=\"p\">:</span> <span class=\"nb\">float</span>,</span><span class=\"param\">\t<span class=\"n\">alpha</span><span class=\"p\">:</span> <span class=\"nb\">float</span>,</span><span class=\"param\">\t<span class=\"n\">initial_power</span><span class=\"p\">:</span> <span class=\"nb\">float</span>,</span><span class=\"param\">\t<span class=\"n\">transform_matrix</span><span class=\"p\">:</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span>,</span><span class=\"param\">\t<span class=\"n\">step_size</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">0.01</span>,</span><span class=\"param\">\t<span class=\"n\">w_init</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span><span class=\"p\">,</span> <span class=\"nb\">list</span><span class=\"p\">,</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"o\">*</span>,</span><span class=\"param\">\t<span class=\"n\">assume_unitary</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">True</span></span>)</span>"}, {"fullname": "pydaptivefiltering.TDomainLMS.supports_complex", "modulename": "pydaptivefiltering", "qualname": "TDomainLMS.supports_complex", "kind": "variable", "doc": "<p></p>\n", "annotation": ": bool", "default_value": "True"}, {"fullname": "pydaptivefiltering.TDomainLMS.gamma", "modulename": "pydaptivefiltering", "qualname": "TDomainLMS.gamma", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pydaptivefiltering.TDomainLMS.alpha", "modulename": "pydaptivefiltering", "qualname": "TDomainLMS.alpha", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pydaptivefiltering.TDomainLMS.step_size", "modulename": "pydaptivefiltering", "qualname": "TDomainLMS.step_size", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pydaptivefiltering.TDomainLMS.N", "modulename": "pydaptivefiltering", "qualname": "TDomainLMS.N", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pydaptivefiltering.TDomainLMS.T", "modulename": "pydaptivefiltering", "qualname": "TDomainLMS.T", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pydaptivefiltering.TDomainLMS.w_T", "modulename": "pydaptivefiltering", "qualname": "TDomainLMS.w_T", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pydaptivefiltering.TDomainLMS.power_vector", "modulename": "pydaptivefiltering", "qualname": "TDomainLMS.power_vector", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pydaptivefiltering.TDomainLMS.optimize", "modulename": "pydaptivefiltering", "qualname": "TDomainLMS.optimize", "kind": "function", "doc": "<p>Run Transform-Domain LMS adaptation.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>input_signal:\n    Input signal x[k].\ndesired_signal:\n    Desired signal d[k].\nverbose:\n    If True, prints runtime.\nreturn_internal_states:\n    If True, returns transform-domain coefficient history and final power vector in result.extra.</p>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>OptimizationResult\n    outputs:\n        Filter output y[k] (a priori).\n    errors:\n        A priori error e[k] = d[k] - y[k].\n    coefficients:\n        Time-domain coefficient history stored in the base class.\n    error_type:\n        \"a_priori\".</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">input_signal</span><span class=\"p\">:</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span>,</span><span class=\"param\">\t<span class=\"n\">desired_signal</span><span class=\"p\">:</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span>,</span><span class=\"param\">\t<span class=\"n\">verbose</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">return_internal_states</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span></span><span class=\"return-annotation\">) -> <span class=\"n\">pydaptivefiltering</span><span class=\"o\">.</span><span class=\"n\">base</span><span class=\"o\">.</span><span class=\"n\">OptimizationResult</span>:</span></span>", "funcdef": "def"}, {"fullname": "pydaptivefiltering.TDomainDCT", "modulename": "pydaptivefiltering", "qualname": "TDomainDCT", "kind": "class", "doc": "<p>Transform-Domain LMS using a DCT matrix (complex-valued).</p>\n\n<p>Implements the Transform-Domain LMS recursion (Algorithm 4.4 - Diniz),\nwhere the regressor is transformed via an orthonormal DCT:</p>\n\n<pre><code>z_k = T x_k\ny[k] = w_z^H z_k\ne[k] = d[k] - y[k]\nP_z[k] = alpha * |z_k|^2 + (1-alpha) * P_z[k-1]\nw_z &lt;- w_z + mu * conj(e[k]) * z_k / (gamma + P_z[k])\n</code></pre>\n\n<p>Then the time-domain coefficients are recovered by:\n    w = T^T w_z    (since T is orthonormal/real)</p>\n\n<h2 id=\"library-conventions\">Library conventions</h2>\n\n<ul>\n<li>Complex-valued implementation (<code>supports_complex=True</code>).</li>\n<li><code>OptimizationResult.coefficients</code> stores time-domain coefficient history (self.w_history).</li>\n<li>Transform-domain coefficient history is provided in <code>result.extra[\"coefficients_dct\"]</code>\nwhen requested.</li>\n</ul>\n", "bases": "pydaptivefiltering.base.AdaptiveFilter"}, {"fullname": "pydaptivefiltering.TDomainDCT.__init__", "modulename": "pydaptivefiltering", "qualname": "TDomainDCT.__init__", "kind": "function", "doc": "<h2 id=\"parameters\">Parameters</h2>\n\n<p>filter_order:\n    FIR order M (number of taps is M+1).\ngamma:\n    Regularization factor to avoid division by (near) zero in each bin.\nalpha:\n    Smoothing factor for power estimation (typically close to 1).\ninitial_power:\n    Initial power estimate used for all transform bins.\nstep_size:\n    Step-size (mu).\nw_init:\n    Optional initial coefficients in time domain (length M+1). If None, zeros.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">filter_order</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">gamma</span><span class=\"p\">:</span> <span class=\"nb\">float</span>,</span><span class=\"param\">\t<span class=\"n\">alpha</span><span class=\"p\">:</span> <span class=\"nb\">float</span>,</span><span class=\"param\">\t<span class=\"n\">initial_power</span><span class=\"p\">:</span> <span class=\"nb\">float</span>,</span><span class=\"param\">\t<span class=\"n\">step_size</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">0.01</span>,</span><span class=\"param\">\t<span class=\"n\">w_init</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span><span class=\"p\">,</span> <span class=\"nb\">list</span><span class=\"p\">,</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span>)</span>"}, {"fullname": "pydaptivefiltering.TDomainDCT.supports_complex", "modulename": "pydaptivefiltering", "qualname": "TDomainDCT.supports_complex", "kind": "variable", "doc": "<p></p>\n", "annotation": ": bool", "default_value": "True"}, {"fullname": "pydaptivefiltering.TDomainDCT.gamma", "modulename": "pydaptivefiltering", "qualname": "TDomainDCT.gamma", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pydaptivefiltering.TDomainDCT.alpha", "modulename": "pydaptivefiltering", "qualname": "TDomainDCT.alpha", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pydaptivefiltering.TDomainDCT.step_size", "modulename": "pydaptivefiltering", "qualname": "TDomainDCT.step_size", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pydaptivefiltering.TDomainDCT.N", "modulename": "pydaptivefiltering", "qualname": "TDomainDCT.N", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pydaptivefiltering.TDomainDCT.T", "modulename": "pydaptivefiltering", "qualname": "TDomainDCT.T", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pydaptivefiltering.TDomainDCT.w_dct", "modulename": "pydaptivefiltering", "qualname": "TDomainDCT.w_dct", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pydaptivefiltering.TDomainDCT.power_vector", "modulename": "pydaptivefiltering", "qualname": "TDomainDCT.power_vector", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pydaptivefiltering.TDomainDCT.optimize", "modulename": "pydaptivefiltering", "qualname": "TDomainDCT.optimize", "kind": "function", "doc": "<p>Run Transform-Domain LMS (DCT) adaptation.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>input_signal:\n    Input signal x[k].\ndesired_signal:\n    Desired signal d[k].\nverbose:\n    If True, prints runtime.\nreturn_internal_states:\n    If True, returns extra sequences such as DCT coefficients history and final power vector.</p>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>OptimizationResult\n    outputs:\n        Filter output y[k] (a priori).\n    errors:\n        A priori error e[k] = d[k] - y[k].\n    coefficients:\n        Time-domain coefficient history stored in the base class.\n    error_type:\n        \"a_priori\".</p>\n\n<h2 id=\"extra-when-return_internal_statestrue\">Extra (when return_internal_states=True)</h2>\n\n<p>extra[\"coefficients_dct\"]:\n    List/array of transform-domain coefficient vectors over time.\nextra[\"power_vector_last\"]:\n    Final transform-bin power estimate.\nextra[\"dct_matrix\"]:\n    The DCT matrix T used (shape (M+1, M+1)).</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">input_signal</span><span class=\"p\">:</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span>,</span><span class=\"param\">\t<span class=\"n\">desired_signal</span><span class=\"p\">:</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span>,</span><span class=\"param\">\t<span class=\"n\">verbose</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">return_internal_states</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span></span><span class=\"return-annotation\">) -> <span class=\"n\">pydaptivefiltering</span><span class=\"o\">.</span><span class=\"n\">base</span><span class=\"o\">.</span><span class=\"n\">OptimizationResult</span>:</span></span>", "funcdef": "def"}, {"fullname": "pydaptivefiltering.TDomainDFT", "modulename": "pydaptivefiltering", "qualname": "TDomainDFT", "kind": "class", "doc": "<p>Transform-Domain LMS using a DFT (complex-valued).</p>\n\n<p>Implements a transform-domain LMS variant (Algorithm 4.4 - Diniz) where the\nregressor is transformed via a unitary DFT:</p>\n\n<pre><code>z_k = FFT(x_k) / sqrt(N)\ny[k] = w_z^H z_k\ne[k] = d[k] - y[k]\nP_z[k] = alpha * |z_k|^2 + (1-alpha) * P_z[k-1]\nw_z &lt;- w_z + mu * conj(e[k]) * z_k / (gamma + P_z[k])\n</code></pre>\n\n<p>Time-domain coefficients are recovered by:\n    w = IFFT(w_z) * sqrt(N)</p>\n\n<h2 id=\"library-conventions\">Library conventions</h2>\n\n<ul>\n<li>Complex-valued implementation (<code>supports_complex=True</code>).</li>\n<li><code>OptimizationResult.coefficients</code> stores time-domain coefficient history (self.w_history).</li>\n<li>Transform-domain coefficient history is provided in <code>result.extra[\"coefficients_dft\"]</code>\nwhen requested.</li>\n</ul>\n", "bases": "pydaptivefiltering.base.AdaptiveFilter"}, {"fullname": "pydaptivefiltering.TDomainDFT.__init__", "modulename": "pydaptivefiltering", "qualname": "TDomainDFT.__init__", "kind": "function", "doc": "<h2 id=\"parameters\">Parameters</h2>\n\n<p>filter_order:\n    FIR order M (number of taps is M+1). The DFT size is N = M+1.\ngamma:\n    Small positive constant to avoid division by (near) zero in each bin.\nalpha:\n    Smoothing factor for power estimation (typically close to 1).\ninitial_power:\n    Initial power estimate for all bins.\nstep_size:\n    Step-size (mu).\nw_init:\n    Optional initial coefficients in time domain (length M+1). If None, zeros.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">filter_order</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">gamma</span><span class=\"p\">:</span> <span class=\"nb\">float</span>,</span><span class=\"param\">\t<span class=\"n\">alpha</span><span class=\"p\">:</span> <span class=\"nb\">float</span>,</span><span class=\"param\">\t<span class=\"n\">initial_power</span><span class=\"p\">:</span> <span class=\"nb\">float</span>,</span><span class=\"param\">\t<span class=\"n\">step_size</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">0.01</span>,</span><span class=\"param\">\t<span class=\"n\">w_init</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span><span class=\"p\">,</span> <span class=\"nb\">list</span><span class=\"p\">,</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span>)</span>"}, {"fullname": "pydaptivefiltering.TDomainDFT.supports_complex", "modulename": "pydaptivefiltering", "qualname": "TDomainDFT.supports_complex", "kind": "variable", "doc": "<p></p>\n", "annotation": ": bool", "default_value": "True"}, {"fullname": "pydaptivefiltering.TDomainDFT.gamma", "modulename": "pydaptivefiltering", "qualname": "TDomainDFT.gamma", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pydaptivefiltering.TDomainDFT.alpha", "modulename": "pydaptivefiltering", "qualname": "TDomainDFT.alpha", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pydaptivefiltering.TDomainDFT.step_size", "modulename": "pydaptivefiltering", "qualname": "TDomainDFT.step_size", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pydaptivefiltering.TDomainDFT.N", "modulename": "pydaptivefiltering", "qualname": "TDomainDFT.N", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pydaptivefiltering.TDomainDFT.w_dft", "modulename": "pydaptivefiltering", "qualname": "TDomainDFT.w_dft", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pydaptivefiltering.TDomainDFT.power_vector", "modulename": "pydaptivefiltering", "qualname": "TDomainDFT.power_vector", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pydaptivefiltering.TDomainDFT.optimize", "modulename": "pydaptivefiltering", "qualname": "TDomainDFT.optimize", "kind": "function", "doc": "<p>Run Transform-Domain LMS (DFT) adaptation.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>input_signal:\n    Input signal x[k].\ndesired_signal:\n    Desired signal d[k].\nverbose:\n    If True, prints runtime.\nreturn_internal_states:\n    If True, returns extra sequences such as DFT coefficients history and final power vector.</p>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>OptimizationResult\n    outputs:\n        Filter output y[k] (a priori).\n    errors:\n        A priori error e[k] = d[k] - y[k].\n    coefficients:\n        Time-domain coefficient history stored in the base class.\n    error_type:\n        \"a_priori\".</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">input_signal</span><span class=\"p\">:</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span>,</span><span class=\"param\">\t<span class=\"n\">desired_signal</span><span class=\"p\">:</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span>,</span><span class=\"param\">\t<span class=\"n\">verbose</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">return_internal_states</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span></span><span class=\"return-annotation\">) -> <span class=\"n\">pydaptivefiltering</span><span class=\"o\">.</span><span class=\"n\">base</span><span class=\"o\">.</span><span class=\"n\">OptimizationResult</span>:</span></span>", "funcdef": "def"}, {"fullname": "pydaptivefiltering.RLS", "modulename": "pydaptivefiltering", "qualname": "RLS", "kind": "class", "doc": "<p>Recursive Least Squares (RLS) for complex-valued adaptive FIR filtering.</p>\n\n<p>Implements Algorithm 5.3 (Diniz). RLS minimizes an exponentially-weighted\nleast-squares cost by updating an inverse correlation matrix using the\nmatrix inversion lemma.</p>\n\n<h2 id=\"recursion-common-form\">Recursion (common form)</h2>\n\n<pre><code>y[k] = w[k]^H x_k\ne[k] = d[k] - y[k]\n\ng[k] = (S[k-1] x_k) / (lambda + x_k^H S[k-1] x_k)\nw[k] = w[k-1] + conj(e[k]) g[k]\nS[k] = (S[k-1] - g[k] x_k^H S[k-1]) / lambda\n</code></pre>\n\n<h2 id=\"notes\">Notes</h2>\n\n<ul>\n<li>Complex-valued implementation (supports_complex=True).</li>\n<li>By default, returns a priori output/error.</li>\n<li>If <code>return_internal_states=True</code>, includes a posteriori sequences and\nselected internal states in <code>result.extra</code>.</li>\n</ul>\n", "bases": "pydaptivefiltering.base.AdaptiveFilter"}, {"fullname": "pydaptivefiltering.RLS.__init__", "modulename": "pydaptivefiltering", "qualname": "RLS.__init__", "kind": "function", "doc": "<h2 id=\"parameters\">Parameters</h2>\n\n<p>filter_order:\n    FIR order M (number of taps is M+1).\ndelta:\n    Initialization for S_d(0) = (1/delta) * I. Must be positive.\nlamb:\n    Forgetting factor \u03bb, typically 0 &lt; \u03bb &lt;= 1.\nw_init:\n    Optional initial coefficients (length M+1). If None, zeros.\nsafe_eps:\n    Small epsilon used to guard denominators.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">filter_order</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">delta</span><span class=\"p\">:</span> <span class=\"nb\">float</span>,</span><span class=\"param\">\t<span class=\"n\">lamb</span><span class=\"p\">:</span> <span class=\"nb\">float</span>,</span><span class=\"param\">\t<span class=\"n\">w_init</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span><span class=\"p\">,</span> <span class=\"nb\">list</span><span class=\"p\">,</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"o\">*</span>,</span><span class=\"param\">\t<span class=\"n\">safe_eps</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">1e-12</span></span>)</span>"}, {"fullname": "pydaptivefiltering.RLS.supports_complex", "modulename": "pydaptivefiltering", "qualname": "RLS.supports_complex", "kind": "variable", "doc": "<p></p>\n", "annotation": ": bool", "default_value": "True"}, {"fullname": "pydaptivefiltering.RLS.lamb", "modulename": "pydaptivefiltering", "qualname": "RLS.lamb", "kind": "variable", "doc": "<p></p>\n", "annotation": ": float"}, {"fullname": "pydaptivefiltering.RLS.delta", "modulename": "pydaptivefiltering", "qualname": "RLS.delta", "kind": "variable", "doc": "<p></p>\n", "annotation": ": float"}, {"fullname": "pydaptivefiltering.RLS.S_d", "modulename": "pydaptivefiltering", "qualname": "RLS.S_d", "kind": "variable", "doc": "<p></p>\n", "annotation": ": numpy.ndarray"}, {"fullname": "pydaptivefiltering.RLS.optimize", "modulename": "pydaptivefiltering", "qualname": "RLS.optimize", "kind": "function", "doc": "<p>Run RLS adaptation.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>input_signal:\n    Input signal x[k].\ndesired_signal:\n    Desired signal d[k].\nverbose:\n    If True, prints runtime.\nreturn_internal_states:\n    If True, includes a posteriori sequences and final internal states in <code>result.extra</code>.</p>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>OptimizationResult\n    outputs:\n        A priori output y[k] = w^H x_k.\n    errors:\n        A priori error e[k] = d[k] - y[k].\n    coefficients:\n        Coefficient history stored in the base class.\n    error_type:\n        \"a_priori\".</p>\n\n<h2 id=\"extra-when-return_internal_statestrue\">Extra (when return_internal_states=True)</h2>\n\n<p>extra[\"outputs_posteriori\"]:\n    A posteriori output y_post[k] computed after updating w.\nextra[\"errors_posteriori\"]:\n    A posteriori error e_post[k] = d[k] - y_post[k].\nextra[\"S_d_last\"]:\n    Final inverse correlation matrix.\nextra[\"gain_last\"]:\n    Last gain vector g.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">input_signal</span><span class=\"p\">:</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span>,</span><span class=\"param\">\t<span class=\"n\">desired_signal</span><span class=\"p\">:</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span>,</span><span class=\"param\">\t<span class=\"n\">verbose</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">return_internal_states</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span></span><span class=\"return-annotation\">) -> <span class=\"n\">pydaptivefiltering</span><span class=\"o\">.</span><span class=\"n\">base</span><span class=\"o\">.</span><span class=\"n\">OptimizationResult</span>:</span></span>", "funcdef": "def"}, {"fullname": "pydaptivefiltering.RLSAlt", "modulename": "pydaptivefiltering", "qualname": "RLSAlt", "kind": "class", "doc": "<p>Alternative RLS (RLS-Alt) for complex-valued adaptive FIR filtering.</p>\n\n<p>Implements Algorithm 5.4 (Diniz). This variant reduces computational burden by\nusing the auxiliary vector:</p>\n\n<pre><code>psi[k] = S_d[k-1] x_k\n</code></pre>\n\n<p>where S_d is the inverse correlation (or inverse deterministic autocorrelation)\nmatrix, and x_k is the tapped-delay-line regressor.</p>\n\n<h2 id=\"notes\">Notes</h2>\n\n<ul>\n<li>Complex-valued implementation (supports_complex=True).</li>\n<li>Returns the <strong>a priori</strong> output and error by default:\n  y[k] = w[k]^H x_k\n  e[k] = d[k] - y[k]\nand can optionally provide a posteriori sequences in <code>extra</code>.</li>\n<li>Uses unified base API via <code>@validate_input</code>.</li>\n</ul>\n", "bases": "pydaptivefiltering.base.AdaptiveFilter"}, {"fullname": "pydaptivefiltering.RLSAlt.__init__", "modulename": "pydaptivefiltering", "qualname": "RLSAlt.__init__", "kind": "function", "doc": "<h2 id=\"parameters\">Parameters</h2>\n\n<p>filter_order:\n    FIR order M (number of taps is M+1).\ndelta:\n    Initialization factor for S_d(0) = (1/delta) * I. Must be positive.\nlamb:\n    Forgetting factor \u03bb. Typically 0 &lt; \u03bb &lt;= 1.\nw_init:\n    Optional initial coefficients (length M+1). If None, zeros.\nsafe_eps:\n    Small epsilon used to guard denominators.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">filter_order</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">delta</span><span class=\"p\">:</span> <span class=\"nb\">float</span>,</span><span class=\"param\">\t<span class=\"n\">lamb</span><span class=\"p\">:</span> <span class=\"nb\">float</span>,</span><span class=\"param\">\t<span class=\"n\">w_init</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span><span class=\"p\">,</span> <span class=\"nb\">list</span><span class=\"p\">,</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"o\">*</span>,</span><span class=\"param\">\t<span class=\"n\">safe_eps</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">1e-12</span></span>)</span>"}, {"fullname": "pydaptivefiltering.RLSAlt.supports_complex", "modulename": "pydaptivefiltering", "qualname": "RLSAlt.supports_complex", "kind": "variable", "doc": "<p></p>\n", "annotation": ": bool", "default_value": "True"}, {"fullname": "pydaptivefiltering.RLSAlt.lamb", "modulename": "pydaptivefiltering", "qualname": "RLSAlt.lamb", "kind": "variable", "doc": "<p></p>\n", "annotation": ": float"}, {"fullname": "pydaptivefiltering.RLSAlt.delta", "modulename": "pydaptivefiltering", "qualname": "RLSAlt.delta", "kind": "variable", "doc": "<p></p>\n", "annotation": ": float"}, {"fullname": "pydaptivefiltering.RLSAlt.S_d", "modulename": "pydaptivefiltering", "qualname": "RLSAlt.S_d", "kind": "variable", "doc": "<p></p>\n", "annotation": ": numpy.ndarray"}, {"fullname": "pydaptivefiltering.RLSAlt.optimize", "modulename": "pydaptivefiltering", "qualname": "RLSAlt.optimize", "kind": "function", "doc": "<p>Run RLS-Alt adaptation.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>input_signal:\n    Input signal x[k].\ndesired_signal:\n    Desired signal d[k].\nverbose:\n    If True, prints runtime.\nreturn_internal_states:\n    If True, includes a posteriori sequences and last internal matrices in <code>result.extra</code>.</p>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>OptimizationResult\n    outputs:\n        A priori output y[k] = w^H x_k.\n    errors:\n        A priori error e[k] = d[k] - y[k].\n    coefficients:\n        Coefficient history stored in the base class.\n    error_type:\n        \"a_priori\".</p>\n\n<h2 id=\"extra-when-return_internal_statestrue\">Extra (when return_internal_states=True)</h2>\n\n<p>extra[\"outputs_posteriori\"]:\n    A posteriori output y_post[k] using updated w[k+1].\nextra[\"errors_posteriori\"]:\n    A posteriori error e_post[k] = d[k] - y_post[k].\nextra[\"S_d_last\"]:\n    Final inverse correlation matrix.\nextra[\"gain_last\"]:\n    Kalman gain-like vector g at last iteration.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">input_signal</span><span class=\"p\">:</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span>,</span><span class=\"param\">\t<span class=\"n\">desired_signal</span><span class=\"p\">:</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span>,</span><span class=\"param\">\t<span class=\"n\">verbose</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">return_internal_states</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span></span><span class=\"return-annotation\">) -> <span class=\"n\">pydaptivefiltering</span><span class=\"o\">.</span><span class=\"n\">base</span><span class=\"o\">.</span><span class=\"n\">OptimizationResult</span>:</span></span>", "funcdef": "def"}, {"fullname": "pydaptivefiltering.SMNLMS", "modulename": "pydaptivefiltering", "qualname": "SMNLMS", "kind": "class", "doc": "<p>Implements the Set-membership Normalized LMS algorithm for complex-valued data.</p>\n\n<p>Coefficients are updated only when |e(k)| &gt; gamma_bar. (Algorithm 6.1, Diniz)</p>\n", "bases": "pydaptivefiltering.base.AdaptiveFilter"}, {"fullname": "pydaptivefiltering.SMNLMS.__init__", "modulename": "pydaptivefiltering", "qualname": "SMNLMS.__init__", "kind": "function", "doc": "<h2 id=\"parameters\">Parameters</h2>\n\n<p>filter_order:\n    FIR filter order (number of taps - 1). Number of coefficients is filter_order + 1.\ngamma_bar:\n    Error magnitude threshold for triggering updates.\ngamma:\n    Regularization factor to avoid division by zero in normalization.\nw_init:\n    Optional initial coefficient vector. If None, initializes to zeros.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">filter_order</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">gamma_bar</span><span class=\"p\">:</span> <span class=\"nb\">float</span>,</span><span class=\"param\">\t<span class=\"n\">gamma</span><span class=\"p\">:</span> <span class=\"nb\">float</span>,</span><span class=\"param\">\t<span class=\"n\">w_init</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span><span class=\"p\">,</span> <span class=\"nb\">list</span><span class=\"p\">,</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span>)</span>"}, {"fullname": "pydaptivefiltering.SMNLMS.supports_complex", "modulename": "pydaptivefiltering", "qualname": "SMNLMS.supports_complex", "kind": "variable", "doc": "<p></p>\n", "annotation": ": bool", "default_value": "True"}, {"fullname": "pydaptivefiltering.SMNLMS.gamma_bar", "modulename": "pydaptivefiltering", "qualname": "SMNLMS.gamma_bar", "kind": "variable", "doc": "<p></p>\n", "annotation": ": float"}, {"fullname": "pydaptivefiltering.SMNLMS.gamma", "modulename": "pydaptivefiltering", "qualname": "SMNLMS.gamma", "kind": "variable", "doc": "<p></p>\n", "annotation": ": float"}, {"fullname": "pydaptivefiltering.SMNLMS.n_coeffs", "modulename": "pydaptivefiltering", "qualname": "SMNLMS.n_coeffs", "kind": "variable", "doc": "<p></p>\n", "annotation": ": int"}, {"fullname": "pydaptivefiltering.SMNLMS.n_updates", "modulename": "pydaptivefiltering", "qualname": "SMNLMS.n_updates", "kind": "variable", "doc": "<p></p>\n", "annotation": ": int"}, {"fullname": "pydaptivefiltering.SMNLMS.optimize", "modulename": "pydaptivefiltering", "qualname": "SMNLMS.optimize", "kind": "function", "doc": "<p>Executes the SM-NLMS adaptation.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>input_signal:\n    Input signal x[k].\ndesired_signal:\n    Desired signal d[k].\nverbose:\n    If True, prints runtime and update stats.\nreturn_internal_states:\n    If True, includes additional internal trajectories in result.extra.</p>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>OptimizationResult\n    outputs:\n        A-priori output y[k] = w^H x_k.\n    errors:\n        A-priori error e[k] = d[k] - y[k].\n    coefficients:\n        History of coefficients stored in the base class.\n    error_type:\n        \"a_priori\".</p>\n\n<h2 id=\"extra-always\">Extra (always)</h2>\n\n<p>extra[\"n_updates\"]:\n    Number of coefficient updates (iterations where |e(k)| &gt; gamma_bar).\nextra[\"update_mask\"]:\n    Boolean array marking which iterations performed updates.</p>\n\n<h2 id=\"extra-when-return_internal_statestrue\">Extra (when return_internal_states=True)</h2>\n\n<p>extra[\"mu\"]:\n    Trajectory of the SM step-size factor mu[k] (0 when no update).\nextra[\"den\"]:\n    Denominator trajectory gamma + ||x_k||^2 (0 when no update).</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">input_signal</span><span class=\"p\">:</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span>,</span><span class=\"param\">\t<span class=\"n\">desired_signal</span><span class=\"p\">:</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span>,</span><span class=\"param\">\t<span class=\"n\">verbose</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">return_internal_states</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span></span><span class=\"return-annotation\">) -> <span class=\"n\">pydaptivefiltering</span><span class=\"o\">.</span><span class=\"n\">base</span><span class=\"o\">.</span><span class=\"n\">OptimizationResult</span>:</span></span>", "funcdef": "def"}, {"fullname": "pydaptivefiltering.SMBNLMS", "modulename": "pydaptivefiltering", "qualname": "SMBNLMS", "kind": "class", "doc": "<p>Implements the Set-membership Binormalized LMS (SM-BNLMS) algorithm for complex-valued data.</p>\n\n<p>This algorithm is a specific case of SM-AP with L=1, designed to improve\nconvergence speed over SM-NLMS with low computational overhead by reusing\nthe previous regressor. (Algorithm 6.5, Diniz)</p>\n", "bases": "pydaptivefiltering.base.AdaptiveFilter"}, {"fullname": "pydaptivefiltering.SMBNLMS.__init__", "modulename": "pydaptivefiltering", "qualname": "SMBNLMS.__init__", "kind": "function", "doc": "<h2 id=\"parameters\">Parameters</h2>\n\n<p>filter_order:\n    FIR filter order (number of taps - 1). Number of coefficients is filter_order + 1.\ngamma_bar:\n    Upper bound for the error magnitude (set-membership threshold).\ngamma:\n    Regularization factor to avoid division by zero (and stabilize denominator).\nw_init:\n    Optional initial coefficient vector. If None, initializes to zeros.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">filter_order</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">gamma_bar</span><span class=\"p\">:</span> <span class=\"nb\">float</span>,</span><span class=\"param\">\t<span class=\"n\">gamma</span><span class=\"p\">:</span> <span class=\"nb\">float</span>,</span><span class=\"param\">\t<span class=\"n\">w_init</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span><span class=\"p\">,</span> <span class=\"nb\">list</span><span class=\"p\">,</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span>)</span>"}, {"fullname": "pydaptivefiltering.SMBNLMS.supports_complex", "modulename": "pydaptivefiltering", "qualname": "SMBNLMS.supports_complex", "kind": "variable", "doc": "<p></p>\n", "annotation": ": bool", "default_value": "True"}, {"fullname": "pydaptivefiltering.SMBNLMS.gamma_bar", "modulename": "pydaptivefiltering", "qualname": "SMBNLMS.gamma_bar", "kind": "variable", "doc": "<p></p>\n", "annotation": ": float"}, {"fullname": "pydaptivefiltering.SMBNLMS.gamma", "modulename": "pydaptivefiltering", "qualname": "SMBNLMS.gamma", "kind": "variable", "doc": "<p></p>\n", "annotation": ": float"}, {"fullname": "pydaptivefiltering.SMBNLMS.n_coeffs", "modulename": "pydaptivefiltering", "qualname": "SMBNLMS.n_coeffs", "kind": "variable", "doc": "<p></p>\n", "annotation": ": int"}, {"fullname": "pydaptivefiltering.SMBNLMS.regressor_prev", "modulename": "pydaptivefiltering", "qualname": "SMBNLMS.regressor_prev", "kind": "variable", "doc": "<p></p>\n", "annotation": ": numpy.ndarray"}, {"fullname": "pydaptivefiltering.SMBNLMS.n_updates", "modulename": "pydaptivefiltering", "qualname": "SMBNLMS.n_updates", "kind": "variable", "doc": "<p></p>\n", "annotation": ": int"}, {"fullname": "pydaptivefiltering.SMBNLMS.optimize", "modulename": "pydaptivefiltering", "qualname": "SMBNLMS.optimize", "kind": "function", "doc": "<p>Executes the SM-BNLMS adaptation.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>input_signal:\n    Input signal x[k].\ndesired_signal:\n    Desired signal d[k].\nverbose:\n    If True, prints runtime and update count.\nreturn_internal_states:\n    If True, includes internal trajectories in result.extra.</p>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>OptimizationResult\n    outputs:\n        A-priori output y[k] = w^H x_k.\n    errors:\n        A-priori error e[k] = d[k] - y[k].\n    coefficients:\n        History of coefficients stored in the base class.\n    error_type:\n        \"a_priori\".</p>\n\n<h2 id=\"extra-always\">Extra (always)</h2>\n\n<p>extra[\"n_updates\"]:\n    Number of coefficient updates (iterations where |e(k)| &gt; gamma_bar).\nextra[\"update_mask\"]:\n    Boolean array marking which iterations performed updates.</p>\n\n<h2 id=\"extra-when-return_internal_statestrue\">Extra (when return_internal_states=True)</h2>\n\n<p>extra[\"mu\"]:\n    Trajectory of the SM step-size factor mu[k] (0 when no update).\nextra[\"den\"]:\n    Denominator trajectory used in lambda1/lambda2 (0 when no update).\nextra[\"lambda1\"]:\n    Lambda1 trajectory (0 when no update).\nextra[\"lambda2\"]:\n    Lambda2 trajectory (0 when no update).</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">input_signal</span><span class=\"p\">:</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span>,</span><span class=\"param\">\t<span class=\"n\">desired_signal</span><span class=\"p\">:</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span>,</span><span class=\"param\">\t<span class=\"n\">verbose</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">return_internal_states</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span></span><span class=\"return-annotation\">) -> <span class=\"n\">pydaptivefiltering</span><span class=\"o\">.</span><span class=\"n\">base</span><span class=\"o\">.</span><span class=\"n\">OptimizationResult</span>:</span></span>", "funcdef": "def"}, {"fullname": "pydaptivefiltering.SMAffineProjection", "modulename": "pydaptivefiltering", "qualname": "SMAffineProjection", "kind": "class", "doc": "<p>Implements the Set-membership Affine-Projection (SM-AP) algorithm for complex-valued data.</p>\n\n<p>This is a supervised algorithm, i.e., it requires both input_signal and desired_signal.</p>\n", "bases": "pydaptivefiltering.base.AdaptiveFilter"}, {"fullname": "pydaptivefiltering.SMAffineProjection.__init__", "modulename": "pydaptivefiltering", "qualname": "SMAffineProjection.__init__", "kind": "function", "doc": "<h2 id=\"parameters\">Parameters</h2>\n\n<p>filter_order:\n    FIR filter order (number of taps - 1). Number of coefficients is filter_order + 1.\ngamma_bar:\n    Upper bound for the (a-priori) error magnitude used by set-membership criterion.\ngamma_bar_vector:\n    Target a-posteriori error vector, size (L+1,). (Algorithm-dependent)\ngamma:\n    Regularization factor for the AP correlation matrix.\nL:\n    Reuse data factor / constraint length (projection order).\nw_init:\n    Optional initial coefficient vector. If None, initializes to zeros.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">filter_order</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">gamma_bar</span><span class=\"p\">:</span> <span class=\"nb\">float</span>,</span><span class=\"param\">\t<span class=\"n\">gamma_bar_vector</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span><span class=\"p\">,</span> <span class=\"nb\">list</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"n\">gamma</span><span class=\"p\">:</span> <span class=\"nb\">float</span>,</span><span class=\"param\">\t<span class=\"n\">L</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">w_init</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span><span class=\"p\">,</span> <span class=\"nb\">list</span><span class=\"p\">,</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span>)</span>"}, {"fullname": "pydaptivefiltering.SMAffineProjection.supports_complex", "modulename": "pydaptivefiltering", "qualname": "SMAffineProjection.supports_complex", "kind": "variable", "doc": "<p></p>\n", "annotation": ": bool", "default_value": "True"}, {"fullname": "pydaptivefiltering.SMAffineProjection.gamma_bar", "modulename": "pydaptivefiltering", "qualname": "SMAffineProjection.gamma_bar", "kind": "variable", "doc": "<p></p>\n", "annotation": ": float"}, {"fullname": "pydaptivefiltering.SMAffineProjection.gamma_bar_vector", "modulename": "pydaptivefiltering", "qualname": "SMAffineProjection.gamma_bar_vector", "kind": "variable", "doc": "<p></p>\n", "annotation": ": numpy.ndarray"}, {"fullname": "pydaptivefiltering.SMAffineProjection.gamma", "modulename": "pydaptivefiltering", "qualname": "SMAffineProjection.gamma", "kind": "variable", "doc": "<p></p>\n", "annotation": ": float"}, {"fullname": "pydaptivefiltering.SMAffineProjection.L", "modulename": "pydaptivefiltering", "qualname": "SMAffineProjection.L", "kind": "variable", "doc": "<p></p>\n", "annotation": ": int"}, {"fullname": "pydaptivefiltering.SMAffineProjection.n_coeffs", "modulename": "pydaptivefiltering", "qualname": "SMAffineProjection.n_coeffs", "kind": "variable", "doc": "<p></p>\n", "annotation": ": int"}, {"fullname": "pydaptivefiltering.SMAffineProjection.regressor_matrix", "modulename": "pydaptivefiltering", "qualname": "SMAffineProjection.regressor_matrix", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pydaptivefiltering.SMAffineProjection.n_updates", "modulename": "pydaptivefiltering", "qualname": "SMAffineProjection.n_updates", "kind": "variable", "doc": "<p></p>\n", "annotation": ": int"}, {"fullname": "pydaptivefiltering.SMAffineProjection.optimize", "modulename": "pydaptivefiltering", "qualname": "SMAffineProjection.optimize", "kind": "function", "doc": "<p>Executes the SM-AP adaptation.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>input_signal:\n    Input signal x[k].\ndesired_signal:\n    Desired signal d[k].\nverbose:\n    If True, prints runtime and update count.\nreturn_internal_states:\n    If True, includes additional internal trajectories in result.extra.</p>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>OptimizationResult\n    outputs:\n        A-priori output y[k].\n    errors:\n        A-priori error e[k] = d[k] - y[k] (first component of AP error vector).\n    coefficients:\n        History of coefficients stored in the base class.\n    error_type:\n        \"a_priori\".</p>\n\n<h2 id=\"extra-always\">Extra (always)</h2>\n\n<p>extra[\"n_updates\"]:\n    Number of coefficient updates (iterations where |e(k)| &gt; gamma_bar).\nextra[\"update_mask\"]:\n    Boolean array marking which iterations performed updates.</p>\n\n<h2 id=\"extra-when-return_internal_statestrue\">Extra (when return_internal_states=True)</h2>\n\n<p>extra[\"errors_vector\"]:\n    Full AP a-priori error vector over time, shape (N, L+1).</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">input_signal</span><span class=\"p\">:</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span>,</span><span class=\"param\">\t<span class=\"n\">desired_signal</span><span class=\"p\">:</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span>,</span><span class=\"param\">\t<span class=\"n\">verbose</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">return_internal_states</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span></span><span class=\"return-annotation\">) -> <span class=\"n\">pydaptivefiltering</span><span class=\"o\">.</span><span class=\"n\">base</span><span class=\"o\">.</span><span class=\"n\">OptimizationResult</span>:</span></span>", "funcdef": "def"}, {"fullname": "pydaptivefiltering.Simplified_SMAP", "modulename": "pydaptivefiltering", "qualname": "Simplified_SMAP", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pydaptivefiltering.Simplified_PUAP", "modulename": "pydaptivefiltering", "qualname": "Simplified_PUAP", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pydaptivefiltering.LRLSPosteriori", "modulename": "pydaptivefiltering", "qualname": "LRLSPosteriori", "kind": "class", "doc": "<p>Lattice Recursive Least Squares (LRLS) using a posteriori errors.</p>\n\n<p>Implements Algorithm 7.1 (Diniz) in a lattice structure (prediction + ladder).</p>\n\n<h2 id=\"library-conventions\">Library conventions</h2>\n\n<ul>\n<li>Complex-valued implementation (<code>supports_complex=True</code>).</li>\n<li>Ladder coefficients are stored in <code>self.v</code> (length M+1).</li>\n<li><code>self.w</code> mirrors <code>self.v</code> and history is recorded via <code>_record_history()</code>.</li>\n</ul>\n", "bases": "pydaptivefiltering.base.AdaptiveFilter"}, {"fullname": "pydaptivefiltering.LRLSPosteriori.__init__", "modulename": "pydaptivefiltering", "qualname": "LRLSPosteriori.__init__", "kind": "function", "doc": "<h2 id=\"parameters\">Parameters</h2>\n\n<p>filter_order:\n    Number of lattice sections M. Ladder has M+1 coefficients.\nlambda_factor:\n    Forgetting factor \u03bb.\nepsilon:\n    Energy initialization / regularization.\nw_init:\n    Optional initial ladder coefficient vector (length M+1). If None, zeros.\ndenom_floor:\n    Floor used to avoid division by (near) zero in normalization terms.\nxi_floor:\n    Floor used to keep energies positive (defaults to epsilon).</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">filter_order</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">lambda_factor</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">0.99</span>,</span><span class=\"param\">\t<span class=\"n\">epsilon</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">0.1</span>,</span><span class=\"param\">\t<span class=\"n\">w_init</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span><span class=\"p\">,</span> <span class=\"nb\">list</span><span class=\"p\">,</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">denom_floor</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">1e-12</span>,</span><span class=\"param\">\t<span class=\"n\">xi_floor</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">float</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span>)</span>"}, {"fullname": "pydaptivefiltering.LRLSPosteriori.supports_complex", "modulename": "pydaptivefiltering", "qualname": "LRLSPosteriori.supports_complex", "kind": "variable", "doc": "<p></p>\n", "annotation": ": bool", "default_value": "True"}, {"fullname": "pydaptivefiltering.LRLSPosteriori.lam", "modulename": "pydaptivefiltering", "qualname": "LRLSPosteriori.lam", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pydaptivefiltering.LRLSPosteriori.epsilon", "modulename": "pydaptivefiltering", "qualname": "LRLSPosteriori.epsilon", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pydaptivefiltering.LRLSPosteriori.n_sections", "modulename": "pydaptivefiltering", "qualname": "LRLSPosteriori.n_sections", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pydaptivefiltering.LRLSPosteriori.delta", "modulename": "pydaptivefiltering", "qualname": "LRLSPosteriori.delta", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pydaptivefiltering.LRLSPosteriori.xi_f", "modulename": "pydaptivefiltering", "qualname": "LRLSPosteriori.xi_f", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pydaptivefiltering.LRLSPosteriori.xi_b", "modulename": "pydaptivefiltering", "qualname": "LRLSPosteriori.xi_b", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pydaptivefiltering.LRLSPosteriori.error_b_prev", "modulename": "pydaptivefiltering", "qualname": "LRLSPosteriori.error_b_prev", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pydaptivefiltering.LRLSPosteriori.delta_v", "modulename": "pydaptivefiltering", "qualname": "LRLSPosteriori.delta_v", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pydaptivefiltering.LRLSPosteriori.w", "modulename": "pydaptivefiltering", "qualname": "LRLSPosteriori.w", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pydaptivefiltering.LRLSPosteriori.w_history", "modulename": "pydaptivefiltering", "qualname": "LRLSPosteriori.w_history", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pydaptivefiltering.LRLSPosteriori.optimize", "modulename": "pydaptivefiltering", "qualname": "LRLSPosteriori.optimize", "kind": "function", "doc": "<p>Executes LRLS adaptation (a posteriori version) over (x[k], d[k]).</p>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>OptimizationResult\n    outputs:\n        Filter output y[k].\n    errors:\n        A posteriori error e[k].\n    coefficients:\n        History of ladder coefficients v (mirrored in self.w_history).\n    error_type:\n        \"a_posteriori\".</p>\n\n<h2 id=\"extra-when-return_internal_statestrue\">Extra (when return_internal_states=True)</h2>\n\n<p>extra[\"xi_f\"], extra[\"xi_b\"], extra[\"delta\"], extra[\"delta_v\"]:\n    Final arrays at the end of adaptation.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">input_signal</span><span class=\"p\">:</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span>,</span><span class=\"param\">\t<span class=\"n\">desired_signal</span><span class=\"p\">:</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span>,</span><span class=\"param\">\t<span class=\"n\">verbose</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">return_internal_states</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span></span><span class=\"return-annotation\">) -> <span class=\"n\">pydaptivefiltering</span><span class=\"o\">.</span><span class=\"n\">base</span><span class=\"o\">.</span><span class=\"n\">OptimizationResult</span>:</span></span>", "funcdef": "def"}, {"fullname": "pydaptivefiltering.LRLSErrorFeedback", "modulename": "pydaptivefiltering", "qualname": "LRLSErrorFeedback", "kind": "class", "doc": "<p>Lattice Recursive Least Squares with Error Feedback (LRLS-EF).</p>\n\n<p>Implements Algorithm 7.5 from:\n    P. S. R. Diniz, \"Adaptive Filtering: Algorithms and Practical Implementation\".</p>\n\n<h2 id=\"structure-overview\">Structure overview</h2>\n\n<p>The LRLS-EF algorithm combines:\n1) A lattice prediction stage (forward/backward errors and reflection updates).\n2) An error-feedback ladder stage (joint process / ladder weights).</p>\n\n<h2 id=\"library-conventions\">Library conventions</h2>\n\n<ul>\n<li>Complex-valued implementation (<code>supports_complex=True</code>).</li>\n<li>The ladder coefficient vector is <code>self.v</code> (length M+1).</li>\n<li>For compatibility with the base class:\n<ul>\n<li><code>self.w</code> mirrors <code>self.v</code> at each iteration.</li>\n<li>coefficient history is stored via <code>self._record_history()</code>.</li>\n</ul></li>\n</ul>\n", "bases": "pydaptivefiltering.base.AdaptiveFilter"}, {"fullname": "pydaptivefiltering.LRLSErrorFeedback.__init__", "modulename": "pydaptivefiltering", "qualname": "LRLSErrorFeedback.__init__", "kind": "function", "doc": "<h2 id=\"parameters\">Parameters</h2>\n\n<p>filter_order:\n    Lattice order M (number of sections). Ladder has M+1 coefficients.\nlambda_factor:\n    Forgetting factor \u03bb.\nepsilon:\n    Regularization/initialization constant for energies.\nw_init:\n    Optional initial ladder coefficients (length M+1). If None, zeros.\nsafe_eps:\n    Small positive floor used to avoid division by (near) zero.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">filter_order</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">lambda_factor</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">0.99</span>,</span><span class=\"param\">\t<span class=\"n\">epsilon</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">0.1</span>,</span><span class=\"param\">\t<span class=\"n\">w_init</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span><span class=\"p\">,</span> <span class=\"nb\">list</span><span class=\"p\">,</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">safe_eps</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">1e-12</span></span>)</span>"}, {"fullname": "pydaptivefiltering.LRLSErrorFeedback.supports_complex", "modulename": "pydaptivefiltering", "qualname": "LRLSErrorFeedback.supports_complex", "kind": "variable", "doc": "<p></p>\n", "annotation": ": bool", "default_value": "True"}, {"fullname": "pydaptivefiltering.LRLSErrorFeedback.lam", "modulename": "pydaptivefiltering", "qualname": "LRLSErrorFeedback.lam", "kind": "variable", "doc": "<p></p>\n", "annotation": ": float"}, {"fullname": "pydaptivefiltering.LRLSErrorFeedback.epsilon", "modulename": "pydaptivefiltering", "qualname": "LRLSErrorFeedback.epsilon", "kind": "variable", "doc": "<p></p>\n", "annotation": ": float"}, {"fullname": "pydaptivefiltering.LRLSErrorFeedback.n_sections", "modulename": "pydaptivefiltering", "qualname": "LRLSErrorFeedback.n_sections", "kind": "variable", "doc": "<p></p>\n", "annotation": ": int"}, {"fullname": "pydaptivefiltering.LRLSErrorFeedback.safe_eps", "modulename": "pydaptivefiltering", "qualname": "LRLSErrorFeedback.safe_eps", "kind": "variable", "doc": "<p></p>\n", "annotation": ": float"}, {"fullname": "pydaptivefiltering.LRLSErrorFeedback.delta", "modulename": "pydaptivefiltering", "qualname": "LRLSErrorFeedback.delta", "kind": "variable", "doc": "<p></p>\n", "annotation": ": numpy.ndarray"}, {"fullname": "pydaptivefiltering.LRLSErrorFeedback.xi_f", "modulename": "pydaptivefiltering", "qualname": "LRLSErrorFeedback.xi_f", "kind": "variable", "doc": "<p></p>\n", "annotation": ": numpy.ndarray"}, {"fullname": "pydaptivefiltering.LRLSErrorFeedback.xi_b", "modulename": "pydaptivefiltering", "qualname": "LRLSErrorFeedback.xi_b", "kind": "variable", "doc": "<p></p>\n", "annotation": ": numpy.ndarray"}, {"fullname": "pydaptivefiltering.LRLSErrorFeedback.error_b_prev", "modulename": "pydaptivefiltering", "qualname": "LRLSErrorFeedback.error_b_prev", "kind": "variable", "doc": "<p></p>\n", "annotation": ": numpy.ndarray"}, {"fullname": "pydaptivefiltering.LRLSErrorFeedback.v", "modulename": "pydaptivefiltering", "qualname": "LRLSErrorFeedback.v", "kind": "variable", "doc": "<p></p>\n", "annotation": ": numpy.ndarray"}, {"fullname": "pydaptivefiltering.LRLSErrorFeedback.delta_v", "modulename": "pydaptivefiltering", "qualname": "LRLSErrorFeedback.delta_v", "kind": "variable", "doc": "<p></p>\n", "annotation": ": numpy.ndarray"}, {"fullname": "pydaptivefiltering.LRLSErrorFeedback.w", "modulename": "pydaptivefiltering", "qualname": "LRLSErrorFeedback.w", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pydaptivefiltering.LRLSErrorFeedback.w_history", "modulename": "pydaptivefiltering", "qualname": "LRLSErrorFeedback.w_history", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pydaptivefiltering.LRLSErrorFeedback.optimize", "modulename": "pydaptivefiltering", "qualname": "LRLSErrorFeedback.optimize", "kind": "function", "doc": "<p>Executes LRLS-EF adaptation over (x[k], d[k]).</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>input_signal:\n    Input sequence x[k].\ndesired_signal:\n    Desired sequence d[k].\nverbose:\n    If True, prints runtime.\nreturn_internal_states:\n    If True, includes selected internal states in <code>result.extra</code>.</p>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>OptimizationResult\n    outputs:\n        Estimated output y[k].\n    errors:\n        Output error e[k] = d[k] - y[k].\n    coefficients:\n        History of ladder coefficients v (mirrored in <code>self.w_history</code>).\n    error_type:\n        \"output_error\".</p>\n\n<h2 id=\"extra-when-return_internal_statestrue\">Extra (when return_internal_states=True)</h2>\n\n<p>extra[\"xi_f\"], extra[\"xi_b\"]:\n    Final forward/backward energies (length M+2).\nextra[\"delta\"]:\n    Final delta vector (length M+1).\nextra[\"delta_v\"]:\n    Final delta_v vector (length M+1).</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">input_signal</span><span class=\"p\">:</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span>,</span><span class=\"param\">\t<span class=\"n\">desired_signal</span><span class=\"p\">:</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span>,</span><span class=\"param\">\t<span class=\"n\">verbose</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">return_internal_states</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span></span><span class=\"return-annotation\">) -> <span class=\"n\">pydaptivefiltering</span><span class=\"o\">.</span><span class=\"n\">base</span><span class=\"o\">.</span><span class=\"n\">OptimizationResult</span>:</span></span>", "funcdef": "def"}, {"fullname": "pydaptivefiltering.LRLSPriori", "modulename": "pydaptivefiltering", "qualname": "LRLSPriori", "kind": "class", "doc": "<p>Lattice Recursive Least Squares (LRLS) using a priori errors.</p>\n\n<p>Implements Algorithm 7.4 (Diniz) in a lattice (prediction + ladder) structure.</p>\n\n<h2 id=\"library-conventions\">Library conventions</h2>\n\n<ul>\n<li>Complex arithmetic (<code>supports_complex=True</code>).</li>\n<li>Ladder coefficients are stored in <code>self.v</code> (length M+1).</li>\n<li>For consistency with the library base class:\n<ul>\n<li><code>self.w</code> mirrors <code>self.v</code></li>\n<li><code>self._record_history()</code> is called each iteration</li>\n<li>coefficients history is available as <code>result.coefficients</code></li>\n</ul></li>\n</ul>\n", "bases": "pydaptivefiltering.base.AdaptiveFilter"}, {"fullname": "pydaptivefiltering.LRLSPriori.__init__", "modulename": "pydaptivefiltering", "qualname": "LRLSPriori.__init__", "kind": "function", "doc": "<h2 id=\"parameters\">Parameters</h2>\n\n<p>filter_order:\n    Number of lattice sections M. Ladder has M+1 coefficients.\nlambda_factor:\n    Forgetting factor \u03bb.\nepsilon:\n    Energy initialization / regularization.\nw_init:\n    Optional initial ladder coefficient vector (length M+1). If None, zeros.\ndenom_floor:\n    Floor used to avoid division by (near) zero in normalization terms.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">filter_order</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">lambda_factor</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">0.99</span>,</span><span class=\"param\">\t<span class=\"n\">epsilon</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">0.1</span>,</span><span class=\"param\">\t<span class=\"n\">w_init</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span><span class=\"p\">,</span> <span class=\"nb\">list</span><span class=\"p\">,</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">denom_floor</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">1e-12</span></span>)</span>"}, {"fullname": "pydaptivefiltering.LRLSPriori.supports_complex", "modulename": "pydaptivefiltering", "qualname": "LRLSPriori.supports_complex", "kind": "variable", "doc": "<p></p>\n", "annotation": ": bool", "default_value": "True"}, {"fullname": "pydaptivefiltering.LRLSPriori.lam", "modulename": "pydaptivefiltering", "qualname": "LRLSPriori.lam", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pydaptivefiltering.LRLSPriori.epsilon", "modulename": "pydaptivefiltering", "qualname": "LRLSPriori.epsilon", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pydaptivefiltering.LRLSPriori.n_sections", "modulename": "pydaptivefiltering", "qualname": "LRLSPriori.n_sections", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pydaptivefiltering.LRLSPriori.delta", "modulename": "pydaptivefiltering", "qualname": "LRLSPriori.delta", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pydaptivefiltering.LRLSPriori.xi_f", "modulename": "pydaptivefiltering", "qualname": "LRLSPriori.xi_f", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pydaptivefiltering.LRLSPriori.xi_b", "modulename": "pydaptivefiltering", "qualname": "LRLSPriori.xi_b", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pydaptivefiltering.LRLSPriori.error_b_prev", "modulename": "pydaptivefiltering", "qualname": "LRLSPriori.error_b_prev", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pydaptivefiltering.LRLSPriori.delta_v", "modulename": "pydaptivefiltering", "qualname": "LRLSPriori.delta_v", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pydaptivefiltering.LRLSPriori.w", "modulename": "pydaptivefiltering", "qualname": "LRLSPriori.w", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pydaptivefiltering.LRLSPriori.w_history", "modulename": "pydaptivefiltering", "qualname": "LRLSPriori.w_history", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pydaptivefiltering.LRLSPriori.optimize", "modulename": "pydaptivefiltering", "qualname": "LRLSPriori.optimize", "kind": "function", "doc": "<p>Executes LRLS adaptation (a priori version) over (x[k], d[k]).</p>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>OptimizationResult\n    outputs:\n        Filter output y[k].\n    errors:\n        A priori error e[k].\n    coefficients:\n        History of ladder coefficients v (mirrored in <code>self.w_history</code>).\n    error_type:\n        \"a_priori\".</p>\n\n<h2 id=\"extra-when-return_internal_statestrue\">Extra (when return_internal_states=True)</h2>\n\n<p>extra[\"xi_f\"], extra[\"xi_b\"], extra[\"delta\"], extra[\"delta_v\"]:\n    Final arrays at the end of adaptation.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">input_signal</span><span class=\"p\">:</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span>,</span><span class=\"param\">\t<span class=\"n\">desired_signal</span><span class=\"p\">:</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span>,</span><span class=\"param\">\t<span class=\"n\">verbose</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">return_internal_states</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span></span><span class=\"return-annotation\">) -> <span class=\"n\">pydaptivefiltering</span><span class=\"o\">.</span><span class=\"n\">base</span><span class=\"o\">.</span><span class=\"n\">OptimizationResult</span>:</span></span>", "funcdef": "def"}, {"fullname": "pydaptivefiltering.NormalizedLRLS", "modulename": "pydaptivefiltering", "qualname": "NormalizedLRLS", "kind": "class", "doc": "<p>Normalized Lattice RLS (NLRLS) algorithm based on a posteriori error.</p>\n\n<p>Implements Algorithm 7.6 (Diniz). The goal of the normalized lattice recursion\nis improved numerical robustness: internal normalized variables (errors and\nreflection-like coefficients) are designed to be magnitude-bounded by 1.</p>\n\n<h2 id=\"library-conventions\">Library conventions</h2>\n\n<ul>\n<li>Complex-valued implementation (supports_complex=True).</li>\n<li>For API consistency, we expose rho_v (length M+1) as the \"coefficient vector\":\n<ul>\n<li>self.w mirrors self.rho_v</li>\n<li>self.w_history stores rho_v trajectories</li>\n<li>optimize returns OptimizationResult with coefficients stacked from w_history</li>\n</ul></li>\n</ul>\n", "bases": "pydaptivefiltering.base.AdaptiveFilter"}, {"fullname": "pydaptivefiltering.NormalizedLRLS.__init__", "modulename": "pydaptivefiltering", "qualname": "NormalizedLRLS.__init__", "kind": "function", "doc": "<h2 id=\"parameters\">Parameters</h2>\n\n<p>filter_order:\n    Number of lattice sections M. The estimation stage uses M+1 coefficients.\nlambda_factor:\n    Forgetting factor \u03bb.\nepsilon:\n    Regularization used in normalizations and clipping.\nw_init:\n    Optional initialization for rho_v (length M+1). If None, zeros.\ndenom_floor:\n    Extra floor for denominators / sqrt protections.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">filter_order</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">lambda_factor</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">0.99</span>,</span><span class=\"param\">\t<span class=\"n\">epsilon</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">1e-06</span>,</span><span class=\"param\">\t<span class=\"n\">w_init</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span><span class=\"p\">,</span> <span class=\"nb\">list</span><span class=\"p\">,</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">denom_floor</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">1e-12</span></span>)</span>"}, {"fullname": "pydaptivefiltering.NormalizedLRLS.supports_complex", "modulename": "pydaptivefiltering", "qualname": "NormalizedLRLS.supports_complex", "kind": "variable", "doc": "<p></p>\n", "annotation": ": bool", "default_value": "True"}, {"fullname": "pydaptivefiltering.NormalizedLRLS.lam", "modulename": "pydaptivefiltering", "qualname": "NormalizedLRLS.lam", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pydaptivefiltering.NormalizedLRLS.epsilon", "modulename": "pydaptivefiltering", "qualname": "NormalizedLRLS.epsilon", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pydaptivefiltering.NormalizedLRLS.n_sections", "modulename": "pydaptivefiltering", "qualname": "NormalizedLRLS.n_sections", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pydaptivefiltering.NormalizedLRLS.rho", "modulename": "pydaptivefiltering", "qualname": "NormalizedLRLS.rho", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pydaptivefiltering.NormalizedLRLS.bar_b_prev", "modulename": "pydaptivefiltering", "qualname": "NormalizedLRLS.bar_b_prev", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pydaptivefiltering.NormalizedLRLS.xi_half", "modulename": "pydaptivefiltering", "qualname": "NormalizedLRLS.xi_half", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pydaptivefiltering.NormalizedLRLS.w", "modulename": "pydaptivefiltering", "qualname": "NormalizedLRLS.w", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pydaptivefiltering.NormalizedLRLS.w_history", "modulename": "pydaptivefiltering", "qualname": "NormalizedLRLS.w_history", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pydaptivefiltering.NormalizedLRLS.optimize", "modulename": "pydaptivefiltering", "qualname": "NormalizedLRLS.optimize", "kind": "function", "doc": "<p>Runs the Normalized LRLS adaptation.</p>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>OptimizationResult\n    outputs:\n        Estimated output y[k].\n    errors:\n        A posteriori error e[k].\n    coefficients:\n        History of rho_v (stacked from w_history).\n    error_type:\n        \"a_posteriori\".</p>\n\n<h2 id=\"extra-when-return_internal_statestrue\">Extra (when return_internal_states=True)</h2>\n\n<p>extra[\"rho\"]:\n    Final rho vector (length M).\nextra[\"rho_v\"]:\n    Final rho_v vector (length M+1).\nextra[\"xi_half\"]:\n    Final xi_half scalar.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">input_signal</span><span class=\"p\">:</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span>,</span><span class=\"param\">\t<span class=\"n\">desired_signal</span><span class=\"p\">:</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span>,</span><span class=\"param\">\t<span class=\"n\">verbose</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">return_internal_states</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span></span><span class=\"return-annotation\">) -> <span class=\"n\">pydaptivefiltering</span><span class=\"o\">.</span><span class=\"n\">base</span><span class=\"o\">.</span><span class=\"n\">OptimizationResult</span>:</span></span>", "funcdef": "def"}, {"fullname": "pydaptivefiltering.FastRLS", "modulename": "pydaptivefiltering", "qualname": "FastRLS", "kind": "class", "doc": "<p>Implements the Fast Transversal RLS algorithm for complex-valued data.</p>\n\n<p>This is a supervised algorithm, i.e., it requires both input_signal and desired_signal.</p>\n", "bases": "pydaptivefiltering.base.AdaptiveFilter"}, {"fullname": "pydaptivefiltering.FastRLS.__init__", "modulename": "pydaptivefiltering", "qualname": "FastRLS.__init__", "kind": "function", "doc": "<h2 id=\"parameters\">Parameters</h2>\n\n<p>filter_order:\n    FIR filter order (number of taps - 1). Number of coefficients is filter_order + 1.\nforgetting_factor:\n    Forgetting factor (lambda), typically close to 1.\nepsilon:\n    Regularization / initial prediction error energy (positive).\nw_init:\n    Optional initial coefficient vector. If None, initializes to zeros.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">filter_order</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">forgetting_factor</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">0.99</span>,</span><span class=\"param\">\t<span class=\"n\">epsilon</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">0.1</span>,</span><span class=\"param\">\t<span class=\"n\">w_init</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span><span class=\"p\">,</span> <span class=\"nb\">list</span><span class=\"p\">,</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span>)</span>"}, {"fullname": "pydaptivefiltering.FastRLS.supports_complex", "modulename": "pydaptivefiltering", "qualname": "FastRLS.supports_complex", "kind": "variable", "doc": "<p></p>\n", "annotation": ": bool", "default_value": "True"}, {"fullname": "pydaptivefiltering.FastRLS.forgetting_factor", "modulename": "pydaptivefiltering", "qualname": "FastRLS.forgetting_factor", "kind": "variable", "doc": "<p></p>\n", "annotation": ": float"}, {"fullname": "pydaptivefiltering.FastRLS.epsilon", "modulename": "pydaptivefiltering", "qualname": "FastRLS.epsilon", "kind": "variable", "doc": "<p></p>\n", "annotation": ": float"}, {"fullname": "pydaptivefiltering.FastRLS.n_coeffs", "modulename": "pydaptivefiltering", "qualname": "FastRLS.n_coeffs", "kind": "variable", "doc": "<p></p>\n", "annotation": ": int"}, {"fullname": "pydaptivefiltering.FastRLS.optimize", "modulename": "pydaptivefiltering", "qualname": "FastRLS.optimize", "kind": "function", "doc": "<p>Executes the Fast Transversal RLS algorithm.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>input_signal:\n    Input signal x[k].\ndesired_signal:\n    Desired signal d[k].\nverbose:\n    If True, prints runtime.\nreturn_internal_states:\n    If True, returns additional internal trajectories in result.extra.</p>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>OptimizationResult\n    outputs:\n        A-priori output y[k].\n    errors:\n        A-priori error e[k] = d[k] - y[k].\n    coefficients:\n        History of coefficients stored in the base class.\n    error_type:\n        \"a_priori\".</p>\n\n<h2 id=\"extra-always\">Extra (always)</h2>\n\n<p>extra[\"outputs_posteriori\"]:\n    A-posteriori output sequence.\nextra[\"errors_posteriori\"]:\n    A-posteriori error sequence.</p>\n\n<h2 id=\"extra-when-return_internal_statestrue\">Extra (when return_internal_states=True)</h2>\n\n<p>extra[\"gamma\"]:\n    Conversion factor trajectory.\nextra[\"xi_min_f\"]:\n    Forward prediction minimum error energy trajectory.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">input_signal</span><span class=\"p\">:</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span>,</span><span class=\"param\">\t<span class=\"n\">desired_signal</span><span class=\"p\">:</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span>,</span><span class=\"param\">\t<span class=\"n\">verbose</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">return_internal_states</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span></span><span class=\"return-annotation\">) -> <span class=\"n\">pydaptivefiltering</span><span class=\"o\">.</span><span class=\"n\">base</span><span class=\"o\">.</span><span class=\"n\">OptimizationResult</span>:</span></span>", "funcdef": "def"}, {"fullname": "pydaptivefiltering.StabFastRLS", "modulename": "pydaptivefiltering", "qualname": "StabFastRLS", "kind": "class", "doc": "<p>Implements the Stabilized Fast Transversal RLS algorithm for real-valued data.</p>\n", "bases": "pydaptivefiltering.base.AdaptiveFilter"}, {"fullname": "pydaptivefiltering.StabFastRLS.__init__", "modulename": "pydaptivefiltering", "qualname": "StabFastRLS.__init__", "kind": "function", "doc": "<h2 id=\"parameters\">Parameters</h2>\n\n<p>filter_order:\n    FIR filter order (number of taps - 1). Number of coefficients is filter_order + 1.\nforgetting_factor:\n    Forgetting factor (lambda), typically close to 1.\nepsilon:\n    Regularization / initial prediction error energy (positive).\nkappa1, kappa2, kappa3:\n    Stabilization parameters from the stabilized FTRLS formulation.\nw_init:\n    Optional initial coefficient vector. If None, initializes to zeros.\ndenom_floor:\n    Floor for denominators used in safe inversions. If None, a tiny float-based default is used.\nxi_floor:\n    Floor for prediction error energies. If None, a tiny float-based default is used.\ngamma_clip:\n    Optional clipping threshold for gamma (if provided).</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">filter_order</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">forgetting_factor</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">0.99</span>,</span><span class=\"param\">\t<span class=\"n\">epsilon</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">0.1</span>,</span><span class=\"param\">\t<span class=\"n\">kappa1</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">1.5</span>,</span><span class=\"param\">\t<span class=\"n\">kappa2</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">2.5</span>,</span><span class=\"param\">\t<span class=\"n\">kappa3</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">1.0</span>,</span><span class=\"param\">\t<span class=\"n\">w_init</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span><span class=\"p\">,</span> <span class=\"nb\">list</span><span class=\"p\">,</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">denom_floor</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">float</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">xi_floor</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">float</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">gamma_clip</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">float</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span>)</span>"}, {"fullname": "pydaptivefiltering.StabFastRLS.supports_complex", "modulename": "pydaptivefiltering", "qualname": "StabFastRLS.supports_complex", "kind": "variable", "doc": "<p></p>\n", "annotation": ": bool", "default_value": "False"}, {"fullname": "pydaptivefiltering.StabFastRLS.lambda_", "modulename": "pydaptivefiltering", "qualname": "StabFastRLS.lambda_", "kind": "variable", "doc": "<p></p>\n", "annotation": ": float"}, {"fullname": "pydaptivefiltering.StabFastRLS.epsilon", "modulename": "pydaptivefiltering", "qualname": "StabFastRLS.epsilon", "kind": "variable", "doc": "<p></p>\n", "annotation": ": float"}, {"fullname": "pydaptivefiltering.StabFastRLS.kappa1", "modulename": "pydaptivefiltering", "qualname": "StabFastRLS.kappa1", "kind": "variable", "doc": "<p></p>\n", "annotation": ": float"}, {"fullname": "pydaptivefiltering.StabFastRLS.kappa2", "modulename": "pydaptivefiltering", "qualname": "StabFastRLS.kappa2", "kind": "variable", "doc": "<p></p>\n", "annotation": ": float"}, {"fullname": "pydaptivefiltering.StabFastRLS.kappa3", "modulename": "pydaptivefiltering", "qualname": "StabFastRLS.kappa3", "kind": "variable", "doc": "<p></p>\n", "annotation": ": float"}, {"fullname": "pydaptivefiltering.StabFastRLS.denom_floor", "modulename": "pydaptivefiltering", "qualname": "StabFastRLS.denom_floor", "kind": "variable", "doc": "<p></p>\n", "annotation": ": float"}, {"fullname": "pydaptivefiltering.StabFastRLS.xi_floor", "modulename": "pydaptivefiltering", "qualname": "StabFastRLS.xi_floor", "kind": "variable", "doc": "<p></p>\n", "annotation": ": float"}, {"fullname": "pydaptivefiltering.StabFastRLS.gamma_clip", "modulename": "pydaptivefiltering", "qualname": "StabFastRLS.gamma_clip", "kind": "variable", "doc": "<p></p>\n", "annotation": ": Optional[float]"}, {"fullname": "pydaptivefiltering.StabFastRLS.n_coeffs", "modulename": "pydaptivefiltering", "qualname": "StabFastRLS.n_coeffs", "kind": "variable", "doc": "<p></p>\n", "annotation": ": int"}, {"fullname": "pydaptivefiltering.StabFastRLS.filter_order", "modulename": "pydaptivefiltering", "qualname": "StabFastRLS.filter_order", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pydaptivefiltering.StabFastRLS.w", "modulename": "pydaptivefiltering", "qualname": "StabFastRLS.w", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pydaptivefiltering.StabFastRLS.optimize", "modulename": "pydaptivefiltering", "qualname": "StabFastRLS.optimize", "kind": "function", "doc": "<p>Executes the Stabilized Fast Transversal RLS algorithm.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>input_signal:\n    Input signal x[k].\ndesired_signal:\n    Desired signal d[k].\nverbose:\n    If True, prints runtime.\nreturn_internal_states:\n    If True, returns internal trajectories and clamping stats in result.extra.</p>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>OptimizationResult\n    outputs:\n        A-priori output y[k].\n    errors:\n        A-priori error e[k] = d[k] - y[k].\n    coefficients:\n        History of coefficients stored in the base class.\n    error_type:\n        \"a_priori\".</p>\n\n<h2 id=\"extra-always\">Extra (always)</h2>\n\n<p>extra[\"errors_posteriori\"]:\n    A-posteriori error sequence e_post[k] = gamma[k] * e[k].\nextra[\"clamp_stats\"]:\n    Dictionary with counters of how many times each denominator was clamped.</p>\n\n<h2 id=\"extra-when-return_internal_statestrue\">Extra (when return_internal_states=True)</h2>\n\n<p>extra[\"xi_min_f\"]:\n    Forward prediction error energy trajectory.\nextra[\"xi_min_b\"]:\n    Backward prediction error energy trajectory.\nextra[\"gamma\"]:\n    Conversion factor trajectory.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">input_signal</span><span class=\"p\">:</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span>,</span><span class=\"param\">\t<span class=\"n\">desired_signal</span><span class=\"p\">:</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span>,</span><span class=\"param\">\t<span class=\"n\">verbose</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">return_internal_states</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span></span><span class=\"return-annotation\">) -> <span class=\"n\">pydaptivefiltering</span><span class=\"o\">.</span><span class=\"n\">base</span><span class=\"o\">.</span><span class=\"n\">OptimizationResult</span>:</span></span>", "funcdef": "def"}, {"fullname": "pydaptivefiltering.QRRLS", "modulename": "pydaptivefiltering", "qualname": "QRRLS", "kind": "class", "doc": "<p>QR-RLS (real-valued) using Givens rotations.</p>\n\n<p>Implements Algorithm 9.1 (Diniz, 3rd ed.) in a QR-decomposition framework.\nThis version mirrors the provided MATLAB routine (QR_RLS.m) and keeps the\nsame internal state variables.</p>\n\n<h2 id=\"key-internal-state-matlab-naming\">Key internal state (MATLAB naming)</h2>\n\n<p>ULineMatrix:\n    Square matrix updated by sequential Givens rotations (size n_coeffs x n_coeffs).\ndLine_q2:\n    Transformed desired vector (size n_coeffs,).\ngamma:\n    Likelihood scalar accumulated as a product of cosines in the Givens steps.</p>\n\n<h2 id=\"notes\">Notes</h2>\n\n<ul>\n<li>Real-valued only (supports_complex=False).</li>\n<li>The returned <code>errors</code> correspond to the MATLAB <code>errorVector</code>:\n  e[k] = d_line * gamma\nand the output is:\n  y[k] = d[k] - e[k]\nTherefore we label <code>error_type=\"a_posteriori\"</code> to match the MATLAB-style\n\u201cpost-rotation\u201d error quantity.</li>\n</ul>\n", "bases": "pydaptivefiltering.base.AdaptiveFilter"}, {"fullname": "pydaptivefiltering.QRRLS.__init__", "modulename": "pydaptivefiltering", "qualname": "QRRLS.__init__", "kind": "function", "doc": "<h2 id=\"parameters\">Parameters</h2>\n\n<p>filter_order:\n    FIR order M (number of coefficients is M+1).\nlamb:\n    Forgetting factor \u03bb, must satisfy 0 &lt; \u03bb &lt;= 1.\nw_init:\n    Optional initial coefficients (length M+1). If None, zeros are used.\ndenom_floor:\n    Small floor used to avoid division by (near) zero in scalar denominators.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">filter_order</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">lamb</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">0.99</span>,</span><span class=\"param\">\t<span class=\"n\">w_init</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span><span class=\"p\">,</span> <span class=\"nb\">list</span><span class=\"p\">,</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"o\">*</span>,</span><span class=\"param\">\t<span class=\"n\">denom_floor</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">1e-18</span></span>)</span>"}, {"fullname": "pydaptivefiltering.QRRLS.supports_complex", "modulename": "pydaptivefiltering", "qualname": "QRRLS.supports_complex", "kind": "variable", "doc": "<p></p>\n", "annotation": ": bool", "default_value": "False"}, {"fullname": "pydaptivefiltering.QRRLS.lamb", "modulename": "pydaptivefiltering", "qualname": "QRRLS.lamb", "kind": "variable", "doc": "<p></p>\n", "annotation": ": float"}, {"fullname": "pydaptivefiltering.QRRLS.n_coeffs", "modulename": "pydaptivefiltering", "qualname": "QRRLS.n_coeffs", "kind": "variable", "doc": "<p></p>\n", "annotation": ": int"}, {"fullname": "pydaptivefiltering.QRRLS.ULineMatrix", "modulename": "pydaptivefiltering", "qualname": "QRRLS.ULineMatrix", "kind": "variable", "doc": "<p></p>\n", "annotation": ": numpy.ndarray"}, {"fullname": "pydaptivefiltering.QRRLS.dLine_q2", "modulename": "pydaptivefiltering", "qualname": "QRRLS.dLine_q2", "kind": "variable", "doc": "<p></p>\n", "annotation": ": numpy.ndarray"}, {"fullname": "pydaptivefiltering.QRRLS.w", "modulename": "pydaptivefiltering", "qualname": "QRRLS.w", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pydaptivefiltering.QRRLS.w_history", "modulename": "pydaptivefiltering", "qualname": "QRRLS.w_history", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pydaptivefiltering.QRRLS.optimize", "modulename": "pydaptivefiltering", "qualname": "QRRLS.optimize", "kind": "function", "doc": "<p>Run QR-RLS adaptation over (x[k], d[k]) using the MATLAB-style recursion.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>input_signal:\n    Input sequence x[k] (real), shape (N,).\ndesired_signal:\n    Desired sequence d[k] (real), shape (N,).\nverbose:\n    If True, prints runtime.\nreturn_internal_states:\n    If True, includes selected internal state in <code>result.extra</code>.</p>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>OptimizationResult\n    outputs:\n        Estimated output y[k] (real).\n    errors:\n        MATLAB-style error quantity e[k] = d_line * gamma (real).\n    coefficients:\n        History of coefficients stored in the base class.\n    error_type:\n        \"a_posteriori\".</p>\n\n<h2 id=\"extra-when-return_internal_statestrue\">Extra (when return_internal_states=True)</h2>\n\n<p>extra[\"ULineMatrix_last\"]:\n    Final ULineMatrix.\nextra[\"dLine_q2_last\"]:\n    Final dLine_q2.\nextra[\"gamma_last\"]:\n    gamma at the last iteration.\nextra[\"d_line_last\"]:\n    d_line at the last iteration.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">input_signal</span><span class=\"p\">:</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span>,</span><span class=\"param\">\t<span class=\"n\">desired_signal</span><span class=\"p\">:</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span>,</span><span class=\"param\">\t<span class=\"n\">verbose</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">return_internal_states</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span></span><span class=\"return-annotation\">) -> <span class=\"n\">pydaptivefiltering</span><span class=\"o\">.</span><span class=\"n\">base</span><span class=\"o\">.</span><span class=\"n\">OptimizationResult</span>:</span></span>", "funcdef": "def"}, {"fullname": "pydaptivefiltering.ErrorEquation", "modulename": "pydaptivefiltering", "qualname": "ErrorEquation", "kind": "class", "doc": "<p>Implements the Equation Error RLS algorithm for real-valued IIR adaptive filtering.</p>\n", "bases": "pydaptivefiltering.base.AdaptiveFilter"}, {"fullname": "pydaptivefiltering.ErrorEquation.__init__", "modulename": "pydaptivefiltering", "qualname": "ErrorEquation.__init__", "kind": "function", "doc": "<h2 id=\"parameters\">Parameters</h2>\n\n<p>zeros_order:\n    Numerator order (number of zeros).\npoles_order:\n    Denominator order (number of poles).\nforgetting_factor:\n    Forgetting factor (lambda), typically close to 1.\nepsilon:\n    Regularization / initialization parameter for the inverse correlation matrix.\nw_init:\n    Optional initial coefficient vector. If None, initializes to zeros.</p>\n\n<h2 id=\"notes\">Notes</h2>\n\n<p>Coefficient vector convention:</p>\n\n<ul>\n<li>First <code>poles_order</code> entries correspond to denominator (pole) parameters.</li>\n<li>Remaining entries correspond to numerator (zero) parameters.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">zeros_order</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">poles_order</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">forgetting_factor</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">0.99</span>,</span><span class=\"param\">\t<span class=\"n\">epsilon</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">0.001</span>,</span><span class=\"param\">\t<span class=\"n\">w_init</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span><span class=\"p\">,</span> <span class=\"nb\">list</span><span class=\"p\">,</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span>)</span>"}, {"fullname": "pydaptivefiltering.ErrorEquation.supports_complex", "modulename": "pydaptivefiltering", "qualname": "ErrorEquation.supports_complex", "kind": "variable", "doc": "<p></p>\n", "annotation": ": bool", "default_value": "False"}, {"fullname": "pydaptivefiltering.ErrorEquation.zeros_order", "modulename": "pydaptivefiltering", "qualname": "ErrorEquation.zeros_order", "kind": "variable", "doc": "<p></p>\n", "annotation": ": int"}, {"fullname": "pydaptivefiltering.ErrorEquation.poles_order", "modulename": "pydaptivefiltering", "qualname": "ErrorEquation.poles_order", "kind": "variable", "doc": "<p></p>\n", "annotation": ": int"}, {"fullname": "pydaptivefiltering.ErrorEquation.forgetting_factor", "modulename": "pydaptivefiltering", "qualname": "ErrorEquation.forgetting_factor", "kind": "variable", "doc": "<p></p>\n", "annotation": ": float"}, {"fullname": "pydaptivefiltering.ErrorEquation.epsilon", "modulename": "pydaptivefiltering", "qualname": "ErrorEquation.epsilon", "kind": "variable", "doc": "<p></p>\n", "annotation": ": float"}, {"fullname": "pydaptivefiltering.ErrorEquation.n_coeffs", "modulename": "pydaptivefiltering", "qualname": "ErrorEquation.n_coeffs", "kind": "variable", "doc": "<p></p>\n", "annotation": ": int"}, {"fullname": "pydaptivefiltering.ErrorEquation.Sd", "modulename": "pydaptivefiltering", "qualname": "ErrorEquation.Sd", "kind": "variable", "doc": "<p></p>\n", "annotation": ": numpy.ndarray"}, {"fullname": "pydaptivefiltering.ErrorEquation.y_buffer", "modulename": "pydaptivefiltering", "qualname": "ErrorEquation.y_buffer", "kind": "variable", "doc": "<p></p>\n", "annotation": ": numpy.ndarray"}, {"fullname": "pydaptivefiltering.ErrorEquation.d_buffer", "modulename": "pydaptivefiltering", "qualname": "ErrorEquation.d_buffer", "kind": "variable", "doc": "<p></p>\n", "annotation": ": numpy.ndarray"}, {"fullname": "pydaptivefiltering.ErrorEquation.w", "modulename": "pydaptivefiltering", "qualname": "ErrorEquation.w", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pydaptivefiltering.ErrorEquation.optimize", "modulename": "pydaptivefiltering", "qualname": "ErrorEquation.optimize", "kind": "function", "doc": "<p>Executes the Equation Error RLS algorithm for IIR filters.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>input_signal:\n    Input signal x[k].\ndesired_signal:\n    Desired signal d[k].\nverbose:\n    If True, prints runtime.\nreturn_internal_states:\n    If True, returns pole coefficients trajectory in result.extra.</p>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>OptimizationResult\n    outputs:\n        Filter output y[k] computed from the output equation.\n    errors:\n        Output error e[k] = d[k] - y[k].\n    coefficients:\n        History of coefficients stored in the base class.\n    error_type:\n        \"equation_error\".</p>\n\n<h2 id=\"extra-always\">Extra (always)</h2>\n\n<p>extra[\"auxiliary_errors\"]:\n    Equation-error based auxiliary error sequence.</p>\n\n<h2 id=\"extra-when-return_internal_statestrue\">Extra (when return_internal_states=True)</h2>\n\n<p>extra[\"a_coefficients\"]:\n    Trajectory of denominator (pole) coefficients, shape (N, poles_order).</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">input_signal</span><span class=\"p\">:</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span>,</span><span class=\"param\">\t<span class=\"n\">desired_signal</span><span class=\"p\">:</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span>,</span><span class=\"param\">\t<span class=\"n\">verbose</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">return_internal_states</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span></span><span class=\"return-annotation\">) -> <span class=\"n\">pydaptivefiltering</span><span class=\"o\">.</span><span class=\"n\">base</span><span class=\"o\">.</span><span class=\"n\">OptimizationResult</span>:</span></span>", "funcdef": "def"}, {"fullname": "pydaptivefiltering.GaussNewton", "modulename": "pydaptivefiltering", "qualname": "GaussNewton", "kind": "class", "doc": "<p>Implements the Gauss-Newton algorithm for real-valued IIR adaptive filters.</p>\n\n<h2 id=\"notes\">Notes</h2>\n\n<p>Coefficient vector convention:</p>\n\n<ul>\n<li>First <code>poles_order</code> entries correspond to denominator (pole) parameters.</li>\n<li>Remaining entries correspond to numerator (zero) parameters.</li>\n</ul>\n", "bases": "pydaptivefiltering.base.AdaptiveFilter"}, {"fullname": "pydaptivefiltering.GaussNewton.__init__", "modulename": "pydaptivefiltering", "qualname": "GaussNewton.__init__", "kind": "function", "doc": "<h2 id=\"parameters\">Parameters</h2>\n\n<p>zeros_order:\n    Numerator order (number of zeros).\npoles_order:\n    Denominator order (number of poles).\nalpha:\n    Exponential weighting factor used in the recursion (0 &lt; alpha &lt; 1).\nstep_size:\n    Step size applied to the Gauss-Newton update.\ndelta:\n    Regularization parameter used to initialize Sd.\nw_init:\n    Optional initial coefficient vector. If None, initializes to zeros.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">zeros_order</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">poles_order</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">alpha</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">0.05</span>,</span><span class=\"param\">\t<span class=\"n\">step_size</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">1.0</span>,</span><span class=\"param\">\t<span class=\"n\">delta</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">0.001</span>,</span><span class=\"param\">\t<span class=\"n\">w_init</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span><span class=\"p\">,</span> <span class=\"nb\">list</span><span class=\"p\">,</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span>)</span>"}, {"fullname": "pydaptivefiltering.GaussNewton.supports_complex", "modulename": "pydaptivefiltering", "qualname": "GaussNewton.supports_complex", "kind": "variable", "doc": "<p></p>\n", "annotation": ": bool", "default_value": "False"}, {"fullname": "pydaptivefiltering.GaussNewton.zeros_order", "modulename": "pydaptivefiltering", "qualname": "GaussNewton.zeros_order", "kind": "variable", "doc": "<p></p>\n", "annotation": ": int"}, {"fullname": "pydaptivefiltering.GaussNewton.poles_order", "modulename": "pydaptivefiltering", "qualname": "GaussNewton.poles_order", "kind": "variable", "doc": "<p></p>\n", "annotation": ": int"}, {"fullname": "pydaptivefiltering.GaussNewton.alpha", "modulename": "pydaptivefiltering", "qualname": "GaussNewton.alpha", "kind": "variable", "doc": "<p></p>\n", "annotation": ": float"}, {"fullname": "pydaptivefiltering.GaussNewton.step_size", "modulename": "pydaptivefiltering", "qualname": "GaussNewton.step_size", "kind": "variable", "doc": "<p></p>\n", "annotation": ": float"}, {"fullname": "pydaptivefiltering.GaussNewton.delta", "modulename": "pydaptivefiltering", "qualname": "GaussNewton.delta", "kind": "variable", "doc": "<p></p>\n", "annotation": ": float"}, {"fullname": "pydaptivefiltering.GaussNewton.n_coeffs", "modulename": "pydaptivefiltering", "qualname": "GaussNewton.n_coeffs", "kind": "variable", "doc": "<p></p>\n", "annotation": ": int"}, {"fullname": "pydaptivefiltering.GaussNewton.Sd", "modulename": "pydaptivefiltering", "qualname": "GaussNewton.Sd", "kind": "variable", "doc": "<p></p>\n", "annotation": ": numpy.ndarray"}, {"fullname": "pydaptivefiltering.GaussNewton.y_buffer", "modulename": "pydaptivefiltering", "qualname": "GaussNewton.y_buffer", "kind": "variable", "doc": "<p></p>\n", "annotation": ": numpy.ndarray"}, {"fullname": "pydaptivefiltering.GaussNewton.x_line_buffer", "modulename": "pydaptivefiltering", "qualname": "GaussNewton.x_line_buffer", "kind": "variable", "doc": "<p></p>\n", "annotation": ": numpy.ndarray"}, {"fullname": "pydaptivefiltering.GaussNewton.y_line_buffer", "modulename": "pydaptivefiltering", "qualname": "GaussNewton.y_line_buffer", "kind": "variable", "doc": "<p></p>\n", "annotation": ": numpy.ndarray"}, {"fullname": "pydaptivefiltering.GaussNewton.w", "modulename": "pydaptivefiltering", "qualname": "GaussNewton.w", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pydaptivefiltering.GaussNewton.optimize", "modulename": "pydaptivefiltering", "qualname": "GaussNewton.optimize", "kind": "function", "doc": "<p>Executes the Gauss-Newton adaptation.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>input_signal:\n    Input signal x[k].\ndesired_signal:\n    Desired signal d[k].\nverbose:\n    If True, prints runtime.\nreturn_internal_states:\n    If True, returns sensitivity signals in result.extra.</p>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>OptimizationResult\n    outputs:\n        Filter output y[k].\n    errors:\n        Output error e[k] = d[k] - y[k].\n    coefficients:\n        History of coefficients stored in the base class.\n    error_type:\n        \"output_error\".</p>\n\n<h2 id=\"extra-when-return_internal_statestrue\">Extra (when return_internal_states=True)</h2>\n\n<p>extra[\"x_sensitivity\"]:\n    Sensitivity-related track (x_line), length N.\nextra[\"y_sensitivity\"]:\n    Sensitivity-related track (y_line), length N.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">input_signal</span><span class=\"p\">:</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span>,</span><span class=\"param\">\t<span class=\"n\">desired_signal</span><span class=\"p\">:</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span>,</span><span class=\"param\">\t<span class=\"n\">verbose</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">return_internal_states</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span></span><span class=\"return-annotation\">) -> <span class=\"n\">pydaptivefiltering</span><span class=\"o\">.</span><span class=\"n\">base</span><span class=\"o\">.</span><span class=\"n\">OptimizationResult</span>:</span></span>", "funcdef": "def"}, {"fullname": "pydaptivefiltering.GaussNewtonGradient", "modulename": "pydaptivefiltering", "qualname": "GaussNewtonGradient", "kind": "class", "doc": "<p>Implements the gradient-based Gauss-Newton algorithm for real-valued IIR adaptive filters.</p>\n", "bases": "pydaptivefiltering.base.AdaptiveFilter"}, {"fullname": "pydaptivefiltering.GaussNewtonGradient.__init__", "modulename": "pydaptivefiltering", "qualname": "GaussNewtonGradient.__init__", "kind": "function", "doc": "<h2 id=\"parameters\">Parameters</h2>\n\n<p>zeros_order:\n    Numerator order (number of zeros).\npoles_order:\n    Denominator order (number of poles).\nstep_size:\n    Gradient step size.\nw_init:\n    Optional initial coefficient vector. If None, initializes to zeros.</p>\n\n<h2 id=\"notes\">Notes</h2>\n\n<p>Coefficient vector convention:</p>\n\n<ul>\n<li>First <code>poles_order</code> entries correspond to denominator (pole) parameters.</li>\n<li>Remaining entries correspond to numerator (zero) parameters.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">zeros_order</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">poles_order</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">step_size</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">0.001</span>,</span><span class=\"param\">\t<span class=\"n\">w_init</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span><span class=\"p\">,</span> <span class=\"nb\">list</span><span class=\"p\">,</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span>)</span>"}, {"fullname": "pydaptivefiltering.GaussNewtonGradient.supports_complex", "modulename": "pydaptivefiltering", "qualname": "GaussNewtonGradient.supports_complex", "kind": "variable", "doc": "<p></p>\n", "annotation": ": bool", "default_value": "False"}, {"fullname": "pydaptivefiltering.GaussNewtonGradient.zeros_order", "modulename": "pydaptivefiltering", "qualname": "GaussNewtonGradient.zeros_order", "kind": "variable", "doc": "<p></p>\n", "annotation": ": int"}, {"fullname": "pydaptivefiltering.GaussNewtonGradient.poles_order", "modulename": "pydaptivefiltering", "qualname": "GaussNewtonGradient.poles_order", "kind": "variable", "doc": "<p></p>\n", "annotation": ": int"}, {"fullname": "pydaptivefiltering.GaussNewtonGradient.step_size", "modulename": "pydaptivefiltering", "qualname": "GaussNewtonGradient.step_size", "kind": "variable", "doc": "<p></p>\n", "annotation": ": float"}, {"fullname": "pydaptivefiltering.GaussNewtonGradient.n_coeffs", "modulename": "pydaptivefiltering", "qualname": "GaussNewtonGradient.n_coeffs", "kind": "variable", "doc": "<p></p>\n", "annotation": ": int"}, {"fullname": "pydaptivefiltering.GaussNewtonGradient.y_buffer", "modulename": "pydaptivefiltering", "qualname": "GaussNewtonGradient.y_buffer", "kind": "variable", "doc": "<p></p>\n", "annotation": ": numpy.ndarray"}, {"fullname": "pydaptivefiltering.GaussNewtonGradient.x_line_buffer", "modulename": "pydaptivefiltering", "qualname": "GaussNewtonGradient.x_line_buffer", "kind": "variable", "doc": "<p></p>\n", "annotation": ": numpy.ndarray"}, {"fullname": "pydaptivefiltering.GaussNewtonGradient.y_line_buffer", "modulename": "pydaptivefiltering", "qualname": "GaussNewtonGradient.y_line_buffer", "kind": "variable", "doc": "<p></p>\n", "annotation": ": numpy.ndarray"}, {"fullname": "pydaptivefiltering.GaussNewtonGradient.w", "modulename": "pydaptivefiltering", "qualname": "GaussNewtonGradient.w", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pydaptivefiltering.GaussNewtonGradient.optimize", "modulename": "pydaptivefiltering", "qualname": "GaussNewtonGradient.optimize", "kind": "function", "doc": "<p>Executes the gradient-based Gauss-Newton adaptation.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>input_signal:\n    Input signal x[k].\ndesired_signal:\n    Desired signal d[k].\nverbose:\n    If True, prints runtime.\nreturn_internal_states:\n    If True, returns sensitivity signals in result.extra.</p>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>OptimizationResult\n    outputs:\n        Filter output y[k].\n    errors:\n        Output error e[k] = d[k] - y[k].\n    coefficients:\n        History of coefficients stored in the base class.\n    error_type:\n        \"output_error\".</p>\n\n<h2 id=\"extra-when-return_internal_statestrue\">Extra (when return_internal_states=True)</h2>\n\n<p>extra[\"x_sensitivity\"]:\n    Sensitivity-related track (x_line), length N.\nextra[\"y_sensitivity\"]:\n    Sensitivity-related track (y_line), length N.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">input_signal</span><span class=\"p\">:</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span>,</span><span class=\"param\">\t<span class=\"n\">desired_signal</span><span class=\"p\">:</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span>,</span><span class=\"param\">\t<span class=\"n\">verbose</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">return_internal_states</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span></span><span class=\"return-annotation\">) -> <span class=\"n\">pydaptivefiltering</span><span class=\"o\">.</span><span class=\"n\">base</span><span class=\"o\">.</span><span class=\"n\">OptimizationResult</span>:</span></span>", "funcdef": "def"}, {"fullname": "pydaptivefiltering.RLSIIR", "modulename": "pydaptivefiltering", "qualname": "RLSIIR", "kind": "class", "doc": "<p>Implements the RLS version of the Output Error algorithm for real-valued IIR adaptive filters.</p>\n\n<h2 id=\"notes\">Notes</h2>\n\n<p>Coefficient vector convention:</p>\n\n<ul>\n<li>First <code>poles_order</code> entries correspond to denominator (pole) parameters.</li>\n<li>Remaining entries correspond to numerator (zero) parameters.</li>\n</ul>\n", "bases": "pydaptivefiltering.base.AdaptiveFilter"}, {"fullname": "pydaptivefiltering.RLSIIR.__init__", "modulename": "pydaptivefiltering", "qualname": "RLSIIR.__init__", "kind": "function", "doc": "<h2 id=\"parameters\">Parameters</h2>\n\n<p>zeros_order:\n    Numerator order (number of zeros).\npoles_order:\n    Denominator order (number of poles).\nforgetting_factor:\n    Forgetting factor (lambda), typically close to 1.\ndelta:\n    Regularization parameter used to initialize Sd (inverse covariance).\nw_init:\n    Optional initial coefficient vector. If None, initializes to zeros.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">zeros_order</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">poles_order</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">forgetting_factor</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">0.99</span>,</span><span class=\"param\">\t<span class=\"n\">delta</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">0.001</span>,</span><span class=\"param\">\t<span class=\"n\">w_init</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span><span class=\"p\">,</span> <span class=\"nb\">list</span><span class=\"p\">,</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span>)</span>"}, {"fullname": "pydaptivefiltering.RLSIIR.supports_complex", "modulename": "pydaptivefiltering", "qualname": "RLSIIR.supports_complex", "kind": "variable", "doc": "<p></p>\n", "annotation": ": bool", "default_value": "False"}, {"fullname": "pydaptivefiltering.RLSIIR.zeros_order", "modulename": "pydaptivefiltering", "qualname": "RLSIIR.zeros_order", "kind": "variable", "doc": "<p></p>\n", "annotation": ": int"}, {"fullname": "pydaptivefiltering.RLSIIR.poles_order", "modulename": "pydaptivefiltering", "qualname": "RLSIIR.poles_order", "kind": "variable", "doc": "<p></p>\n", "annotation": ": int"}, {"fullname": "pydaptivefiltering.RLSIIR.forgetting_factor", "modulename": "pydaptivefiltering", "qualname": "RLSIIR.forgetting_factor", "kind": "variable", "doc": "<p></p>\n", "annotation": ": float"}, {"fullname": "pydaptivefiltering.RLSIIR.delta", "modulename": "pydaptivefiltering", "qualname": "RLSIIR.delta", "kind": "variable", "doc": "<p></p>\n", "annotation": ": float"}, {"fullname": "pydaptivefiltering.RLSIIR.n_coeffs", "modulename": "pydaptivefiltering", "qualname": "RLSIIR.n_coeffs", "kind": "variable", "doc": "<p></p>\n", "annotation": ": int"}, {"fullname": "pydaptivefiltering.RLSIIR.Sd", "modulename": "pydaptivefiltering", "qualname": "RLSIIR.Sd", "kind": "variable", "doc": "<p></p>\n", "annotation": ": numpy.ndarray"}, {"fullname": "pydaptivefiltering.RLSIIR.y_buffer", "modulename": "pydaptivefiltering", "qualname": "RLSIIR.y_buffer", "kind": "variable", "doc": "<p></p>\n", "annotation": ": numpy.ndarray"}, {"fullname": "pydaptivefiltering.RLSIIR.x_line_buffer", "modulename": "pydaptivefiltering", "qualname": "RLSIIR.x_line_buffer", "kind": "variable", "doc": "<p></p>\n", "annotation": ": numpy.ndarray"}, {"fullname": "pydaptivefiltering.RLSIIR.y_line_buffer", "modulename": "pydaptivefiltering", "qualname": "RLSIIR.y_line_buffer", "kind": "variable", "doc": "<p></p>\n", "annotation": ": numpy.ndarray"}, {"fullname": "pydaptivefiltering.RLSIIR.w", "modulename": "pydaptivefiltering", "qualname": "RLSIIR.w", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pydaptivefiltering.RLSIIR.optimize", "modulename": "pydaptivefiltering", "qualname": "RLSIIR.optimize", "kind": "function", "doc": "<p>Executes the RLS-IIR (Output Error) adaptation.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>input_signal:\n    Input signal x[k].\ndesired_signal:\n    Desired signal d[k].\nverbose:\n    If True, prints runtime.\nreturn_internal_states:\n    If True, returns sensitivity signals in result.extra.</p>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>OptimizationResult\n    outputs:\n        Filter output y[k].\n    errors:\n        Output error e[k] = d[k] - y[k].\n    coefficients:\n        History of coefficients stored in the base class.\n    error_type:\n        \"output_error\".</p>\n\n<h2 id=\"extra-when-return_internal_statestrue\">Extra (when return_internal_states=True)</h2>\n\n<p>extra[\"x_sensitivity\"]:\n    Sensitivity-related track (x_line), length N.\nextra[\"y_sensitivity\"]:\n    Sensitivity-related track (y_line), length N.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">input_signal</span><span class=\"p\">:</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span>,</span><span class=\"param\">\t<span class=\"n\">desired_signal</span><span class=\"p\">:</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span>,</span><span class=\"param\">\t<span class=\"n\">verbose</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">return_internal_states</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span></span><span class=\"return-annotation\">) -> <span class=\"n\">pydaptivefiltering</span><span class=\"o\">.</span><span class=\"n\">base</span><span class=\"o\">.</span><span class=\"n\">OptimizationResult</span>:</span></span>", "funcdef": "def"}, {"fullname": "pydaptivefiltering.SteiglitzMcBride", "modulename": "pydaptivefiltering", "qualname": "SteiglitzMcBride", "kind": "class", "doc": "<p>Implements the Steiglitz-McBride (SM) algorithm for real-valued IIR adaptive filters.</p>\n\n<h2 id=\"notes\">Notes</h2>\n\n<p>This implementation follows the <em>classic</em> Steiglitz-McBride idea:</p>\n\n<ul>\n<li>Build a prefiltered (approximately linear) regression using the current denominator estimate.</li>\n<li>Update coefficients using the <em>filtered equation error</em> (auxiliary error).</li>\n</ul>\n\n<p>Coefficient vector convention:</p>\n\n<ul>\n<li>First <code>poles_order</code> entries correspond to denominator (pole) parameters.</li>\n<li>Remaining entries correspond to numerator (zero) parameters.</li>\n</ul>\n", "bases": "pydaptivefiltering.base.AdaptiveFilter"}, {"fullname": "pydaptivefiltering.SteiglitzMcBride.__init__", "modulename": "pydaptivefiltering", "qualname": "SteiglitzMcBride.__init__", "kind": "function", "doc": "<h2 id=\"parameters\">Parameters</h2>\n\n<p>zeros_order:\n    Numerator order (number of zeros).\npoles_order:\n    Denominator order (number of poles).\nstep_size:\n    Step size used in the coefficient update.\nw_init:\n    Optional initial coefficient vector. If None, initializes to zeros.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">zeros_order</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">poles_order</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">step_size</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">0.001</span>,</span><span class=\"param\">\t<span class=\"n\">w_init</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span><span class=\"p\">,</span> <span class=\"nb\">list</span><span class=\"p\">,</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span>)</span>"}, {"fullname": "pydaptivefiltering.SteiglitzMcBride.supports_complex", "modulename": "pydaptivefiltering", "qualname": "SteiglitzMcBride.supports_complex", "kind": "variable", "doc": "<p></p>\n", "annotation": ": bool", "default_value": "False"}, {"fullname": "pydaptivefiltering.SteiglitzMcBride.zeros_order", "modulename": "pydaptivefiltering", "qualname": "SteiglitzMcBride.zeros_order", "kind": "variable", "doc": "<p></p>\n", "annotation": ": int"}, {"fullname": "pydaptivefiltering.SteiglitzMcBride.poles_order", "modulename": "pydaptivefiltering", "qualname": "SteiglitzMcBride.poles_order", "kind": "variable", "doc": "<p></p>\n", "annotation": ": int"}, {"fullname": "pydaptivefiltering.SteiglitzMcBride.step_size", "modulename": "pydaptivefiltering", "qualname": "SteiglitzMcBride.step_size", "kind": "variable", "doc": "<p></p>\n", "annotation": ": float"}, {"fullname": "pydaptivefiltering.SteiglitzMcBride.n_coeffs", "modulename": "pydaptivefiltering", "qualname": "SteiglitzMcBride.n_coeffs", "kind": "variable", "doc": "<p></p>\n", "annotation": ": int"}, {"fullname": "pydaptivefiltering.SteiglitzMcBride.y_buffer", "modulename": "pydaptivefiltering", "qualname": "SteiglitzMcBride.y_buffer", "kind": "variable", "doc": "<p></p>\n", "annotation": ": numpy.ndarray"}, {"fullname": "pydaptivefiltering.SteiglitzMcBride.xf_buffer", "modulename": "pydaptivefiltering", "qualname": "SteiglitzMcBride.xf_buffer", "kind": "variable", "doc": "<p></p>\n", "annotation": ": numpy.ndarray"}, {"fullname": "pydaptivefiltering.SteiglitzMcBride.df_buffer", "modulename": "pydaptivefiltering", "qualname": "SteiglitzMcBride.df_buffer", "kind": "variable", "doc": "<p></p>\n", "annotation": ": numpy.ndarray"}, {"fullname": "pydaptivefiltering.SteiglitzMcBride.w", "modulename": "pydaptivefiltering", "qualname": "SteiglitzMcBride.w", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pydaptivefiltering.SteiglitzMcBride.optimize", "modulename": "pydaptivefiltering", "qualname": "SteiglitzMcBride.optimize", "kind": "function", "doc": "<p>Executes the Steiglitz-McBride adaptation.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>input_signal:\n    Input signal x[k].\ndesired_signal:\n    Desired signal d[k].\nverbose:\n    If True, prints runtime.\nreturn_internal_states:\n    If True, returns the auxiliary (prefiltered) equation error in result.extra.</p>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>OptimizationResult\n    outputs:\n        Output computed from the current IIR model.\n    errors:\n        Output error e[k] = d[k] - y[k] (for evaluation/monitoring).\n    coefficients:\n        History of coefficients stored in the base class.\n    error_type:\n        \"a_posteriori\".</p>\n\n<h2 id=\"extra-when-return_internal_statestrue\">Extra (when return_internal_states=True)</h2>\n\n<p>extra[\"auxiliary_error\"]:\n    Filtered equation error sequence e_s[k] used in the SM update.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">input_signal</span><span class=\"p\">:</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span>,</span><span class=\"param\">\t<span class=\"n\">desired_signal</span><span class=\"p\">:</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span>,</span><span class=\"param\">\t<span class=\"n\">verbose</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">return_internal_states</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span></span><span class=\"return-annotation\">) -> <span class=\"n\">pydaptivefiltering</span><span class=\"o\">.</span><span class=\"n\">base</span><span class=\"o\">.</span><span class=\"n\">OptimizationResult</span>:</span></span>", "funcdef": "def"}, {"fullname": "pydaptivefiltering.BilinearRLS", "modulename": "pydaptivefiltering", "qualname": "BilinearRLS", "kind": "class", "doc": "<p>Bilinear RLS (real-valued).</p>\n\n<p>Implements a bilinear regressor RLS structure (Algorithm 11.3 - Diniz).\nThe regressor used here has 4 components:</p>\n\n<pre><code>u[k] = [ x[k],\n         d[k-1],\n         x[k] d[k-1],\n         x[k-1] d[k-1] ]^T\n</code></pre>\n\n<p>and the RLS update (a priori form) is:</p>\n\n<pre><code>y[k] = w^T u[k]\ne[k] = d[k] - y[k]\nk[k] = P[k-1] u[k] / (lambda + u[k]^T P[k-1] u[k])\nP[k] = (P[k-1] - k[k] u[k]^T P[k-1]) / lambda\nw[k] = w[k-1] + k[k] e[k]\n</code></pre>\n\n<h2 id=\"notes\">Notes</h2>\n\n<ul>\n<li>Real-valued only: enforced by <code>ensure_real_signals</code>.</li>\n<li>Uses the unified base API via <code>validate_input</code>.</li>\n<li>Returns a priori error by default.</li>\n</ul>\n", "bases": "pydaptivefiltering.base.AdaptiveFilter"}, {"fullname": "pydaptivefiltering.BilinearRLS.__init__", "modulename": "pydaptivefiltering", "qualname": "BilinearRLS.__init__", "kind": "function", "doc": "<h2 id=\"parameters\">Parameters</h2>\n\n<p>forgetting_factor:\n    Forgetting factor lambda (0 &lt; lambda &lt;= 1).\ndelta:\n    Regularization factor for initial P = I/delta (delta &gt; 0).\nw_init:\n    Optional initial coefficients (length 4). If None, zeros.\nsafe_eps:\n    Small epsilon used to guard denominators.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">forgetting_factor</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">0.98</span>,</span><span class=\"param\">\t<span class=\"n\">delta</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">1.0</span>,</span><span class=\"param\">\t<span class=\"n\">w_init</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span><span class=\"p\">,</span> <span class=\"nb\">list</span><span class=\"p\">,</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"o\">*</span>,</span><span class=\"param\">\t<span class=\"n\">safe_eps</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">1e-12</span></span>)</span>"}, {"fullname": "pydaptivefiltering.BilinearRLS.supports_complex", "modulename": "pydaptivefiltering", "qualname": "BilinearRLS.supports_complex", "kind": "variable", "doc": "<p></p>\n", "annotation": ": bool", "default_value": "False"}, {"fullname": "pydaptivefiltering.BilinearRLS.lambda_factor", "modulename": "pydaptivefiltering", "qualname": "BilinearRLS.lambda_factor", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pydaptivefiltering.BilinearRLS.delta", "modulename": "pydaptivefiltering", "qualname": "BilinearRLS.delta", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pydaptivefiltering.BilinearRLS.P", "modulename": "pydaptivefiltering", "qualname": "BilinearRLS.P", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pydaptivefiltering.BilinearRLS.optimize", "modulename": "pydaptivefiltering", "qualname": "BilinearRLS.optimize", "kind": "function", "doc": "<p>Run Bilinear RLS adaptation.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>input_signal:\n    Input signal x[k] (real).\ndesired_signal:\n    Desired signal d[k] (real).\nverbose:\n    If True, prints runtime.\nreturn_internal_states:\n    If True, returns the last regressor and last gain in result.extra.</p>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>OptimizationResult\n    outputs:\n        Filter output y[k] (a priori).\n    errors:\n        A priori error e[k] = d[k] - y[k].\n    coefficients:\n        History of coefficients stored in the base class (length 4).\n    error_type:\n        \"a_priori\".</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">input_signal</span><span class=\"p\">:</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span>,</span><span class=\"param\">\t<span class=\"n\">desired_signal</span><span class=\"p\">:</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span>,</span><span class=\"param\">\t<span class=\"n\">verbose</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">return_internal_states</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span></span><span class=\"return-annotation\">) -> <span class=\"n\">pydaptivefiltering</span><span class=\"o\">.</span><span class=\"n\">base</span><span class=\"o\">.</span><span class=\"n\">OptimizationResult</span>:</span></span>", "funcdef": "def"}, {"fullname": "pydaptivefiltering.ComplexRBF", "modulename": "pydaptivefiltering", "qualname": "ComplexRBF", "kind": "class", "doc": "<p>Complex Radial Basis Function (CRBF) network (complex-valued).</p>\n\n<p>Implements a complex-valued RBF adaptive model (Algorithm 11.6 - Diniz).\nThe model output is computed as:</p>\n\n<pre><code>f_p(u) = exp( -||u - c_p||^2 / sigma_p^2 )\ny[k]   = w^H f(u_k)\n</code></pre>\n\n<p>where:</p>\n\n<ul>\n<li>u_k is the input regressor (dimension = input_dim),</li>\n<li>c_p are complex centers (\"vet\" in the original code),</li>\n<li>sigma_p are real spreads,</li>\n<li>w are complex neuron weights.</li>\n</ul>\n\n<h2 id=\"input-handling\">Input handling</h2>\n\n<p>This implementation accepts two input formats in <code>optimize</code>:</p>\n\n<p>1) 1D input signal x[k] (shape (N,)):\n   A tapped-delay regressor u_k of length <code>input_dim</code> is formed internally.</p>\n\n<p>2) 2D regressor matrix U (shape (N, input_dim)):\n   Each row is used directly as u_k.</p>\n\n<h2 id=\"notes\">Notes</h2>\n\n<ul>\n<li>Complex-valued implementation (<code>supports_complex=True</code>).</li>\n<li>The base class <code>filter_order</code> is used here as a size indicator (n_neurons-1).</li>\n<li><code>OptimizationResult.coefficients</code> stores the history of neuron weights <code>w</code>.\nCenters and spreads can be returned via <code>result.extra</code> when requested.</li>\n</ul>\n", "bases": "pydaptivefiltering.base.AdaptiveFilter"}, {"fullname": "pydaptivefiltering.ComplexRBF.__init__", "modulename": "pydaptivefiltering", "qualname": "ComplexRBF.__init__", "kind": "function", "doc": "<h2 id=\"parameters\">Parameters</h2>\n\n<p>n_neurons:\n    Number of RBF neurons.\ninput_dim:\n    Dimension of the input regressor u_k.\nur:\n    Step-size for centers update.\nuw:\n    Step-size for weights update.\nus:\n    Step-size for spread (sigma) update.\nw_init:\n    Optional initial neuron weights (length n_neurons). If None, random complex.\nsigma_init:\n    Initial spread value used for all neurons (must be &gt; 0).\nrng:\n    Optional numpy random generator for reproducible initialization.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">n_neurons</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">input_dim</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">ur</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">0.01</span>,</span><span class=\"param\">\t<span class=\"n\">uw</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">0.01</span>,</span><span class=\"param\">\t<span class=\"n\">us</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">0.01</span>,</span><span class=\"param\">\t<span class=\"n\">w_init</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span><span class=\"p\">,</span> <span class=\"nb\">list</span><span class=\"p\">,</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"o\">*</span>,</span><span class=\"param\">\t<span class=\"n\">sigma_init</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">1.0</span>,</span><span class=\"param\">\t<span class=\"n\">rng</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">random</span><span class=\"o\">.</span><span class=\"n\">_generator</span><span class=\"o\">.</span><span class=\"n\">Generator</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span>)</span>"}, {"fullname": "pydaptivefiltering.ComplexRBF.supports_complex", "modulename": "pydaptivefiltering", "qualname": "ComplexRBF.supports_complex", "kind": "variable", "doc": "<p></p>\n", "annotation": ": bool", "default_value": "True"}, {"fullname": "pydaptivefiltering.ComplexRBF.n_neurons", "modulename": "pydaptivefiltering", "qualname": "ComplexRBF.n_neurons", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pydaptivefiltering.ComplexRBF.input_dim", "modulename": "pydaptivefiltering", "qualname": "ComplexRBF.input_dim", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pydaptivefiltering.ComplexRBF.ur", "modulename": "pydaptivefiltering", "qualname": "ComplexRBF.ur", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pydaptivefiltering.ComplexRBF.uw", "modulename": "pydaptivefiltering", "qualname": "ComplexRBF.uw", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pydaptivefiltering.ComplexRBF.us", "modulename": "pydaptivefiltering", "qualname": "ComplexRBF.us", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pydaptivefiltering.ComplexRBF.vet", "modulename": "pydaptivefiltering", "qualname": "ComplexRBF.vet", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pydaptivefiltering.ComplexRBF.sigma", "modulename": "pydaptivefiltering", "qualname": "ComplexRBF.sigma", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pydaptivefiltering.ComplexRBF.w_history", "modulename": "pydaptivefiltering", "qualname": "ComplexRBF.w_history", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pydaptivefiltering.ComplexRBF.optimize", "modulename": "pydaptivefiltering", "qualname": "ComplexRBF.optimize", "kind": "function", "doc": "<p>Run CRBF adaptation.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>input_signal:\n    Either:\n      - 1D signal x[k] with shape (N,), or\n      - regressor matrix U with shape (N, input_dim).\ndesired_signal:\n    Desired signal d[k], shape (N,).\nverbose:\n    If True, prints runtime.\nreturn_internal_states:\n    If True, returns final centers/spreads and last activation vector in result.extra.\nsafe_eps:\n    Small epsilon to protect denominators (sigma and other divisions).</p>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>OptimizationResult\n    outputs:\n        Model output y[k].\n    errors:\n        A priori error e[k] = d[k] - y[k].\n    coefficients:\n        History of neuron weights w[k] (shape (N+1, n_neurons) in base history).\n    error_type:\n        \"a_priori\".</p>\n\n<h2 id=\"extra-when-return_internal_statestrue\">Extra (when return_internal_states=True)</h2>\n\n<p>extra[\"centers_last\"]:\n    Final centers array (n_neurons, input_dim).\nextra[\"sigma_last\"]:\n    Final spreads array (n_neurons,).\nextra[\"last_activation\"]:\n    Last activation vector f(u_k) (n_neurons,).\nextra[\"last_regressor\"]:\n    Last regressor u_k (input_dim,).</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">input_signal</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span><span class=\"p\">,</span> <span class=\"nb\">list</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"n\">desired_signal</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span><span class=\"p\">,</span> <span class=\"nb\">list</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"n\">verbose</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">return_internal_states</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"o\">*</span>,</span><span class=\"param\">\t<span class=\"n\">safe_eps</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">1e-12</span></span><span class=\"return-annotation\">) -> <span class=\"n\">pydaptivefiltering</span><span class=\"o\">.</span><span class=\"n\">base</span><span class=\"o\">.</span><span class=\"n\">OptimizationResult</span>:</span></span>", "funcdef": "def"}, {"fullname": "pydaptivefiltering.MultilayerPerceptron", "modulename": "pydaptivefiltering", "qualname": "MultilayerPerceptron", "kind": "class", "doc": "<p>Multilayer Perceptron (MLP) adaptive model with momentum (real-valued).</p>\n\n<p>This is a 2-hidden-layer MLP adapted online using a gradient update with momentum.\nThe network is:</p>\n\n<pre><code>y1 = act(w1 u - b1)\ny2 = act(w2 y1 - b2)\ny  = w3^T y2 - b3\n</code></pre>\n\n<p>where <code>act</code> is either tanh or sigmoid.</p>\n\n<h2 id=\"input-handling\">Input handling</h2>\n\n<p>This implementation accepts two input formats in <code>optimize</code>:</p>\n\n<p>1) 2D input matrix X with shape (N, input_dim):\n   Each row is used directly as the regressor u[k].</p>\n\n<p>2) 1D input signal x[k] with shape (N,):\n   A 3-dimensional regressor is formed internally as:\n       u[k] = [x[k], d[k-1], x[k-1]]\n   In this mode, <code>input_dim</code> must be 3.</p>\n\n<h2 id=\"notes\">Notes</h2>\n\n<ul>\n<li>Real-valued only: enforced by <code>ensure_real_signals</code>.</li>\n<li>The base class <code>filter_order</code> is used only as a size indicator here.</li>\n<li><code>OptimizationResult.coefficients</code> stores a proxy coefficient history (w3).\nFull parameter trajectories can be returned in <code>result.extra</code> when requested.</li>\n</ul>\n", "bases": "pydaptivefiltering.base.AdaptiveFilter"}, {"fullname": "pydaptivefiltering.MultilayerPerceptron.__init__", "modulename": "pydaptivefiltering", "qualname": "MultilayerPerceptron.__init__", "kind": "function", "doc": "<h2 id=\"parameters\">Parameters</h2>\n\n<p>n_neurons:\n    Number of neurons in each hidden layer.\ninput_dim:\n    Dimension of the input regressor u[k].\n    If <code>optimize</code> is called with a 1D signal, input_dim must be 3.\nstep_size:\n    Gradient step-size (mu).\nmomentum:\n    Momentum factor in [0, 1). Typical values: 0.0 to 0.9.\nactivation:\n    Activation function: \"tanh\" or \"sigmoid\".\nw_init:\n    Optional initialization for the output-layer weights w3 (length n_neurons).\n    If None, Xavier/Glorot initialization is used for all weights.\nrng:\n    Optional numpy random generator for reproducible initialization.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">n_neurons</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">10</span>,</span><span class=\"param\">\t<span class=\"n\">input_dim</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">3</span>,</span><span class=\"param\">\t<span class=\"n\">step_size</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">0.01</span>,</span><span class=\"param\">\t<span class=\"n\">momentum</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">0.9</span>,</span><span class=\"param\">\t<span class=\"n\">activation</span><span class=\"p\">:</span> <span class=\"nb\">str</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;tanh&#39;</span>,</span><span class=\"param\">\t<span class=\"n\">w_init</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span><span class=\"p\">,</span> <span class=\"nb\">list</span><span class=\"p\">,</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"o\">*</span>,</span><span class=\"param\">\t<span class=\"n\">rng</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">random</span><span class=\"o\">.</span><span class=\"n\">_generator</span><span class=\"o\">.</span><span class=\"n\">Generator</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span>)</span>"}, {"fullname": "pydaptivefiltering.MultilayerPerceptron.supports_complex", "modulename": "pydaptivefiltering", "qualname": "MultilayerPerceptron.supports_complex", "kind": "variable", "doc": "<p></p>\n", "annotation": ": bool", "default_value": "False"}, {"fullname": "pydaptivefiltering.MultilayerPerceptron.n_neurons", "modulename": "pydaptivefiltering", "qualname": "MultilayerPerceptron.n_neurons", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pydaptivefiltering.MultilayerPerceptron.input_dim", "modulename": "pydaptivefiltering", "qualname": "MultilayerPerceptron.input_dim", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pydaptivefiltering.MultilayerPerceptron.step_size", "modulename": "pydaptivefiltering", "qualname": "MultilayerPerceptron.step_size", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pydaptivefiltering.MultilayerPerceptron.momentum", "modulename": "pydaptivefiltering", "qualname": "MultilayerPerceptron.momentum", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pydaptivefiltering.MultilayerPerceptron.w1", "modulename": "pydaptivefiltering", "qualname": "MultilayerPerceptron.w1", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pydaptivefiltering.MultilayerPerceptron.w2", "modulename": "pydaptivefiltering", "qualname": "MultilayerPerceptron.w2", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pydaptivefiltering.MultilayerPerceptron.w3", "modulename": "pydaptivefiltering", "qualname": "MultilayerPerceptron.w3", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pydaptivefiltering.MultilayerPerceptron.b1", "modulename": "pydaptivefiltering", "qualname": "MultilayerPerceptron.b1", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pydaptivefiltering.MultilayerPerceptron.b2", "modulename": "pydaptivefiltering", "qualname": "MultilayerPerceptron.b2", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pydaptivefiltering.MultilayerPerceptron.b3", "modulename": "pydaptivefiltering", "qualname": "MultilayerPerceptron.b3", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pydaptivefiltering.MultilayerPerceptron.prev_dw1", "modulename": "pydaptivefiltering", "qualname": "MultilayerPerceptron.prev_dw1", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pydaptivefiltering.MultilayerPerceptron.prev_dw2", "modulename": "pydaptivefiltering", "qualname": "MultilayerPerceptron.prev_dw2", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pydaptivefiltering.MultilayerPerceptron.prev_dw3", "modulename": "pydaptivefiltering", "qualname": "MultilayerPerceptron.prev_dw3", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pydaptivefiltering.MultilayerPerceptron.prev_db1", "modulename": "pydaptivefiltering", "qualname": "MultilayerPerceptron.prev_db1", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pydaptivefiltering.MultilayerPerceptron.prev_db2", "modulename": "pydaptivefiltering", "qualname": "MultilayerPerceptron.prev_db2", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pydaptivefiltering.MultilayerPerceptron.prev_db3", "modulename": "pydaptivefiltering", "qualname": "MultilayerPerceptron.prev_db3", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pydaptivefiltering.MultilayerPerceptron.w", "modulename": "pydaptivefiltering", "qualname": "MultilayerPerceptron.w", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pydaptivefiltering.MultilayerPerceptron.w_history", "modulename": "pydaptivefiltering", "qualname": "MultilayerPerceptron.w_history", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pydaptivefiltering.MultilayerPerceptron.optimize", "modulename": "pydaptivefiltering", "qualname": "MultilayerPerceptron.optimize", "kind": "function", "doc": "<p>Run MLP online adaptation with momentum.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>input_signal:\n    Either:\n      - regressor matrix X with shape (N, input_dim), or\n      - 1D signal x[k] with shape (N,) (uses u[k]=[x[k], d[k-1], x[k-1]]; requires input_dim=3).\ndesired_signal:\n    Desired signal d[k], shape (N,).\nverbose:\n    If True, prints runtime.\nreturn_internal_states:\n    If True, returns parameter histories in <code>result.extra</code>.</p>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>OptimizationResult\n    outputs:\n        Estimated output y[k].\n    errors:\n        A priori error e[k] = d[k] - y[k].\n    coefficients:\n        Proxy coefficient history (w3) stacked from base history.\n    error_type:\n        \"a_priori\".</p>\n\n<h2 id=\"extra-when-return_internal_statestrue\">Extra (when return_internal_states=True)</h2>\n\n<p>extra[\"w1_hist\"], extra[\"w2_hist\"], extra[\"w3_hist\"]:\n    Parameter histories (each item is a snapshot per iteration).\nextra[\"b1_hist\"], extra[\"b2_hist\"], extra[\"b3_hist\"]:\n    Bias histories.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">input_signal</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span><span class=\"p\">,</span> <span class=\"nb\">list</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"n\">desired_signal</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span><span class=\"p\">,</span> <span class=\"nb\">list</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"n\">verbose</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">return_internal_states</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span></span><span class=\"return-annotation\">) -> <span class=\"n\">pydaptivefiltering</span><span class=\"o\">.</span><span class=\"n\">base</span><span class=\"o\">.</span><span class=\"n\">OptimizationResult</span>:</span></span>", "funcdef": "def"}, {"fullname": "pydaptivefiltering.RBF", "modulename": "pydaptivefiltering", "qualname": "RBF", "kind": "class", "doc": "<p>Radial Basis Function (RBF) adaptive model (real-valued).</p>\n\n<p>Implements Algorithm 11.5 (Diniz) with online adaptation of:</p>\n\n<ul>\n<li>output weights w (length n_neurons),</li>\n<li>centers/centroids (reference vectors) <code>vet</code> (shape n_neurons x input_dim),</li>\n<li>spreads <code>sigma</code> (length n_neurons).</li>\n</ul>\n\n<h2 id=\"model-common-form\">Model (common form)</h2>\n\n<p>For regressor u[k] (shape input_dim,), the i-th basis function is:</p>\n\n<pre><code>phi_i(u[k]) = exp( -||u[k] - c_i||^2 / sigma_i^2 )\n</code></pre>\n\n<p>Output:\n    y[k] = sum_i w_i * phi_i(u[k])</p>\n\n<h2 id=\"input-handling\">Input handling</h2>\n\n<p><code>optimize</code> accepts:\n1) input_signal as a regressor matrix with shape (N, input_dim), where each row is u[k].\n2) input_signal as a 1D signal x[k] with shape (N,). In this case, regressors are built\n   as tapped-delay vectors of length input_dim:\n       u[k] = [x[k], x[k-1], ..., x[k-input_dim+1]]</p>\n\n<h2 id=\"notes\">Notes</h2>\n\n<ul>\n<li>Real-valued only: enforced by <code>ensure_real_signals</code>.</li>\n<li>The base class coefficient vector <code>self.w</code> is used for the neuron output weights.\nCoefficient history in <code>OptimizationResult.coefficients</code> corresponds to w over time.</li>\n</ul>\n", "bases": "pydaptivefiltering.base.AdaptiveFilter"}, {"fullname": "pydaptivefiltering.RBF.__init__", "modulename": "pydaptivefiltering", "qualname": "RBF.__init__", "kind": "function", "doc": "<h2 id=\"parameters\">Parameters</h2>\n\n<p>n_neurons:\n    Number of RBF neurons (basis functions).\ninput_dim:\n    Dimension of the regressor u[k]. If input_signal is 1D, this is the tap length.\nur:\n    Step-size for center updates.\nuw:\n    Step-size for output weight updates.\nus:\n    Step-size for spread (sigma) updates.\nw_init:\n    Optional initialization for output weights w (length n_neurons). If None, random normal.\nsigma_init:\n    Initial sigma value for all neurons.\ncenters_init_scale:\n    Scale factor used for random initialization of centers.\nrng:\n    Optional numpy random generator for reproducible initialization.\nsafe_eps:\n    Small epsilon to protect denominators (sigma^2, sigma^3).</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">n_neurons</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">input_dim</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">ur</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">0.01</span>,</span><span class=\"param\">\t<span class=\"n\">uw</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">0.01</span>,</span><span class=\"param\">\t<span class=\"n\">us</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">0.01</span>,</span><span class=\"param\">\t<span class=\"n\">w_init</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span><span class=\"p\">,</span> <span class=\"nb\">list</span><span class=\"p\">,</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"o\">*</span>,</span><span class=\"param\">\t<span class=\"n\">sigma_init</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">1.0</span>,</span><span class=\"param\">\t<span class=\"n\">centers_init_scale</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">0.5</span>,</span><span class=\"param\">\t<span class=\"n\">rng</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">random</span><span class=\"o\">.</span><span class=\"n\">_generator</span><span class=\"o\">.</span><span class=\"n\">Generator</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">safe_eps</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">1e-12</span></span>)</span>"}, {"fullname": "pydaptivefiltering.RBF.supports_complex", "modulename": "pydaptivefiltering", "qualname": "RBF.supports_complex", "kind": "variable", "doc": "<p></p>\n", "annotation": ": bool", "default_value": "False"}, {"fullname": "pydaptivefiltering.RBF.n_neurons", "modulename": "pydaptivefiltering", "qualname": "RBF.n_neurons", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pydaptivefiltering.RBF.input_dim", "modulename": "pydaptivefiltering", "qualname": "RBF.input_dim", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pydaptivefiltering.RBF.ur", "modulename": "pydaptivefiltering", "qualname": "RBF.ur", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pydaptivefiltering.RBF.uw", "modulename": "pydaptivefiltering", "qualname": "RBF.uw", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pydaptivefiltering.RBF.us", "modulename": "pydaptivefiltering", "qualname": "RBF.us", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pydaptivefiltering.RBF.vet", "modulename": "pydaptivefiltering", "qualname": "RBF.vet", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pydaptivefiltering.RBF.sigma", "modulename": "pydaptivefiltering", "qualname": "RBF.sigma", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pydaptivefiltering.RBF.w_history", "modulename": "pydaptivefiltering", "qualname": "RBF.w_history", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pydaptivefiltering.RBF.optimize", "modulename": "pydaptivefiltering", "qualname": "RBF.optimize", "kind": "function", "doc": "<p>Run RBF online adaptation.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>input_signal:\n    Either:\n      - regressor matrix with shape (N, input_dim), or\n      - 1D signal x[k] with shape (N,) (tapped-delay regressors are built internally).\ndesired_signal:\n    Desired output d[k], shape (N,).\nverbose:\n    If True, prints runtime.\nreturn_internal_states:\n    If True, returns final centers/spreads and selected debug info in <code>result.extra</code>.</p>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>OptimizationResult\n    outputs:\n        Estimated output y[k].\n    errors:\n        A priori error e[k] = d[k] - y[k].\n    coefficients:\n        History of neuron output weights w (stacked from base history).\n    error_type:\n        \"a_priori\".</p>\n\n<h2 id=\"extra-when-return_internal_statestrue\">Extra (when return_internal_states=True)</h2>\n\n<p>extra[\"centers_last\"]:\n    Final centers array <code>vet</code> (n_neurons, input_dim).\nextra[\"sigma_last\"]:\n    Final sigma vector (n_neurons,).\nextra[\"last_phi\"]:\n    Last basis-function activation vector phi(u[k]) (n_neurons,).</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">input_signal</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span><span class=\"p\">,</span> <span class=\"nb\">list</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"n\">desired_signal</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span><span class=\"p\">,</span> <span class=\"nb\">list</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"n\">verbose</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">return_internal_states</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span></span><span class=\"return-annotation\">) -> <span class=\"n\">pydaptivefiltering</span><span class=\"o\">.</span><span class=\"n\">base</span><span class=\"o\">.</span><span class=\"n\">OptimizationResult</span>:</span></span>", "funcdef": "def"}, {"fullname": "pydaptivefiltering.VolterraLMS", "modulename": "pydaptivefiltering", "qualname": "VolterraLMS", "kind": "class", "doc": "<p>Volterra LMS (2nd-order) for real-valued adaptive filtering.</p>\n\n<p>Implements Algorithm 11.1 (Diniz) using a second-order Volterra expansion.</p>\n\n<p>For a linear memory length L (called <code>memory</code>), the regressor is composed of:</p>\n\n<ul>\n<li>linear terms:  [x[k], x[k-1], ..., x[k-L+1]]</li>\n<li>quadratic terms (with i &lt;= j):\n[x[k]^2, x[k]x[k-1], ..., x[k-L+1]^2]</li>\n</ul>\n\n<p>Total number of coefficients:\n    n_coeffs = L + L(L+1)/2</p>\n\n<h2 id=\"notes\">Notes</h2>\n\n<ul>\n<li>Real-valued only: enforced by <code>ensure_real_signals</code>.</li>\n<li>The base class coefficient vector <code>self.w</code> corresponds to the Volterra\ncoefficient vector (linear + quadratic). The history returned in\n<code>OptimizationResult.coefficients</code> is the stacked trajectory of <code>self.w</code>.</li>\n<li><code>step</code> can be:\n<ul>\n<li>scalar (same step for all coefficients), or</li>\n<li>vector (shape (n_coeffs,)) allowing per-term step scaling.</li>\n</ul></li>\n</ul>\n", "bases": "pydaptivefiltering.base.AdaptiveFilter"}, {"fullname": "pydaptivefiltering.VolterraLMS.__init__", "modulename": "pydaptivefiltering", "qualname": "VolterraLMS.__init__", "kind": "function", "doc": "<h2 id=\"parameters\">Parameters</h2>\n\n<p>memory:\n    Linear memory length L. Determines the Volterra regressor size:\n    n_coeffs = L + L(L+1)/2.\nstep:\n    Step-size mu. Can be a scalar or a vector of length n_coeffs.\nw_init:\n    Optional initial coefficients (length n_coeffs). If None, zeros.\nsafe_eps:\n    Small epsilon used for internal safety checks (kept for consistency).</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">memory</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">3</span>,</span><span class=\"param\">\t<span class=\"n\">step</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"nb\">float</span><span class=\"p\">,</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span><span class=\"p\">,</span> <span class=\"nb\">list</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"mf\">0.01</span>,</span><span class=\"param\">\t<span class=\"n\">w_init</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span><span class=\"p\">,</span> <span class=\"nb\">list</span><span class=\"p\">,</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"o\">*</span>,</span><span class=\"param\">\t<span class=\"n\">safe_eps</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">1e-12</span></span>)</span>"}, {"fullname": "pydaptivefiltering.VolterraLMS.supports_complex", "modulename": "pydaptivefiltering", "qualname": "VolterraLMS.supports_complex", "kind": "variable", "doc": "<p></p>\n", "annotation": ": bool", "default_value": "False"}, {"fullname": "pydaptivefiltering.VolterraLMS.memory", "modulename": "pydaptivefiltering", "qualname": "VolterraLMS.memory", "kind": "variable", "doc": "<p></p>\n", "annotation": ": int"}, {"fullname": "pydaptivefiltering.VolterraLMS.n_coeffs", "modulename": "pydaptivefiltering", "qualname": "VolterraLMS.n_coeffs", "kind": "variable", "doc": "<p></p>\n", "annotation": ": int"}, {"fullname": "pydaptivefiltering.VolterraLMS.w", "modulename": "pydaptivefiltering", "qualname": "VolterraLMS.w", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pydaptivefiltering.VolterraLMS.w_history", "modulename": "pydaptivefiltering", "qualname": "VolterraLMS.w_history", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pydaptivefiltering.VolterraLMS.optimize", "modulename": "pydaptivefiltering", "qualname": "VolterraLMS.optimize", "kind": "function", "doc": "<p>Run Volterra LMS adaptation over (x[k], d[k]).</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>input_signal:\n    Input sequence x[k], shape (N,).\ndesired_signal:\n    Desired sequence d[k], shape (N,).\nverbose:\n    If True, prints runtime.\nreturn_internal_states:\n    If True, returns selected internal values in <code>result.extra</code>.</p>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>OptimizationResult\n    outputs:\n        Filter output y[k] (a priori).\n    errors:\n        A priori error e[k] = d[k] - y[k].\n    coefficients:\n        History of Volterra coefficient vector w (stacked from base history).\n    error_type:\n        \"a_priori\".</p>\n\n<h2 id=\"extra-when-return_internal_statestrue\">Extra (when return_internal_states=True)</h2>\n\n<p>extra[\"last_regressor\"]:\n    Last Volterra regressor u[k] (length n_coeffs).\nextra[\"memory\"]:\n    Linear memory length L.\nextra[\"n_coeffs\"]:\n    Number of Volterra coefficients.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">input_signal</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span><span class=\"p\">,</span> <span class=\"nb\">list</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"n\">desired_signal</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span><span class=\"p\">,</span> <span class=\"nb\">list</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"n\">verbose</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">return_internal_states</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span></span><span class=\"return-annotation\">) -> <span class=\"n\">pydaptivefiltering</span><span class=\"o\">.</span><span class=\"n\">base</span><span class=\"o\">.</span><span class=\"n\">OptimizationResult</span>:</span></span>", "funcdef": "def"}, {"fullname": "pydaptivefiltering.VolterraRLS", "modulename": "pydaptivefiltering", "qualname": "VolterraRLS", "kind": "class", "doc": "<p>Volterra RLS (2nd-order) for real-valued adaptive filtering.</p>\n\n<p>Implements Algorithm 11.2 (Diniz) using a second-order Volterra expansion\nand an RLS update on the expanded regressor.</p>\n\n<p>For linear memory length L (<code>memory</code>), the Volterra regressor is:</p>\n\n<ul>\n<li>linear terms:  [x[k], x[k-1], ..., x[k-L+1]]</li>\n<li>quadratic terms (i &lt;= j):\n[x[k]^2, x[k]x[k-1], ..., x[k-L+1]^2]</li>\n</ul>\n\n<p>Total number of coefficients:\n    n_coeffs = L + L(L+1)/2</p>\n\n<h2 id=\"notes\">Notes</h2>\n\n<ul>\n<li>Real-valued only (enforced by <code>ensure_real_signals</code>).</li>\n<li>We return the <em>a priori</em> error by default:\n  e[k] = d[k] - y[k]  with y[k] = w^T u[k]  (before the weight update)\nand set <code>error_type=\"a_priori\"</code>.</li>\n<li>If <code>return_internal_states=True</code>, we also include posterior sequences in <code>extra</code>.</li>\n</ul>\n", "bases": "pydaptivefiltering.base.AdaptiveFilter"}, {"fullname": "pydaptivefiltering.VolterraRLS.__init__", "modulename": "pydaptivefiltering", "qualname": "VolterraRLS.__init__", "kind": "function", "doc": "<h2 id=\"parameters\">Parameters</h2>\n\n<p>memory:\n    Linear memory length L. Determines number of Volterra coefficients:\n    n_coeffs = L + L(L+1)/2.\nforgetting_factor:\n    Forgetting factor \u03bb (typically close to 1). Must satisfy 0 &lt; \u03bb &lt;= 1.\ndelta:\n    Positive regularization for initializing the inverse correlation matrix:\n    P[0] = I / delta.\nw_init:\n    Optional initial coefficient vector (length n_coeffs). If None, zeros.\nsafe_eps:\n    Small epsilon to guard denominators.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">memory</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">3</span>,</span><span class=\"param\">\t<span class=\"n\">forgetting_factor</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">0.98</span>,</span><span class=\"param\">\t<span class=\"n\">delta</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">1.0</span>,</span><span class=\"param\">\t<span class=\"n\">w_init</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span><span class=\"p\">,</span> <span class=\"nb\">list</span><span class=\"p\">,</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"o\">*</span>,</span><span class=\"param\">\t<span class=\"n\">safe_eps</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">1e-12</span></span>)</span>"}, {"fullname": "pydaptivefiltering.VolterraRLS.supports_complex", "modulename": "pydaptivefiltering", "qualname": "VolterraRLS.supports_complex", "kind": "variable", "doc": "<p></p>\n", "annotation": ": bool", "default_value": "False"}, {"fullname": "pydaptivefiltering.VolterraRLS.memory", "modulename": "pydaptivefiltering", "qualname": "VolterraRLS.memory", "kind": "variable", "doc": "<p></p>\n", "annotation": ": int"}, {"fullname": "pydaptivefiltering.VolterraRLS.lam", "modulename": "pydaptivefiltering", "qualname": "VolterraRLS.lam", "kind": "variable", "doc": "<p></p>\n", "annotation": ": float"}, {"fullname": "pydaptivefiltering.VolterraRLS.n_coeffs", "modulename": "pydaptivefiltering", "qualname": "VolterraRLS.n_coeffs", "kind": "variable", "doc": "<p></p>\n", "annotation": ": int"}, {"fullname": "pydaptivefiltering.VolterraRLS.w", "modulename": "pydaptivefiltering", "qualname": "VolterraRLS.w", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pydaptivefiltering.VolterraRLS.P", "modulename": "pydaptivefiltering", "qualname": "VolterraRLS.P", "kind": "variable", "doc": "<p></p>\n", "annotation": ": numpy.ndarray"}, {"fullname": "pydaptivefiltering.VolterraRLS.w_history", "modulename": "pydaptivefiltering", "qualname": "VolterraRLS.w_history", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pydaptivefiltering.VolterraRLS.optimize", "modulename": "pydaptivefiltering", "qualname": "VolterraRLS.optimize", "kind": "function", "doc": "<p>Run Volterra RLS adaptation over (x[k], d[k]).</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>input_signal:\n    Input sequence x[k], shape (N,).\ndesired_signal:\n    Desired sequence d[k], shape (N,).\nverbose:\n    If True, prints runtime.\nreturn_internal_states:\n    If True, includes additional sequences in <code>result.extra</code>.</p>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>OptimizationResult\n    outputs:\n        A priori output y[k] = w^T u[k].\n    errors:\n        A priori error e[k] = d[k] - y[k].\n    coefficients:\n        History of Volterra coefficients w (stacked from base history).\n    error_type:\n        \"a_priori\".</p>\n\n<h2 id=\"extra-when-return_internal_statestrue\">Extra (when return_internal_states=True)</h2>\n\n<p>extra[\"posteriori_outputs\"]:\n    Output after the weight update (y_post).\nextra[\"posteriori_errors\"]:\n    Error after the weight update (e_post).\nextra[\"last_gain\"]:\n    Last RLS gain vector k (shape (n_coeffs,)).\nextra[\"last_den\"]:\n    Last denominator (scalar).\nextra[\"last_regressor\"]:\n    Last Volterra regressor u[k].</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">input_signal</span><span class=\"p\">:</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span>,</span><span class=\"param\">\t<span class=\"n\">desired_signal</span><span class=\"p\">:</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span>,</span><span class=\"param\">\t<span class=\"n\">verbose</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">return_internal_states</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span></span><span class=\"return-annotation\">) -> <span class=\"n\">pydaptivefiltering</span><span class=\"o\">.</span><span class=\"n\">base</span><span class=\"o\">.</span><span class=\"n\">OptimizationResult</span>:</span></span>", "funcdef": "def"}, {"fullname": "pydaptivefiltering.CFDLMS", "modulename": "pydaptivefiltering", "qualname": "CFDLMS", "kind": "class", "doc": "<p>Implements the Constrained Frequency-Domain LMS (CFDLMS) algorithm for real-valued data.\n(Algorithm 12.4, Diniz)</p>\n\n<h2 id=\"notes\">Notes</h2>\n\n<ul>\n<li>This algorithm is block-based: each iteration produces L time-domain outputs.</li>\n<li>Internally it uses complex FFT processing; outputs/errors returned are real.</li>\n<li>Coefficients are a subband matrix ww with shape (M, Nw+1).</li>\n<li>For compatibility with the base class, <code>self.w</code> stores a flattened view of <code>ww</code>.\nThe returned OptimizationResult.coefficients still comes from <code>self.w_history</code>\n(flattened), and the full matrix history is provided in <code>extra[\"ww_history\"]</code>.</li>\n</ul>\n", "bases": "pydaptivefiltering.base.AdaptiveFilter"}, {"fullname": "pydaptivefiltering.CFDLMS.__init__", "modulename": "pydaptivefiltering", "qualname": "CFDLMS.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">filter_order</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">5</span>,</span><span class=\"param\">\t<span class=\"n\">n_subbands</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">64</span>,</span><span class=\"param\">\t<span class=\"n\">decimation</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">step</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">0.1</span>,</span><span class=\"param\">\t<span class=\"n\">gamma</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">0.01</span>,</span><span class=\"param\">\t<span class=\"n\">smoothing</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">0.01</span>,</span><span class=\"param\">\t<span class=\"n\">w_init</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span><span class=\"p\">,</span> <span class=\"nb\">list</span><span class=\"p\">,</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span>)</span>"}, {"fullname": "pydaptivefiltering.CFDLMS.supports_complex", "modulename": "pydaptivefiltering", "qualname": "CFDLMS.supports_complex", "kind": "variable", "doc": "<p></p>\n", "annotation": ": bool", "default_value": "False"}, {"fullname": "pydaptivefiltering.CFDLMS.M", "modulename": "pydaptivefiltering", "qualname": "CFDLMS.M", "kind": "variable", "doc": "<p></p>\n", "annotation": ": int"}, {"fullname": "pydaptivefiltering.CFDLMS.L", "modulename": "pydaptivefiltering", "qualname": "CFDLMS.L", "kind": "variable", "doc": "<p></p>\n", "annotation": ": int"}, {"fullname": "pydaptivefiltering.CFDLMS.Nw", "modulename": "pydaptivefiltering", "qualname": "CFDLMS.Nw", "kind": "variable", "doc": "<p></p>\n", "annotation": ": int"}, {"fullname": "pydaptivefiltering.CFDLMS.step", "modulename": "pydaptivefiltering", "qualname": "CFDLMS.step", "kind": "variable", "doc": "<p></p>\n", "annotation": ": float"}, {"fullname": "pydaptivefiltering.CFDLMS.gamma", "modulename": "pydaptivefiltering", "qualname": "CFDLMS.gamma", "kind": "variable", "doc": "<p></p>\n", "annotation": ": float"}, {"fullname": "pydaptivefiltering.CFDLMS.smoothing", "modulename": "pydaptivefiltering", "qualname": "CFDLMS.smoothing", "kind": "variable", "doc": "<p></p>\n", "annotation": ": float"}, {"fullname": "pydaptivefiltering.CFDLMS.ww", "modulename": "pydaptivefiltering", "qualname": "CFDLMS.ww", "kind": "variable", "doc": "<p></p>\n", "annotation": ": numpy.ndarray"}, {"fullname": "pydaptivefiltering.CFDLMS.uu", "modulename": "pydaptivefiltering", "qualname": "CFDLMS.uu", "kind": "variable", "doc": "<p></p>\n", "annotation": ": numpy.ndarray"}, {"fullname": "pydaptivefiltering.CFDLMS.sig", "modulename": "pydaptivefiltering", "qualname": "CFDLMS.sig", "kind": "variable", "doc": "<p></p>\n", "annotation": ": numpy.ndarray"}, {"fullname": "pydaptivefiltering.CFDLMS.w", "modulename": "pydaptivefiltering", "qualname": "CFDLMS.w", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pydaptivefiltering.CFDLMS.w_history", "modulename": "pydaptivefiltering", "qualname": "CFDLMS.w_history", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pydaptivefiltering.CFDLMS.ww_history", "modulename": "pydaptivefiltering", "qualname": "CFDLMS.ww_history", "kind": "variable", "doc": "<p></p>\n", "annotation": ": list[numpy.ndarray]"}, {"fullname": "pydaptivefiltering.CFDLMS.reset_filter", "modulename": "pydaptivefiltering", "qualname": "CFDLMS.reset_filter", "kind": "function", "doc": "<p>Reset coefficients/history.</p>\n\n<p>If w_new is:</p>\n\n<ul>\n<li>None: zeros</li>\n<li>shape (M, Nw+1): used directly</li>\n<li>flat of length M*(Nw+1): reshaped</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">w_new</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span><span class=\"p\">,</span> <span class=\"nb\">list</span><span class=\"p\">,</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span><span class=\"return-annotation\">) -> <span class=\"kc\">None</span>:</span></span>", "funcdef": "def"}, {"fullname": "pydaptivefiltering.CFDLMS.optimize", "modulename": "pydaptivefiltering", "qualname": "CFDLMS.optimize", "kind": "function", "doc": "<p>Executes the CFDLMS weight update process.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>input_signal:\n    Input signal x[n] (real-valued).\ndesired_signal:\n    Desired signal d[n] (real-valued).\nverbose:\n    If True, prints runtime.\nreturn_internal_states:\n    If True, returns additional internal trajectories in result.extra.</p>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>OptimizationResult\n    outputs:\n        Estimated output signal (real), length = n_iters * L.\n    errors:\n        Output error signal (real), same length as outputs.\n    coefficients:\n        Flattened coefficient history (from base <code>w_history</code>).\n    error_type:\n        \"output_error\".</p>\n\n<h2 id=\"extra-always\">Extra (always)</h2>\n\n<p>extra[\"ww_history\"]:\n    List of coefficient matrices ww over iterations; each entry has shape (M, Nw+1).\nextra[\"n_iters\"]:\n    Number of block iterations.</p>\n\n<h2 id=\"extra-when-return_internal_statestrue\">Extra (when return_internal_states=True)</h2>\n\n<p>extra[\"sig\"]:\n    Final smoothed energy per bin (M,).\nextra[\"sig_history\"]:\n    Energy history per iteration (n_iters, M).</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">input_signal</span><span class=\"p\">:</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span>,</span><span class=\"param\">\t<span class=\"n\">desired_signal</span><span class=\"p\">:</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span>,</span><span class=\"param\">\t<span class=\"n\">verbose</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">return_internal_states</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span></span><span class=\"return-annotation\">) -> <span class=\"n\">pydaptivefiltering</span><span class=\"o\">.</span><span class=\"n\">base</span><span class=\"o\">.</span><span class=\"n\">OptimizationResult</span>:</span></span>", "funcdef": "def"}, {"fullname": "pydaptivefiltering.DLCLLMS", "modulename": "pydaptivefiltering", "qualname": "DLCLLMS", "kind": "class", "doc": "<p>Implements the Delayless Closed-Loop Subband LMS adaptive-filtering algorithm (DLCLLMS)\nfor real-valued fullband data. (Algorithm 12.3, Diniz)</p>\n\n<h2 id=\"notes\">Notes</h2>\n\n<ul>\n<li>Processing is block-based with block length L = M (number of subbands).</li>\n<li>Internally uses complex subband signals (DFT analysis bank).</li>\n<li>The mapped equivalent fullband FIR GG (length M*Nw) is exposed via <code>self.w</code> (float).</li>\n<li>For compatibility with the base class, <code>OptimizationResult.coefficients</code> returns\n<code>self.w_history</code> which stores the mapped GG <strong>once per processed block</strong>.</li>\n</ul>\n", "bases": "pydaptivefiltering.base.AdaptiveFilter"}, {"fullname": "pydaptivefiltering.DLCLLMS.__init__", "modulename": "pydaptivefiltering", "qualname": "DLCLLMS.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">filter_order</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">5</span>,</span><span class=\"param\">\t<span class=\"n\">n_subbands</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">4</span>,</span><span class=\"param\">\t<span class=\"n\">step</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">0.1</span>,</span><span class=\"param\">\t<span class=\"n\">gamma</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">0.01</span>,</span><span class=\"param\">\t<span class=\"n\">a</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">0.01</span>,</span><span class=\"param\">\t<span class=\"n\">nyquist_len</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">2</span>,</span><span class=\"param\">\t<span class=\"n\">w_init</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span><span class=\"p\">,</span> <span class=\"nb\">list</span><span class=\"p\">,</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span>)</span>"}, {"fullname": "pydaptivefiltering.DLCLLMS.supports_complex", "modulename": "pydaptivefiltering", "qualname": "DLCLLMS.supports_complex", "kind": "variable", "doc": "<p></p>\n", "annotation": ": bool", "default_value": "False"}, {"fullname": "pydaptivefiltering.DLCLLMS.M", "modulename": "pydaptivefiltering", "qualname": "DLCLLMS.M", "kind": "variable", "doc": "<p></p>\n", "annotation": ": int"}, {"fullname": "pydaptivefiltering.DLCLLMS.Nw", "modulename": "pydaptivefiltering", "qualname": "DLCLLMS.Nw", "kind": "variable", "doc": "<p></p>\n", "annotation": ": int"}, {"fullname": "pydaptivefiltering.DLCLLMS.step", "modulename": "pydaptivefiltering", "qualname": "DLCLLMS.step", "kind": "variable", "doc": "<p></p>\n", "annotation": ": float"}, {"fullname": "pydaptivefiltering.DLCLLMS.gamma", "modulename": "pydaptivefiltering", "qualname": "DLCLLMS.gamma", "kind": "variable", "doc": "<p></p>\n", "annotation": ": float"}, {"fullname": "pydaptivefiltering.DLCLLMS.a", "modulename": "pydaptivefiltering", "qualname": "DLCLLMS.a", "kind": "variable", "doc": "<p></p>\n", "annotation": ": float"}, {"fullname": "pydaptivefiltering.DLCLLMS.nyquist_len", "modulename": "pydaptivefiltering", "qualname": "DLCLLMS.nyquist_len", "kind": "variable", "doc": "<p></p>\n", "annotation": ": int"}, {"fullname": "pydaptivefiltering.DLCLLMS.Ed", "modulename": "pydaptivefiltering", "qualname": "DLCLLMS.Ed", "kind": "variable", "doc": "<p></p>\n", "annotation": ": numpy.ndarray"}, {"fullname": "pydaptivefiltering.DLCLLMS.F", "modulename": "pydaptivefiltering", "qualname": "DLCLLMS.F", "kind": "variable", "doc": "<p></p>\n", "annotation": ": numpy.ndarray"}, {"fullname": "pydaptivefiltering.DLCLLMS.w_sb", "modulename": "pydaptivefiltering", "qualname": "DLCLLMS.w_sb", "kind": "variable", "doc": "<p></p>\n", "annotation": ": numpy.ndarray"}, {"fullname": "pydaptivefiltering.DLCLLMS.x_cl", "modulename": "pydaptivefiltering", "qualname": "DLCLLMS.x_cl", "kind": "variable", "doc": "<p></p>\n", "annotation": ": numpy.ndarray"}, {"fullname": "pydaptivefiltering.DLCLLMS.sig", "modulename": "pydaptivefiltering", "qualname": "DLCLLMS.sig", "kind": "variable", "doc": "<p></p>\n", "annotation": ": numpy.ndarray"}, {"fullname": "pydaptivefiltering.DLCLLMS.w_history", "modulename": "pydaptivefiltering", "qualname": "DLCLLMS.w_history", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pydaptivefiltering.DLCLLMS.reset_filter", "modulename": "pydaptivefiltering", "qualname": "DLCLLMS.reset_filter", "kind": "function", "doc": "<p>Reset coefficients and history.</p>\n\n<ul>\n<li>If w_new is provided:\n<ul>\n<li>If shape (M, Nw+1): interpreted as subband coefficients.</li>\n<li>If flat of length M*(Nw+1): reshaped as subband coefficients.</li>\n</ul></li>\n<li>Resets internal states (x_cl, sig, fractional-delay, FIR state).</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">w_new</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span><span class=\"p\">,</span> <span class=\"nb\">list</span><span class=\"p\">,</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span><span class=\"return-annotation\">) -> <span class=\"kc\">None</span>:</span></span>", "funcdef": "def"}, {"fullname": "pydaptivefiltering.DLCLLMS.optimize", "modulename": "pydaptivefiltering", "qualname": "DLCLLMS.optimize", "kind": "function", "doc": "<p>Executes the adaptation process for the DLCLLMS algorithm (faithful to dlcllms.m).</p>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>OptimizationResult\n    outputs:\n        Estimated fullband output y[n] (real), same length as input_signal.\n    errors:\n        Fullband error e[n] = d[n] - y[n] (real).\n    coefficients:\n        History of equivalent fullband FIR vectors GG (length M*Nw),\n        stored once per processed block (plus the initial entry).</p>\n\n<h2 id=\"extra-always\">Extra (always)</h2>\n\n<p>extra[\"n_blocks\"]:\n    Number of processed blocks.\nextra[\"block_len\"]:\n    Block length (equals M).\nextra[\"n_used\"]:\n    Number of samples actually processed (multiple of M).</p>\n\n<h2 id=\"extra-when-return_internal_statestrue\">Extra (when return_internal_states=True)</h2>\n\n<p>extra[\"sig_history\"]:\n    Smoothed subband power per block (n_blocks, M).\nextra[\"w_sb_final\"]:\n    Final subband coefficient matrix (M, Nw+1), complex.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">input_signal</span><span class=\"p\">:</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span>,</span><span class=\"param\">\t<span class=\"n\">desired_signal</span><span class=\"p\">:</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span>,</span><span class=\"param\">\t<span class=\"n\">verbose</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">return_internal_states</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span></span><span class=\"return-annotation\">) -> <span class=\"n\">pydaptivefiltering</span><span class=\"o\">.</span><span class=\"n\">base</span><span class=\"o\">.</span><span class=\"n\">OptimizationResult</span>:</span></span>", "funcdef": "def"}, {"fullname": "pydaptivefiltering.OLSBLMS", "modulename": "pydaptivefiltering", "qualname": "OLSBLMS", "kind": "class", "doc": "<p>Implements the Open-Loop Subband LMS (OLSBLMS) adaptive-filtering algorithm for real-valued data.\n(Algorithm 12.1, Diniz)</p>\n\n<h2 id=\"notes\">Notes</h2>\n\n<ul>\n<li>The adaptive coefficients are subband-wise: w has shape (M, Nw+1).</li>\n<li>For compatibility with the base class, <code>OptimizationResult.coefficients</code> will contain\na flattened history of the subband coefficient matrix (row-major flatten).\nThe full matrix history is provided in <code>extra[\"w_matrix_history\"]</code>.</li>\n<li>The MATLAB reference typically evaluates MSE in subbands; here we also provide a\nconvenience fullband reconstruction via the synthesis bank.</li>\n</ul>\n", "bases": "pydaptivefiltering.base.AdaptiveFilter"}, {"fullname": "pydaptivefiltering.OLSBLMS.__init__", "modulename": "pydaptivefiltering", "qualname": "OLSBLMS.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">n_subbands</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">analysis_filters</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span><span class=\"p\">,</span> <span class=\"nb\">list</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"n\">synthesis_filters</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span><span class=\"p\">,</span> <span class=\"nb\">list</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"n\">filter_order</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">step</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">0.1</span>,</span><span class=\"param\">\t<span class=\"n\">gamma</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">0.01</span>,</span><span class=\"param\">\t<span class=\"n\">a</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">0.01</span>,</span><span class=\"param\">\t<span class=\"n\">decimation_factor</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">w_init</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span><span class=\"p\">,</span> <span class=\"nb\">list</span><span class=\"p\">,</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span>)</span>"}, {"fullname": "pydaptivefiltering.OLSBLMS.supports_complex", "modulename": "pydaptivefiltering", "qualname": "OLSBLMS.supports_complex", "kind": "variable", "doc": "<p></p>\n", "annotation": ": bool", "default_value": "False"}, {"fullname": "pydaptivefiltering.OLSBLMS.M", "modulename": "pydaptivefiltering", "qualname": "OLSBLMS.M", "kind": "variable", "doc": "<p></p>\n", "annotation": ": int"}, {"fullname": "pydaptivefiltering.OLSBLMS.Nw", "modulename": "pydaptivefiltering", "qualname": "OLSBLMS.Nw", "kind": "variable", "doc": "<p></p>\n", "annotation": ": int"}, {"fullname": "pydaptivefiltering.OLSBLMS.L", "modulename": "pydaptivefiltering", "qualname": "OLSBLMS.L", "kind": "variable", "doc": "<p></p>\n", "annotation": ": int"}, {"fullname": "pydaptivefiltering.OLSBLMS.step", "modulename": "pydaptivefiltering", "qualname": "OLSBLMS.step", "kind": "variable", "doc": "<p></p>\n", "annotation": ": float"}, {"fullname": "pydaptivefiltering.OLSBLMS.gamma", "modulename": "pydaptivefiltering", "qualname": "OLSBLMS.gamma", "kind": "variable", "doc": "<p></p>\n", "annotation": ": float"}, {"fullname": "pydaptivefiltering.OLSBLMS.a", "modulename": "pydaptivefiltering", "qualname": "OLSBLMS.a", "kind": "variable", "doc": "<p></p>\n", "annotation": ": float"}, {"fullname": "pydaptivefiltering.OLSBLMS.hk", "modulename": "pydaptivefiltering", "qualname": "OLSBLMS.hk", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pydaptivefiltering.OLSBLMS.fk", "modulename": "pydaptivefiltering", "qualname": "OLSBLMS.fk", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pydaptivefiltering.OLSBLMS.w_mat", "modulename": "pydaptivefiltering", "qualname": "OLSBLMS.w_mat", "kind": "variable", "doc": "<p></p>\n", "annotation": ": numpy.ndarray"}, {"fullname": "pydaptivefiltering.OLSBLMS.w", "modulename": "pydaptivefiltering", "qualname": "OLSBLMS.w", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pydaptivefiltering.OLSBLMS.w_history", "modulename": "pydaptivefiltering", "qualname": "OLSBLMS.w_history", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pydaptivefiltering.OLSBLMS.w_matrix_history", "modulename": "pydaptivefiltering", "qualname": "OLSBLMS.w_matrix_history", "kind": "variable", "doc": "<p></p>\n", "annotation": ": list[numpy.ndarray]"}, {"fullname": "pydaptivefiltering.OLSBLMS.default_test_init_kwargs", "modulename": "pydaptivefiltering", "qualname": "OLSBLMS.default_test_init_kwargs", "kind": "function", "doc": "<p>Override in subclasses to provide init kwargs for standardized tests.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">cls</span>, </span><span class=\"param\"><span class=\"n\">order</span><span class=\"p\">:</span> <span class=\"nb\">int</span></span><span class=\"return-annotation\">) -> <span class=\"nb\">dict</span>:</span></span>", "funcdef": "def"}, {"fullname": "pydaptivefiltering.OLSBLMS.optimize", "modulename": "pydaptivefiltering", "qualname": "OLSBLMS.optimize", "kind": "function", "doc": "<p>Executes the adaptation process for the Open-Loop Subband LMS (OLSBLMS) algorithm.</p>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>OptimizationResult\n    outputs:\n        Fullband reconstructed output y(n), same length as desired_signal.\n    errors:\n        Fullband output error e(n) = d(n) - y(n).\n    coefficients:\n        Flattened coefficient history (shape: (#snapshots, M*(Nw+1))).</p>\n\n<h2 id=\"extra-always\">Extra (always)</h2>\n\n<p>extra[\"w_matrix_history\"]:\n    List of coefficient matrices (M, Nw+1), one per subband-iteration.\nextra[\"subband_outputs\"], extra[\"subband_errors\"]:\n    Arrays with shape (M, N_iter).\nextra[\"mse_subbands\"], extra[\"mse_overall\"]:\n    MSE curves in subbands.</p>\n\n<h2 id=\"extra-when-return_internal_statestrue\">Extra (when return_internal_states=True)</h2>\n\n<p>extra[\"sig_ol\"]:\n    Final subband energy estimates (M,).</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">input_signal</span><span class=\"p\">:</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span>,</span><span class=\"param\">\t<span class=\"n\">desired_signal</span><span class=\"p\">:</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span>,</span><span class=\"param\">\t<span class=\"n\">verbose</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">return_internal_states</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span></span><span class=\"return-annotation\">) -> <span class=\"n\">pydaptivefiltering</span><span class=\"o\">.</span><span class=\"n\">base</span><span class=\"o\">.</span><span class=\"n\">OptimizationResult</span>:</span></span>", "funcdef": "def"}, {"fullname": "pydaptivefiltering.AffineProjectionCM", "modulename": "pydaptivefiltering", "qualname": "AffineProjectionCM", "kind": "class", "doc": "<p>Implements the Affine-Projection Constant-Modulus (AP-CM) algorithm\nfor blind adaptive filtering.</p>\n\n<h2 id=\"notes\">Notes</h2>\n\n<ul>\n<li>This is a BLIND algorithm: it does not require desired_signal.</li>\n<li>We still accept <code>desired_signal=None</code> in <code>optimize</code> to keep a unified API.</li>\n</ul>\n", "bases": "pydaptivefiltering.base.AdaptiveFilter"}, {"fullname": "pydaptivefiltering.AffineProjectionCM.__init__", "modulename": "pydaptivefiltering", "qualname": "AffineProjectionCM.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">filter_order</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">5</span>,</span><span class=\"param\">\t<span class=\"n\">step_size</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">0.1</span>,</span><span class=\"param\">\t<span class=\"n\">memory_length</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">2</span>,</span><span class=\"param\">\t<span class=\"n\">gamma</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">1e-06</span>,</span><span class=\"param\">\t<span class=\"n\">w_init</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span><span class=\"p\">,</span> <span class=\"nb\">list</span><span class=\"p\">,</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span>)</span>"}, {"fullname": "pydaptivefiltering.AffineProjectionCM.supports_complex", "modulename": "pydaptivefiltering", "qualname": "AffineProjectionCM.supports_complex", "kind": "variable", "doc": "<p></p>\n", "annotation": ": bool", "default_value": "True"}, {"fullname": "pydaptivefiltering.AffineProjectionCM.step_size", "modulename": "pydaptivefiltering", "qualname": "AffineProjectionCM.step_size", "kind": "variable", "doc": "<p></p>\n", "annotation": ": float"}, {"fullname": "pydaptivefiltering.AffineProjectionCM.memory_length", "modulename": "pydaptivefiltering", "qualname": "AffineProjectionCM.memory_length", "kind": "variable", "doc": "<p></p>\n", "annotation": ": int"}, {"fullname": "pydaptivefiltering.AffineProjectionCM.gamma", "modulename": "pydaptivefiltering", "qualname": "AffineProjectionCM.gamma", "kind": "variable", "doc": "<p></p>\n", "annotation": ": float"}, {"fullname": "pydaptivefiltering.AffineProjectionCM.n_coeffs", "modulename": "pydaptivefiltering", "qualname": "AffineProjectionCM.n_coeffs", "kind": "variable", "doc": "<p></p>\n", "annotation": ": int"}, {"fullname": "pydaptivefiltering.AffineProjectionCM.optimize", "modulename": "pydaptivefiltering", "qualname": "AffineProjectionCM.optimize", "kind": "function", "doc": "<p>Executes the Affine-Projection Constant-Modulus (AP-CM) algorithm.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>input_signal:\n    The input signal to be filtered.\ndesired_signal:\n    Ignored (kept only for API standardization).\nverbose:\n    If True, prints runtime.\nreturn_internal_states:\n    If True, returns selected internal values in <code>extra</code>.</p>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>OptimizationResult\n    outputs:\n        y[k] = first component of the projection output vector.\n    errors:\n        e[k] = first component of the CM error vector.\n    coefficients:\n        coefficient history stored in the base class.\n    error_type:\n        set to \"blind_constant_modulus\".</p>\n\n<h2 id=\"extra-when-return_internal_statestrue\">Extra (when return_internal_states=True)</h2>\n\n<p>extra[\"last_update_factor\"]:\n    Solution of the (regularized) linear system at the last iteration.\nextra[\"last_regressor_matrix\"]:\n    Final regressor matrix (shape n_coeffs x (memory_length+1)).</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">input_signal</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span><span class=\"p\">,</span> <span class=\"nb\">list</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"n\">desired_signal</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span><span class=\"p\">,</span> <span class=\"nb\">list</span><span class=\"p\">,</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">verbose</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">return_internal_states</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span></span><span class=\"return-annotation\">) -> <span class=\"n\">pydaptivefiltering</span><span class=\"o\">.</span><span class=\"n\">base</span><span class=\"o\">.</span><span class=\"n\">OptimizationResult</span>:</span></span>", "funcdef": "def"}, {"fullname": "pydaptivefiltering.CMA", "modulename": "pydaptivefiltering", "qualname": "CMA", "kind": "class", "doc": "<p>Implements the Constant-Modulus Algorithm (CMA) for blind adaptive filtering.</p>\n\n<h2 id=\"notes\">Notes</h2>\n\n<ul>\n<li>This is a BLIND algorithm: it does not require desired_signal.</li>\n<li>We keep <code>desired_signal=None</code> in <code>optimize</code> only for API standardization.</li>\n</ul>\n", "bases": "pydaptivefiltering.base.AdaptiveFilter"}, {"fullname": "pydaptivefiltering.CMA.__init__", "modulename": "pydaptivefiltering", "qualname": "CMA.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">filter_order</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">5</span>,</span><span class=\"param\">\t<span class=\"n\">step_size</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">0.01</span>,</span><span class=\"param\">\t<span class=\"n\">w_init</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span><span class=\"p\">,</span> <span class=\"nb\">list</span><span class=\"p\">,</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span>)</span>"}, {"fullname": "pydaptivefiltering.CMA.supports_complex", "modulename": "pydaptivefiltering", "qualname": "CMA.supports_complex", "kind": "variable", "doc": "<p></p>\n", "annotation": ": bool", "default_value": "True"}, {"fullname": "pydaptivefiltering.CMA.step_size", "modulename": "pydaptivefiltering", "qualname": "CMA.step_size", "kind": "variable", "doc": "<p></p>\n", "annotation": ": float"}, {"fullname": "pydaptivefiltering.CMA.n_coeffs", "modulename": "pydaptivefiltering", "qualname": "CMA.n_coeffs", "kind": "variable", "doc": "<p></p>\n", "annotation": ": int"}, {"fullname": "pydaptivefiltering.CMA.optimize", "modulename": "pydaptivefiltering", "qualname": "CMA.optimize", "kind": "function", "doc": "<p>Executes the Constant-Modulus Algorithm (CMA) weight update process.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>input_signal:\n    Input signal to be filtered.\ndesired_signal:\n    Ignored (kept only for API standardization).\nverbose:\n    If True, prints runtime.\nreturn_internal_states:\n    If True, includes internal signals in result.extra.\nsafe_eps:\n    Small epsilon to avoid division by zero when estimating the dispersion constant.</p>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>OptimizationResult\n    outputs:\n        Filter output y[k].\n    errors:\n        CMA error (|y[k]|^2 - R2).\n    coefficients:\n        History of coefficients stored in the base class.\n    error_type:\n        \"blind_constant_modulus\".</p>\n\n<h2 id=\"extra-when-return_internal_statestrue\">Extra (when return_internal_states=True)</h2>\n\n<p>extra[\"dispersion_constant\"]:\n    R2 used by CMA.\nextra[\"instantaneous_phi\"]:\n    Trajectory of phi[k] = 2<em>e[k]</em>conj(y[k]) (complex), length N.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">input_signal</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span><span class=\"p\">,</span> <span class=\"nb\">list</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"n\">desired_signal</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span><span class=\"p\">,</span> <span class=\"nb\">list</span><span class=\"p\">,</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">verbose</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">return_internal_states</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">safe_eps</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">1e-12</span></span><span class=\"return-annotation\">) -> <span class=\"n\">pydaptivefiltering</span><span class=\"o\">.</span><span class=\"n\">base</span><span class=\"o\">.</span><span class=\"n\">OptimizationResult</span>:</span></span>", "funcdef": "def"}, {"fullname": "pydaptivefiltering.Godard", "modulename": "pydaptivefiltering", "qualname": "Godard", "kind": "class", "doc": "<p>Implements the Godard algorithm for blind adaptive filtering with complex-valued data.</p>\n\n<p>This is a blind adaptation criterion that does not require a desired signal.\nA <code>desired_signal=None</code> parameter is accepted only to keep a unified API signature\nacross the library.</p>\n", "bases": "pydaptivefiltering.base.AdaptiveFilter"}, {"fullname": "pydaptivefiltering.Godard.__init__", "modulename": "pydaptivefiltering", "qualname": "Godard.__init__", "kind": "function", "doc": "<h2 id=\"parameters\">Parameters</h2>\n\n<p>filter_order:\n    FIR filter order (number of taps - 1). Number of coefficients is filter_order + 1.\nstep_size:\n    Adaptation step size.\np_exponent:\n    Exponent p used by the Godard cost (typically p=2).\nq_exponent:\n    Exponent q used by the Godard cost (typically q=2).\nw_init:\n    Optional initial coefficient vector. If None, initializes to zeros.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">filter_order</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">5</span>,</span><span class=\"param\">\t<span class=\"n\">step_size</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">0.01</span>,</span><span class=\"param\">\t<span class=\"n\">p_exponent</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">2</span>,</span><span class=\"param\">\t<span class=\"n\">q_exponent</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">2</span>,</span><span class=\"param\">\t<span class=\"n\">w_init</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span><span class=\"p\">,</span> <span class=\"nb\">list</span><span class=\"p\">,</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span>)</span>"}, {"fullname": "pydaptivefiltering.Godard.supports_complex", "modulename": "pydaptivefiltering", "qualname": "Godard.supports_complex", "kind": "variable", "doc": "<p></p>\n", "annotation": ": bool", "default_value": "True"}, {"fullname": "pydaptivefiltering.Godard.step_size", "modulename": "pydaptivefiltering", "qualname": "Godard.step_size", "kind": "variable", "doc": "<p></p>\n", "annotation": ": float"}, {"fullname": "pydaptivefiltering.Godard.p", "modulename": "pydaptivefiltering", "qualname": "Godard.p", "kind": "variable", "doc": "<p></p>\n", "annotation": ": int"}, {"fullname": "pydaptivefiltering.Godard.q", "modulename": "pydaptivefiltering", "qualname": "Godard.q", "kind": "variable", "doc": "<p></p>\n", "annotation": ": int"}, {"fullname": "pydaptivefiltering.Godard.n_coeffs", "modulename": "pydaptivefiltering", "qualname": "Godard.n_coeffs", "kind": "variable", "doc": "<p></p>\n", "annotation": ": int"}, {"fullname": "pydaptivefiltering.Godard.optimize", "modulename": "pydaptivefiltering", "qualname": "Godard.optimize", "kind": "function", "doc": "<p>Executes the Godard adaptive algorithm.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>input_signal:\n    Input signal to be filtered.\ndesired_signal:\n    Ignored (kept only for API standardization).\nverbose:\n    If True, prints runtime.\nreturn_internal_states:\n    If True, returns internal signals in result.extra.\nsafe_eps:\n    Small epsilon used to avoid divisions by zero and unstable powers.</p>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>OptimizationResult\n    outputs:\n        Filter output y[k].\n    errors:\n        Godard error defined here as: e[k] = |y[k]|^q - Rq.\n    coefficients:\n        History of coefficients stored in the base class.\n    error_type:\n        \"blind_godard\".</p>\n\n<h2 id=\"extra-when-return_internal_statestrue\">Extra (when return_internal_states=True)</h2>\n\n<p>extra[\"phi_gradient\"]:\n    Trajectory of the instantaneous gradient term used for weight update, length N.\nextra[\"dispersion_constant\"]:\n    Scalar Rq used by the criterion.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">input_signal</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span><span class=\"p\">,</span> <span class=\"nb\">list</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"n\">desired_signal</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span><span class=\"p\">,</span> <span class=\"nb\">list</span><span class=\"p\">,</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">verbose</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">return_internal_states</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">safe_eps</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">1e-12</span></span><span class=\"return-annotation\">) -> <span class=\"n\">pydaptivefiltering</span><span class=\"o\">.</span><span class=\"n\">base</span><span class=\"o\">.</span><span class=\"n\">OptimizationResult</span>:</span></span>", "funcdef": "def"}, {"fullname": "pydaptivefiltering.Sato", "modulename": "pydaptivefiltering", "qualname": "Sato", "kind": "class", "doc": "<p>Implements the Sato algorithm for blind adaptive filtering with complex-valued data.</p>\n\n<h2 id=\"notes\">Notes</h2>\n\n<ul>\n<li>This is a BLIND algorithm: it does not require desired_signal.</li>\n<li>We keep <code>desired_signal=None</code> in <code>optimize</code> only for API standardization.</li>\n</ul>\n", "bases": "pydaptivefiltering.base.AdaptiveFilter"}, {"fullname": "pydaptivefiltering.Sato.__init__", "modulename": "pydaptivefiltering", "qualname": "Sato.__init__", "kind": "function", "doc": "<h2 id=\"parameters\">Parameters</h2>\n\n<p>filter_order:\n    FIR filter order (number of taps - 1). Number of coefficients is filter_order + 1.\nstep_size:\n    Adaptation step size.\nw_init:\n    Optional initial coefficient vector. If None, initializes to zeros.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">filter_order</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">5</span>,</span><span class=\"param\">\t<span class=\"n\">step_size</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">0.01</span>,</span><span class=\"param\">\t<span class=\"n\">w_init</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span><span class=\"p\">,</span> <span class=\"nb\">list</span><span class=\"p\">,</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span>)</span>"}, {"fullname": "pydaptivefiltering.Sato.supports_complex", "modulename": "pydaptivefiltering", "qualname": "Sato.supports_complex", "kind": "variable", "doc": "<p></p>\n", "annotation": ": bool", "default_value": "True"}, {"fullname": "pydaptivefiltering.Sato.step_size", "modulename": "pydaptivefiltering", "qualname": "Sato.step_size", "kind": "variable", "doc": "<p></p>\n", "annotation": ": float"}, {"fullname": "pydaptivefiltering.Sato.n_coeffs", "modulename": "pydaptivefiltering", "qualname": "Sato.n_coeffs", "kind": "variable", "doc": "<p></p>\n", "annotation": ": int"}, {"fullname": "pydaptivefiltering.Sato.optimize", "modulename": "pydaptivefiltering", "qualname": "Sato.optimize", "kind": "function", "doc": "<p>Executes the Sato blind adaptive algorithm.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>input_signal:\n    Input signal to be filtered.\ndesired_signal:\n    Ignored (kept only for API standardization).\nverbose:\n    If True, prints runtime.\nreturn_internal_states:\n    If True, returns internal signals in result.extra.\nsafe_eps:\n    Small epsilon used to avoid division by zero.</p>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>OptimizationResult\n    outputs:\n        Filter output y[k].\n    errors:\n        Sato error defined here as: e[k] = y[k] - gamma * sign(y[k]).\n    coefficients:\n        History of coefficients stored in the base class.\n    error_type:\n        \"blind_sato\".</p>\n\n<h2 id=\"extra-when-return_internal_statestrue\">Extra (when return_internal_states=True)</h2>\n\n<p>extra[\"sato_sign_track\"]:\n    Track of sign(y[k]) = y[k]/|y[k]| (with safe handling around zero), length N.\nextra[\"dispersion_constant\"]:\n    Scalar gamma used by the Sato criterion.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">input_signal</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span><span class=\"p\">,</span> <span class=\"nb\">list</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"n\">desired_signal</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span><span class=\"p\">,</span> <span class=\"nb\">list</span><span class=\"p\">,</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">verbose</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">return_internal_states</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">safe_eps</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">1e-12</span></span><span class=\"return-annotation\">) -> <span class=\"n\">pydaptivefiltering</span><span class=\"o\">.</span><span class=\"n\">base</span><span class=\"o\">.</span><span class=\"n\">OptimizationResult</span>:</span></span>", "funcdef": "def"}, {"fullname": "pydaptivefiltering.Kalman", "modulename": "pydaptivefiltering", "qualname": "Kalman", "kind": "class", "doc": "<p>Kalman Filter for state estimation with complex or real-valued data.</p>\n\n<h2 id=\"state-space-model-standard-form\">State-space model (standard form)</h2>\n\n<p>x(k) = A(k-1) x(k-1) + B(k) n(k)\ny(k) = C^T(k) x(k)   + n1(k)</p>\n\n<p>with covariances:\nE[n(k)  n(k)^H]  = Rn(k)\nE[n1(k) n1(k)^H] = Rn1(k)</p>\n\n<h2 id=\"notes\">Notes</h2>\n\n<ul>\n<li>This class integrates the Kalman recursion into the library-wide\n<code>AdaptiveFilter</code>/<code>OptimizationResult</code> interface.</li>\n<li><code>self.w</code> stores the current state estimate x(k|k) as a 1-D vector (n,).</li>\n<li>In this implementation, <code>OptimizationResult.coefficients</code> stores the\ncovariance history Re(k|k) with shape (N, n, n). To achieve this using\nthe standardized <code>_pack_results</code>, we store Re(k|k) snapshots in\n<code>self.w_history</code> (overriding the typical meaning of w_history for this\nnon-FIR algorithm).</li>\n</ul>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>A:\n    State transition matrix A(k-1), shape (n, n), or a sequence over k.\nC_T:\n    Measurement matrix C^T(k), shape (p, n), or a sequence over k.\nRn:\n    Process noise covariance Rn(k), shape (q, q), or a sequence over k.\nRn1:\n    Measurement noise covariance Rn1(k), shape (p, p), or a sequence over k.\nB:\n    Process noise input matrix B(k), shape (n, q). If None, identity is used\n    (q = n).\nx_init:\n    Initial state estimate x(0|0), shape (n,), (n,1) or (1,n). If None, zeros.\nRe_init:\n    Initial error covariance Re(0|0), shape (n, n). If None, identity.</p>\n\n<h2 id=\"raises\">Raises</h2>\n\n<p>ValueError\n    If the initial shapes are inconsistent.</p>\n", "bases": "pydaptivefiltering.base.AdaptiveFilter"}, {"fullname": "pydaptivefiltering.Kalman.__init__", "modulename": "pydaptivefiltering", "qualname": "Kalman.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">A</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span><span class=\"p\">,</span> <span class=\"n\">Sequence</span><span class=\"p\">[</span><span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span><span class=\"p\">]]</span>,</span><span class=\"param\">\t<span class=\"n\">C_T</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span><span class=\"p\">,</span> <span class=\"n\">Sequence</span><span class=\"p\">[</span><span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span><span class=\"p\">]]</span>,</span><span class=\"param\">\t<span class=\"n\">Rn</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span><span class=\"p\">,</span> <span class=\"n\">Sequence</span><span class=\"p\">[</span><span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span><span class=\"p\">]]</span>,</span><span class=\"param\">\t<span class=\"n\">Rn1</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span><span class=\"p\">,</span> <span class=\"n\">Sequence</span><span class=\"p\">[</span><span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span><span class=\"p\">]]</span>,</span><span class=\"param\">\t<span class=\"n\">B</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span><span class=\"p\">,</span> <span class=\"n\">Sequence</span><span class=\"p\">[</span><span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span><span class=\"p\">],</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">x_init</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">Re_init</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span>)</span>"}, {"fullname": "pydaptivefiltering.Kalman.supports_complex", "modulename": "pydaptivefiltering", "qualname": "Kalman.supports_complex", "kind": "variable", "doc": "<p></p>\n", "annotation": ": bool", "default_value": "True"}, {"fullname": "pydaptivefiltering.Kalman.A", "modulename": "pydaptivefiltering", "qualname": "Kalman.A", "kind": "variable", "doc": "<p></p>\n", "annotation": ": Union[numpy.ndarray, Sequence[numpy.ndarray]]"}, {"fullname": "pydaptivefiltering.Kalman.C_T", "modulename": "pydaptivefiltering", "qualname": "Kalman.C_T", "kind": "variable", "doc": "<p></p>\n", "annotation": ": Union[numpy.ndarray, Sequence[numpy.ndarray]]"}, {"fullname": "pydaptivefiltering.Kalman.Rn", "modulename": "pydaptivefiltering", "qualname": "Kalman.Rn", "kind": "variable", "doc": "<p></p>\n", "annotation": ": Union[numpy.ndarray, Sequence[numpy.ndarray]]"}, {"fullname": "pydaptivefiltering.Kalman.Rn1", "modulename": "pydaptivefiltering", "qualname": "Kalman.Rn1", "kind": "variable", "doc": "<p></p>\n", "annotation": ": Union[numpy.ndarray, Sequence[numpy.ndarray]]"}, {"fullname": "pydaptivefiltering.Kalman.B", "modulename": "pydaptivefiltering", "qualname": "Kalman.B", "kind": "variable", "doc": "<p></p>\n", "annotation": ": Union[numpy.ndarray, Sequence[numpy.ndarray], NoneType]"}, {"fullname": "pydaptivefiltering.Kalman.x", "modulename": "pydaptivefiltering", "qualname": "Kalman.x", "kind": "variable", "doc": "<p></p>\n", "annotation": ": numpy.ndarray"}, {"fullname": "pydaptivefiltering.Kalman.Re", "modulename": "pydaptivefiltering", "qualname": "Kalman.Re", "kind": "variable", "doc": "<p></p>\n", "annotation": ": numpy.ndarray"}, {"fullname": "pydaptivefiltering.Kalman.regressor", "modulename": "pydaptivefiltering", "qualname": "Kalman.regressor", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pydaptivefiltering.Kalman.w", "modulename": "pydaptivefiltering", "qualname": "Kalman.w", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pydaptivefiltering.Kalman.w_history", "modulename": "pydaptivefiltering", "qualname": "Kalman.w_history", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pydaptivefiltering.Kalman.optimize", "modulename": "pydaptivefiltering", "qualname": "Kalman.optimize", "kind": "function", "doc": "<p>Execute the Kalman recursion for a sequence of measurements y(k).</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>input_signal:\n    Measurement sequence y(k). Accepted shapes:\n    - (N,)        for scalar measurements\n    - (N,p)       for p-dimensional measurements\n    - (N,p,1)     also accepted (will be squeezed to (N,p))\ndesired_signal:\n    Ignored (kept only for API standardization).\nverbose:\n    If True, prints runtime.\nreturn_internal_states:\n    If True, returns selected internal values in <code>result.extra</code>.\nsafe_eps:\n    Small positive value used to regularize the innovation covariance\n    matrix when a linear solve fails (numerical stabilization).</p>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>OptimizationResult\n    outputs:\n        State estimates x(k|k), shape (N, n_states).\n    errors:\n        Innovations e(k) = y(k) - C^T(k) x(k|k-1), shape (N, n_meas).\n    coefficients:\n        Covariance history Re(k|k), shape (N, n_states, n_states).\n    error_type:\n        \"innovation\".</p>\n\n<h2 id=\"extra-when-return_internal_statestrue\">Extra (when return_internal_states=True)</h2>\n\n<p>extra[\"kalman_gain_last\"]:\n    Kalman gain K at the last iteration.\nextra[\"predicted_state_last\"]:\n    Predicted state x(k|k-1) at the last iteration (shape (n,)).\nextra[\"predicted_cov_last\"]:\n    Predicted covariance Re(k|k-1) at the last iteration.\nextra[\"innovation_cov_last\"]:\n    Innovation covariance S at the last iteration.\nextra[\"safe_eps\"]:\n    The stabilization epsilon used.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">input_signal</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span><span class=\"p\">,</span> <span class=\"nb\">list</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"n\">desired_signal</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span><span class=\"p\">,</span> <span class=\"nb\">list</span><span class=\"p\">,</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">verbose</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">return_internal_states</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">safe_eps</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">1e-12</span></span><span class=\"return-annotation\">) -> <span class=\"n\">pydaptivefiltering</span><span class=\"o\">.</span><span class=\"n\">base</span><span class=\"o\">.</span><span class=\"n\">OptimizationResult</span>:</span></span>", "funcdef": "def"}, {"fullname": "pydaptivefiltering.info", "modulename": "pydaptivefiltering", "qualname": "info", "kind": "function", "doc": "<p>Imprime informa\u00e7\u00f5es sobre a cobertura de algoritmos da biblioteca.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"return-annotation\">):</span></span>", "funcdef": "def"}];

    // mirrored in build-search-index.js (part 1)
    // Also split on html tags. this is a cheap heuristic, but good enough.
    elasticlunr.tokenizer.setSeperator(/[\s\-.;&_'"=,()]+|<[^>]*>/);

    let searchIndex;
    if (docs._isPrebuiltIndex) {
        console.info("using precompiled search index");
        searchIndex = elasticlunr.Index.load(docs);
    } else {
        console.time("building search index");
        // mirrored in build-search-index.js (part 2)
        searchIndex = elasticlunr(function () {
            this.pipeline.remove(elasticlunr.stemmer);
            this.pipeline.remove(elasticlunr.stopWordFilter);
            this.addField("qualname");
            this.addField("fullname");
            this.addField("annotation");
            this.addField("default_value");
            this.addField("signature");
            this.addField("bases");
            this.addField("doc");
            this.setRef("fullname");
        });
        for (let doc of docs) {
            searchIndex.addDoc(doc);
        }
        console.timeEnd("building search index");
    }

    return (term) => searchIndex.search(term, {
        fields: {
            qualname: {boost: 4},
            fullname: {boost: 2},
            annotation: {boost: 2},
            default_value: {boost: 2},
            signature: {boost: 2},
            bases: {boost: 2},
            doc: {boost: 1},
        },
        expand: true
    });
})();